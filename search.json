[
  {
    "objectID": "galaxy/galaxy.html",
    "href": "galaxy/galaxy.html",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "This first exercise will be executed on Galaxy, an interactive platform to run bioinformatics workflows. We will replicate this lesson with computer code later in this course. Galaxy has the possibility of working with a free account.\n\n\nWhite clover (Trifolium repens) is an allotetraploid. This means that it contains genomes originating from two different species within the same nucleus. Normally, white clover is an outbreeding species, but a self-compatible line was used for sequencing the white clover genome. This line is designated S10 in your data, indicating that this is the 10th self-fertilized generation. In addition, you have data from a wild clover accession (ecotype) called Tienshan (Ti), which is collected from Chinese mountains and is adapted to alpine conditions.\n Figure: Characterisation of the white clover population. T.Repens is a hybrid of T.Occidentale and T.Pallescens\n\n\n\n\n\n\nInstall IGV on your computer from here. This is a genome browser you will use to look at some files.\nCreate an account at usegalaxy.org and log into galaxy.\nFind the course data by going to this web address and by clicking on Import this history (top left corner of the page).\n\n\n\n\n\n\n\nNote\n\n\n\nIf usegalaxy.org has availability problems, you can use the other server https://usegalaxy.eu/ and get the data at this link. You might need to create an account there as well.\n\n\n\n\nYou will be working with two types of sequencing data. The first is PacBio Hifi reads, which are long and accurate. You can find them under Hifi_reads_white_clover.fastq. The second type is Illumina RNA-seq reads, which are short and accurate and should be aligned using a spliced aligner, such as STAR.\nThere are 24 of these files, 12 for each of the two genotypes mentioned before. The files are named [genotype]_[treatment]_[replicate].fastq. Treatment 1 is before and treatment 2 is after exposure to frost, respectively.\nIn addition to the sequencing data, there are also three reference files: one for homologous contig 1 (referencing T. occidentale-derived subgenome), one for contig 2 (T. pallescens-derived subgenome) and one for both Contigs 1 and 2. The reference files are in fasta format.\nThe file white_clover_genes.gtf contains the gene annotations for the two contigs.\n\n\n\nThrough Galaxy, we build a workflow applying tools to the data. We will look at the quality of the raw reads for both PacBio HiFi and Illumina RNA-seq reads. Afterwards, we align to references, using two different tools for the two types of data. Finally, we will look at the alignments on a genome browser. We will work then on a computing cluster to analyze the aligned data in some of the upcoming lessons of the course. The computing cluster is necessary because the analysis requires more resources than the ones offered for free by Galaxy.\n\n\n\n\n\nWhen you import the files, what you actually import is a History - a sequence of files and softwares applied on the data. You can see the history on the right side of your usegalaxy.org webpage with green panels. Here, we only have the starting data, and you will build the rest of your history through various tools.\n\nOn the left side of the screen, you have a menu with various available tools organized by category. All those softwares are also available on a classical computing command line (we will try those as well).\n\n\n\n\n\n\n\nUse the search bat\n\n\n\nThere are quite many tools in Galaxy. Please use the search bar above the toolbar to find quickly the programs we need.\n\n\n\n\n1 Run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis.\nIn the tool searchbar, find FastQC and choose FASTQC read quality reports. You will see a window with tool parameters: for the first option (raw read data from your current history), choose multiple files and select Hifi_reads_white_clover.fastq plus other fastq files you want to see the quality of (example in figure below). Then click on the button Run Tool. \nYou will notice that some new elements are added to your history. Part of them are FastQC producing a text file, while others are FastQC producing a webpage report. The reports are ready when coloured in green: click on the eye symbol of a history item to read a report.\n2 FastQC provides a report for each sample. To have a better comparison between the Hifi and Illumina data, we would combine the three FastQC reports into one using MultiQC.\nFind the tool called MultiQC aggregate results from [...]. In the options, select FastQC as the used tool for the generated logs. Then select the items of FastQC of your history producing RawData (Figure below). In this way, you build a pipeline from the previous reports to the new tool you are using. Now click on Run Tool.\n\nThe tool will be now running in your history. When it is done, click on the eye symbol to see the report.\n\n\n\n\n\n\nTip\n\n\n\nYou can find a “Help” button that offers additional information about the plots for each panel.\n\n\n\nQuestions:\n\nFocus on the following panels: “Per base sequence quality”, “Per sequence quality scores”…. (“Per base sequence content” always gives a FAIL for RNA-seq data). What do you notice with respect to the sequence quality scores? And are there any other quality issues worth noting? \n\n\n\n\n\n3 Map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contigs 1 and 2) using minimap2 (Map with minimap2). Find the minimap2 tool. In the options, change Use a built-in genome index into but select the option for having a genome from history and build an index from that. Choose then DNA_Contig1_2.fasta as the reference sequence.\nUnder the profile with preset options, choose PacBio HiFi reads vs reference mapping (map-hifi). Then click on Run Tool.\n4 Run the same alignment, but choose as preset options Long assembly to reference mapping. Up to 20% divergence (asm20).\nRename then the two alignments using the edit function (pen symbol in the history). Use for example names Contig1_2_maphifi and Contig1_2_asm20, to distinguish alignment options and reference genome.\n5 The aligned genomes are not sorted by coordinates. Sort the alignments using Samtools sort. In the options, choose the two aligned files with multiple selection. Then click on Run Tool.\n6 Download the two alignments to your computer. To do so, click on the disk symbol of each file in your history, and for each download both the Dataset (alignments in bam format) and their index files (in bai format). Download as well the reference genome in fasta format (DNA_Contig1_2.fasta from the history).\n7 Open IGV on your computer. Load the reference first: go on Genome --&gt; Load genome from file and select the fasta file you downloaded. Then load the two alignments: go on File --&gt; Load from file and select the bam and bai files you downloaded, together. You can now visualize the alignments by choosing a region of the genome and zooming in.\n\n\nQuestions:\n\n Look at the alignments in IGV. What do you notice about the alignments? What is the difference between the two alignments? Do you think one of them is better than the other? Choose on of the two alignments for the next steps. \n\n\n8 Repeat the alignment with Minimap2 (using the chosen alignment option from the question above) and the sorting, but using the reference genomes for Contig 1 and for Contig 2 searaately. Note: you can run all at once by choosing multiple reference genomes in the options!\n\nQuestions:\n\n Download the two references for Contig 1 and 2, and the two sorted alignments. Load the references from the menu Genomes in IGV, and then open the two alignments using the menu File in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences? \n\n\n\n\n\n\n9 First, group the 24 RNA-seq libraries into two dataset lists, one list of pairs for S10 libraries and another for Tienshan libraries. so we can work with multiple samples simultaneously. You can do this by selecting the libraries for each genotype and choosing Build Lists of Dataset Pairs.\n\nThe grouping suggested by Galaxy is wrong, because the paired reads are paired according to _1 and _2 in their names. Change those two with R1 and R2, click on Unpair all, and then click on the suggested corrected pairs with the buttons Pair these datasets.\n\nYour sequences will be substituted by two elements in your history. Here we chose for example to name them S10 and TI.\n\n10 Do alignment of the RNA-seq lists of raw files to the reference DNA_Contig1_2.fasta using STAR Gapped-read mapper for RNA-seq data. In the options use:\n\nas data, the parameter Paired-end (as collection), and then choose one of the two collections (you cannot run them all at once)\nas reference, DNA_Contig1_2.fasta, with Length of SA pre-indexing string equal to 9\nas index with gene-model, use white_clover_genes.gtf\nas output, Per gene read counts (GeneCounts).\n\n11 Use MultiQC to see the quality of the output. The alignment of STAR produces log files which can be used for quality reports. In the options of MultiQC select the tool STAR. Then Insert STAR output, as type of output the Log, and choose the two logs listing collections of STAR alignments. Then click on Run Tool.\n\nView the report to see the alignment statistics.\n\n\n\n\n\n\nNote\n\n\n\nGalaxy can also be used to create an automatic workflow that will map the data. This workflow can be useful when running multiple samples. You can generate a workflow from the analysis already completed in a history, by going to Settings → Extract workflow. You can also create a workflow from scratch using the Workflow editor."
  },
  {
    "objectID": "galaxy/galaxy.html#biological-introduction",
    "href": "galaxy/galaxy.html#biological-introduction",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "White clover (Trifolium repens) is an allotetraploid. This means that it contains genomes originating from two different species within the same nucleus. Normally, white clover is an outbreeding species, but a self-compatible line was used for sequencing the white clover genome. This line is designated S10 in your data, indicating that this is the 10th self-fertilized generation. In addition, you have data from a wild clover accession (ecotype) called Tienshan (Ti), which is collected from Chinese mountains and is adapted to alpine conditions.\n Figure: Characterisation of the white clover population. T.Repens is a hybrid of T.Occidentale and T.Pallescens"
  },
  {
    "objectID": "galaxy/galaxy.html#exercise-guide",
    "href": "galaxy/galaxy.html#exercise-guide",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "Install IGV on your computer from here. This is a genome browser you will use to look at some files.\nCreate an account at usegalaxy.org and log into galaxy.\nFind the course data by going to this web address and by clicking on Import this history (top left corner of the page).\n\n\n\n\n\n\n\nNote\n\n\n\nIf usegalaxy.org has availability problems, you can use the other server https://usegalaxy.eu/ and get the data at this link. You might need to create an account there as well.\n\n\n\n\nYou will be working with two types of sequencing data. The first is PacBio Hifi reads, which are long and accurate. You can find them under Hifi_reads_white_clover.fastq. The second type is Illumina RNA-seq reads, which are short and accurate and should be aligned using a spliced aligner, such as STAR.\nThere are 24 of these files, 12 for each of the two genotypes mentioned before. The files are named [genotype]_[treatment]_[replicate].fastq. Treatment 1 is before and treatment 2 is after exposure to frost, respectively.\nIn addition to the sequencing data, there are also three reference files: one for homologous contig 1 (referencing T. occidentale-derived subgenome), one for contig 2 (T. pallescens-derived subgenome) and one for both Contigs 1 and 2. The reference files are in fasta format.\nThe file white_clover_genes.gtf contains the gene annotations for the two contigs.\n\n\n\nThrough Galaxy, we build a workflow applying tools to the data. We will look at the quality of the raw reads for both PacBio HiFi and Illumina RNA-seq reads. Afterwards, we align to references, using two different tools for the two types of data. Finally, we will look at the alignments on a genome browser. We will work then on a computing cluster to analyze the aligned data in some of the upcoming lessons of the course. The computing cluster is necessary because the analysis requires more resources than the ones offered for free by Galaxy.\n\n\n\n\n\nWhen you import the files, what you actually import is a History - a sequence of files and softwares applied on the data. You can see the history on the right side of your usegalaxy.org webpage with green panels. Here, we only have the starting data, and you will build the rest of your history through various tools.\n\nOn the left side of the screen, you have a menu with various available tools organized by category. All those softwares are also available on a classical computing command line (we will try those as well).\n\n\n\n\n\n\n\nUse the search bat\n\n\n\nThere are quite many tools in Galaxy. Please use the search bar above the toolbar to find quickly the programs we need.\n\n\n\n\n1 Run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis.\nIn the tool searchbar, find FastQC and choose FASTQC read quality reports. You will see a window with tool parameters: for the first option (raw read data from your current history), choose multiple files and select Hifi_reads_white_clover.fastq plus other fastq files you want to see the quality of (example in figure below). Then click on the button Run Tool. \nYou will notice that some new elements are added to your history. Part of them are FastQC producing a text file, while others are FastQC producing a webpage report. The reports are ready when coloured in green: click on the eye symbol of a history item to read a report.\n2 FastQC provides a report for each sample. To have a better comparison between the Hifi and Illumina data, we would combine the three FastQC reports into one using MultiQC.\nFind the tool called MultiQC aggregate results from [...]. In the options, select FastQC as the used tool for the generated logs. Then select the items of FastQC of your history producing RawData (Figure below). In this way, you build a pipeline from the previous reports to the new tool you are using. Now click on Run Tool.\n\nThe tool will be now running in your history. When it is done, click on the eye symbol to see the report.\n\n\n\n\n\n\nTip\n\n\n\nYou can find a “Help” button that offers additional information about the plots for each panel.\n\n\n\nQuestions:\n\nFocus on the following panels: “Per base sequence quality”, “Per sequence quality scores”…. (“Per base sequence content” always gives a FAIL for RNA-seq data). What do you notice with respect to the sequence quality scores? And are there any other quality issues worth noting? \n\n\n\n\n\n3 Map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contigs 1 and 2) using minimap2 (Map with minimap2). Find the minimap2 tool. In the options, change Use a built-in genome index into but select the option for having a genome from history and build an index from that. Choose then DNA_Contig1_2.fasta as the reference sequence.\nUnder the profile with preset options, choose PacBio HiFi reads vs reference mapping (map-hifi). Then click on Run Tool.\n4 Run the same alignment, but choose as preset options Long assembly to reference mapping. Up to 20% divergence (asm20).\nRename then the two alignments using the edit function (pen symbol in the history). Use for example names Contig1_2_maphifi and Contig1_2_asm20, to distinguish alignment options and reference genome.\n5 The aligned genomes are not sorted by coordinates. Sort the alignments using Samtools sort. In the options, choose the two aligned files with multiple selection. Then click on Run Tool.\n6 Download the two alignments to your computer. To do so, click on the disk symbol of each file in your history, and for each download both the Dataset (alignments in bam format) and their index files (in bai format). Download as well the reference genome in fasta format (DNA_Contig1_2.fasta from the history).\n7 Open IGV on your computer. Load the reference first: go on Genome --&gt; Load genome from file and select the fasta file you downloaded. Then load the two alignments: go on File --&gt; Load from file and select the bam and bai files you downloaded, together. You can now visualize the alignments by choosing a region of the genome and zooming in.\n\n\nQuestions:\n\n Look at the alignments in IGV. What do you notice about the alignments? What is the difference between the two alignments? Do you think one of them is better than the other? Choose on of the two alignments for the next steps. \n\n\n8 Repeat the alignment with Minimap2 (using the chosen alignment option from the question above) and the sorting, but using the reference genomes for Contig 1 and for Contig 2 searaately. Note: you can run all at once by choosing multiple reference genomes in the options!\n\nQuestions:\n\n Download the two references for Contig 1 and 2, and the two sorted alignments. Load the references from the menu Genomes in IGV, and then open the two alignments using the menu File in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences? \n\n\n\n\n\n\n9 First, group the 24 RNA-seq libraries into two dataset lists, one list of pairs for S10 libraries and another for Tienshan libraries. so we can work with multiple samples simultaneously. You can do this by selecting the libraries for each genotype and choosing Build Lists of Dataset Pairs.\n\nThe grouping suggested by Galaxy is wrong, because the paired reads are paired according to _1 and _2 in their names. Change those two with R1 and R2, click on Unpair all, and then click on the suggested corrected pairs with the buttons Pair these datasets.\n\nYour sequences will be substituted by two elements in your history. Here we chose for example to name them S10 and TI.\n\n10 Do alignment of the RNA-seq lists of raw files to the reference DNA_Contig1_2.fasta using STAR Gapped-read mapper for RNA-seq data. In the options use:\n\nas data, the parameter Paired-end (as collection), and then choose one of the two collections (you cannot run them all at once)\nas reference, DNA_Contig1_2.fasta, with Length of SA pre-indexing string equal to 9\nas index with gene-model, use white_clover_genes.gtf\nas output, Per gene read counts (GeneCounts).\n\n11 Use MultiQC to see the quality of the output. The alignment of STAR produces log files which can be used for quality reports. In the options of MultiQC select the tool STAR. Then Insert STAR output, as type of output the Log, and choose the two logs listing collections of STAR alignments. Then click on Run Tool.\n\nView the report to see the alignment statistics.\n\n\n\n\n\n\nNote\n\n\n\nGalaxy can also be used to create an automatic workflow that will map the data. This workflow can be useful when running multiple samples. You can generate a workflow from the analysis already completed in a history, by going to Settings → Extract workflow. You can also create a workflow from scratch using the Workflow editor."
  },
  {
    "objectID": "about/about.html",
    "href": "about/about.html",
    "title": "About the Sandbox",
    "section": "",
    "text": "An infrastructure project for health data science training and research in Denmark\nThe National Health Data Science Sandbox project kicked off in 2021 with 5 years of funding via the Data Science Research Infrastructure initiative from the Novo Nordisk Foundation. Health data science experts at five Danish universities are contributing to the Sandbox with coordination from the Center for Health Data Science under lead PI Professor Anders Krogh. Data scientists hosted in the research groups of each PI are building infrastructure and training modules on Computerome and UCloud, the primary academic high performance computing (HPC) platforms in Denmark. If you have any questions or would like to get in touch with one of our data scientists, please contact us here.\n\n\n\n\n\nOur computational ‘sandbox’ allows data scientists to explore datasets, tools and analysis pipelines in the same high performance computing environments where real research projects are conducted. Rather than a single, hefty environment, we’re deploying modularized topical environments tailored for independent use on each HPC platform. We aim to support three key user groups based at Danish universities:\n\ntrainees: use our training modules to learn analysis techniques with some guidance and guardrails - for your data type of interest AND for general good practices for HPC environments\n\nresearchers: prototype your tools and algorithms with an array of good quality datasets that are GDPR compliant and free to access\neducators: develop your next course with computational assignments in the HPC environment your students will use for their research\n\nActivity developing independent training modules and hosting workshops has centered on UCloud, while collaborative construction of a flexible Course Platform has been completed on Computerome for use by the Sandbox and independent educators. Publicly sourced datasets are being used in training modules on UCloud, while generation of synthetic data is an ongoing project at Computerome. Sandbox resources are under active construction, so check out our other pages for the current status on HPC Access, Datasets, and Modules. We run workshops using completed training modules on a regular basis and provide active support for Sandbox-hosted courses through a slack workspace. See our Contact page for more information.\n\n\nPartner with the Sandbox\nThe Sandbox welcomes proposals for new courses, modules, and prototyping projects from researchers and educators. We’d like to partner with lecturers engaged with us in developing needed materials collaboratively - we would love to have input from subject experts or help promote exciting new tools and analysis methods via modules! Please contact us with your ideas at nhds_sandbox@sund.ku.dk.\n\nWe thank the Novo Nordisk Foundation for funding support. If you use the Sandbox for research or reference it in text or presentations, please acknowledge the Health Data Science Sandbox project and its funder the Novo Nordisk Foundation (grant number NNF20OC0063268)."
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html",
    "href": "nb/03_bulk_RNA_analysis.html",
    "title": "Bulk RNA Analysis",
    "section": "",
    "text": "Tutorial description\n\n\n\nThis tutorial will cover the steps for performing Differential Gene Expression on the RNA-seq data obtained from Galaxy. At the end of this tutorial you will be able to use R to\n\nPerform preliminary analyses of the RNA-seq results\nFind differentially expressed genes between two conditions using edgeR\nThe present tutorial, like the rest of the course material, is available at our open-source github repository.\nTo use this notebook, use the NGS (R) kernel that contains the packages. Choose it by selecting Kernel -&gt; Change Kernel in the menu on top of the window.\nLoad the necessary R libraries\nlibrary(VennDiagram)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(formattable)\nlibrary(mixOmics)\nlibrary(pheatmap)\nlibrary(edgeR)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#file-processing",
    "href": "nb/03_bulk_RNA_analysis.html#file-processing",
    "title": "Bulk RNA Analysis",
    "section": "File processing",
    "text": "File processing\nThe data for this exercise comes from the 12 tabular files with Reads per Gene counts generated by STAR Mapping in the raw-data alignment part of this course. We want to create a table where each column is a sample, and the content of the table are the read counts from STAR. We must merge the 12 files with Reads per Gene information into a single file.\n\nIf you aligned datasets in the first notebook with jupyterlab, then you will find the files using the following command:\n\n\nsamples &lt;- sort(system(\"find results/STAR_output/*_align_contigs_1_2 -name \\\"*ReadsPerGene.out.tab\\\"\", intern=TRUE))\nprint(samples)\nRead_counts &lt;- do.call(cbind, lapply(samples, function(x) read.delim(file=x, header = FALSE)))\n\n\nIf you aligned datasets interactively with Galaxy, then you will need to\n\ncreate the folder tabular_files into the results folder\ncopy the tabular files from STAR into the created folder. Each file must have the sample name and end by ReadsPerGene.out.tab. For example S10_1_1ReadsPerGene.out.tab\nrun the following commands removing the # symbol\n\n\n\n#samples &lt;- sort(system(\"find results/tabular_files/ -name \\\"*ReadsPerGene.out.tab\\\"\", intern=TRUE))\n#print(samples)\n#Read_counts &lt;- do.call(cbind, lapply(samples, function(x) read.delim(file=x, header = FALSE)))\n\nThe data frame has genes as rows and samples as columns and stores the gene expression counts (value representing the total number of sequence reads that originated from a particular gene in a sample) for each of the 12 samples. This data frame should have 12 columns and 366 rows.\n\nrownames(Read_counts) &lt;- Read_counts[,1]\nRead_counts &lt;- Read_counts[c(5:nrow(Read_counts)), c(seq(2, 46, by=4))]\ncolnames(Read_counts) &lt;- c(\"S10_1_1\", \"S10_1_2\", \"S10_1_3\", \"S10_2_1\", \"S10_2_2\", \"S10_2_3\", \n                       \"TI_1_1\", \"TI_1_2\", \"TI_1_3\", \"TI_2_1\", \"TI_2_2\", \"TI_2_3\")\nhead(Read_counts, n=10)\ndim(Read_counts) # dimensions of the data frame\n\nImport the Metadata table. This file, as its name suggests, contains information about each of the 12 RNA-seq samples, such as the treatment (Condition), genotype and replicate.\nNote that the order of the rows in the Metadata table should be the same as the columns in the Read_counts file generated above.\n\nmetadata &lt;- read.csv(\"../Data/Clover_Data/metadata.csv\", sep =\";\", row.names=1, stringsAsFactors=TRUE)\nmetadata\n\nIn order to aid the following steps, we will create a Group for each sample (a new column in the metadata) based on the Genotype&Condition of each sample and assign the three replicates to this group.\n\nGroup &lt;- factor(paste(metadata$Genotype, metadata$Condition, sep=\"_\"))\nmetadata &lt;- cbind(metadata,Group=Group)\nmetadata"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#create-the-dgelist-object",
    "href": "nb/03_bulk_RNA_analysis.html#create-the-dgelist-object",
    "title": "Bulk RNA Analysis",
    "section": "Create the DGEList object",
    "text": "Create the DGEList object\nWe will merge the read counts and the metadata into a list-based data object named DGEList, which can be manipulated as any list object in R.\nThe main components of the DGEList object are the matrix “counts” containing our read per gene counts and a data.frame “samples” containing the metadata.\nNote that all the genes with zero counts across all samples were eliminated.\n\nDGEList &lt;- DGEList(Read_counts, remove.zeros = TRUE)\nDGEList$samples$Condition &lt;- relevel(metadata$Condition, ref = \"Control\")\nDGEList$samples$Genotype &lt;- metadata$Genotype\nDGEList$samples$group &lt;- metadata$Group\nDGEList"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#preliminary-data-analysis",
    "href": "nb/03_bulk_RNA_analysis.html#preliminary-data-analysis",
    "title": "Bulk RNA Analysis",
    "section": "Preliminary data analysis",
    "text": "Preliminary data analysis\nFirst, we will calculate the “pseudoCounts” as log2 of the reads per gene counts.  This is not part of the actual differential gene expression analysis but is helpful for data exploration and quality assessment. We will look at a histogram of one of the samples and a boxplot representation of the log2 counts for all the 12 samples.  Note that there are many genes with a low number of mapped reads and that there are differences between the average read counts for each library.\n\npseudoCounts &lt;- log2(DGEList$counts + 1)\nhead(pseudoCounts)\nhist(pseudoCounts[ ,\"S10_1_1\"], main = \"\", xlab = \"Read counts\")\nboxplot(pseudoCounts, col = \"gray\", las = 3, cex.names = 1)\n\nWe can also create a PCA plot of the samples in order to assess the differences between the Genotypes and Conditions, but also between the replicates. In this plot the samples that are similar cluster together, while samples that are different are further apart.  In this type of plot, we would expect samples from the same group (the three replicates for each sample) to exhibit a similar gene expression profile thus clustering together while being separated from the other samples.\n\nresPCA &lt;- pca(t(pseudoCounts), ncomp = 6)\nplotIndiv(resPCA, group = metadata$Genotype, pch=metadata$Condition,\n                  legend = T, legend.title = 'Genotype', legend.title.pch = 'Condition',\n                  title = 'PCA plot raw counts', style = 'ggplot2', size.xlabel = 10, size.ylabel = 10)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#filtering-the-lowly-expressed-genes",
    "href": "nb/03_bulk_RNA_analysis.html#filtering-the-lowly-expressed-genes",
    "title": "Bulk RNA Analysis",
    "section": "Filtering the lowly expressed genes",
    "text": "Filtering the lowly expressed genes\nAs seen previously, many genes have a low number of read counts in our samples. The genes with very low counts across all libraries provide little evidence for differential expression, thus we should eliminate these genes before the analysis.  One of the filtering methods we can use is the “filterByExpr” function provided by the edgeR package. By default, this function keeps only the genes that have at least 10 reads per group, but other cutoffs can also be applied.\n\nkeep &lt;- filterByExpr(DGEList, group=metadata$Group) #create the filter\nDGEList &lt;- DGEList[keep, , keep.lib.sizes=FALSE] #apply the filter to on the DGEList object\ntable(keep) #Check the number of genes that passed the filter"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#normalization",
    "href": "nb/03_bulk_RNA_analysis.html#normalization",
    "title": "Bulk RNA Analysis",
    "section": "Normalization",
    "text": "Normalization\nAs we are working with multiple samples we need to normalize the read counts per gene in order to account for compositional and technical differences between the 12 RNA-seq libraries. For this, we will calculate normalization factors using the trimmed mean of M-values (TMM) method. You can read more about different normalization methods in the user manual.\n Note that running “calcNormFactors” does not change the actual reads per gene counts, it just fills the “norm.factors” column in DGEList$samples.\nThese factors will be used to scale the read counts for each library. From the user guide: “A normalization factor below one indicates that a small number of high count genes are monopolizing the sequencing, causing the counts for other genes to be lower than would be usual given the library size.”\n\nDGEList &lt;- calcNormFactors(DGEList, method=\"RLE\")\nDGEList$samples"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#normalized-counts---exploratory-data-analysis",
    "href": "nb/03_bulk_RNA_analysis.html#normalized-counts---exploratory-data-analysis",
    "title": "Bulk RNA Analysis",
    "section": "Normalized counts - Exploratory Data analysis",
    "text": "Normalized counts - Exploratory Data analysis\nFor data analysis purposes normalized log2 counts can be extracted from the DGEList object using the function CPM (counts per million).\nWe will generate the same plots as for the raw counts in order to compare the data before and after normalization.\nDo the plots for normalized counts look different compared with the plots computed before data filtering and normalization?\n\npseudoNormCounts &lt;- cpm(DGEList, log = TRUE, prior.count = 1)\nhead(pseudoNormCounts)\nhist(pseudoNormCounts[ ,\"S10_1_1\"], main = \"\", xlab = \"counts\")\nboxplot(pseudoNormCounts, col = \"gray\", las = 3, cex.names = 1)\n\nresPCA &lt;- pca(t(pseudoNormCounts), ncomp = 6)\nplotIndiv(resPCA, group = metadata$Genotype, pch=metadata$Condition,\n                  legend = T, legend.title = 'Genotype', legend.title.pch = 'Condition',\n                  title = 'PCA plot normalized counts', style = 'ggplot2', size.xlabel = 10, size.ylabel = 10)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#degs-for-white-clover-s10-plants-treatment-vs-control",
    "href": "nb/03_bulk_RNA_analysis.html#degs-for-white-clover-s10-plants-treatment-vs-control",
    "title": "Bulk RNA Analysis",
    "section": "DEGs for White clover S10 plants Treatment vs Control",
    "text": "DEGs for White clover S10 plants Treatment vs Control\nFind DEGs for White clover S10 plants in Treatment condition compared with the Control condition We will test for differentially expressed genes using the quasi-likelihood F-tests method. This is easily done just by running the “glmQFTest” function on the fit model and selecting one of the contrasts we created above (in this case the “S10” contrast).\nNext, we will use the topTags function to extract the information about all the genes.\n\nglmqlf_S10 &lt;- glmQLFTest(fit, contrast=contrasts[,\"S10\"])\nDEG_S10 &lt;- topTags(glmqlf_S10, n = nrow(DGEList$counts))\nDEG_S10\n\nWe have now created a table with certain parameters calculated for each of the genes analysed.\nlogFC represents the base 2 logarithm of the fold change and it shows us how much the expression of the gene has changed between the two conditions. A logFC of 1 means a doubling in the read per gene count between the control and treatment samples. The genes with a logFC higher than 0 are upregulated while the genes with a logFC lower than 0 are downregulated between the control and treatment samples.  logCPM represents the average log2-counts-per-million, the abundance of the gene.\nF - F-statistic.\nPValue is the raw p-value.\nFDR (The false discovery rate) represents the adjusted p-value and is calculated using Benjamini and Hochberg’s algorithm. It controls the rate of false positive values under multiple testing. Usually, a threshold of under 5% is set for the FDR.\nThe important information for us in this table is stored in the “logFC” and the “FDR” columns. The top DE genes have small FDR values and large fold changes\nMany of the genes in the samples are uninteresting for us, as they have a high FDR and/or low logFC values so we cannot consider them as differentially expressed.\nWe will apply a filtering step in order to keep only the statistically significant genes. We will filter out the genes with an FDR higher than 0.05 and an absolute logFC lower than 1.\n\nDEG_S10_filtered &lt;- DEG_S10$table[DEG_S10$table$FDR &lt; 0.05 & abs(DEG_S10$table$logFC) &gt; 1,] #Filtering\nDEG_S10_filtered &lt;- rownames_to_column(DEG_S10_filtered) %&gt;% rename(gene_ID = rowname) #Adding the gene_ID column\nhead(DEG_S10_filtered)\nnrow(DEG_S10_filtered) # finding the number of genes that passed the filter \n\nWe can also visualize the selected genes by plotting a Smear plot or a Volcano plot. The Genes that passed the filter are coloured in red, and the top 10 genes with the lowest FDR value are labelled with their gene ID.\nWe can see that the majority of the genes analysed are either not statistically significant or have a very small logFC.\n\nplotSmear(glmqlf_S10,\n          de.tags = rownames(DEG_S10$table)[which(DEG_S10$table$FDR &lt; 0.05 & abs(DEG_S10$table$logFC) &gt; 1)])\ntext(x=DEG_S10_filtered$logCPM[1:10],\n     y=DEG_S10_filtered$logFC[1:10],\n     labels=DEG_S10_filtered$gene_ID[1:10], cex=0.7, pos=1)\nabline(h = c(-1, 1), col = \"blue\")\n\nWe can also create a heatmap with the log2 read counts of the selected differentially expressed genes so that we can visualise the differences in normalized counts between the Control and the Treatment samples.\nThe genes are ordered by the FDR value.\n\nannot_col &lt;- data.frame(row.names = colnames(pseudoNormCounts)[1:6], Condition = c(rep(\"Control\", 3),rep( \"Treatment\", 3)))                   \npheatmap(as.matrix(pseudoNormCounts[DEG_S10_filtered$gene_ID,c(1:6)]), cluster_rows = F, cluster_col = F, annotation_col = annot_col)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#degs-for-white-clover-tienshan-treatment-vs-control",
    "href": "nb/03_bulk_RNA_analysis.html#degs-for-white-clover-tienshan-treatment-vs-control",
    "title": "Bulk RNA Analysis",
    "section": "DEGs for White clover Tienshan Treatment vs Control",
    "text": "DEGs for White clover Tienshan Treatment vs Control\nWe can do this using the same functions as above and changing the contrast.\nThis time we will directly filter the differentially expressed genes using the same parameters as for the S10 samples.\n\nglmqlf_Ti &lt;- glmQLFTest(fit, contrast=contrasts[,\"Tienshan\"])\nDEG_Ti &lt;- topTags(glmqlf_Ti, n = nrow(DGEList$counts))\nDEG_Ti_filtered &lt;- DEG_Ti$table[DEG_Ti$table$FDR &lt; 0.05 & abs(DEG_Ti$table$logFC) &gt; 1,]\nDEG_Ti_filtered &lt;- rownames_to_column(DEG_Ti_filtered) %&gt;% rename(gene_ID = rowname)\nprint(head(DEG_Ti_filtered))\nprint(\"Nr of differentially expressed genes:\")\nprint(nrow(DEG_Ti_filtered))\n\nWe can now plot a Venn diagram with the DEGs for the two genotypes in order to observe the number of common and specific differentially expressed genes between the two genotypes as response to the cold exposure. You can see that a high percentage of the identified genes are common for the two genotypes, while each genotype has also specific genes.\n\nvd &lt;- venn.diagram(\n  x = list(DEG_S10_filtered$gene_ID, DEG_Ti_filtered$gene_ID),\n  category.names = c(\"S10\" , \"Tienshan\"),\n  lwd = 4,\n  fill = c(\"cornflowerblue\", \"yellowgreen\"),\n  filename = NULL,\n  cat.cex = 1,\n  cat.fontface = \"bold\",\n  output=TRUE\n)\ngrid.draw(vd)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#degs-for-s10tienshan-treatment-vs-control-wo-genotype-effects",
    "href": "nb/03_bulk_RNA_analysis.html#degs-for-s10tienshan-treatment-vs-control-wo-genotype-effects",
    "title": "Bulk RNA Analysis",
    "section": "DEGs for S10+Tienshan Treatment vs Control w/o genotype effects",
    "text": "DEGs for S10+Tienshan Treatment vs Control w/o genotype effects\nUntil now we tested for DEGs specific for each of the two genotypes under cold treatment. We can also run a test where we ignore the genotype and just test for the differences in the cold response.  Consider the counts for both genotypes as a single dataset using the previously created contrast “S10_Tienshan”.  * Do the results look different compared with the previous tests?\n\nglmqlf_S10_Ti &lt;- glmQLFTest(fit, contrast=contrasts[,\"S10_Tienshan\"])\nDEG_S10_Ti &lt;- topTags(glmqlf_S10_Ti, n = nrow(DGEList$counts))\nDEG_S10_Ti_filtered &lt;- DEG_S10_Ti$table[DEG_S10_Ti$table$FDR &lt; 0.05 & abs(DEG_S10_Ti$table$logFC) &gt; 1,]\nDEG_S10_Ti_filtered &lt;- rownames_to_column(DEG_S10_Ti_filtered)  %&gt;% rename(gene_ID = rowname)\nprint(head(DEG_S10_Ti_filtered))\nprint(\"Nr of differentially expressed genes:\")\nprint(nrow(DEG_S10_Ti_filtered))\n\nPlot the results from the 3 tests in a Venn diagram to visualize the number of common and unique genes\n\nvd &lt;- venn.diagram(\n  x = list(DEG_S10_filtered$gene_ID, DEG_Ti_filtered$gene_ID,\n           DEG_S10_Ti_filtered$gene_ID),\n  category.names = c(\"S10\" , \"Tienshan\", \"S10_Tienshan\"),\n  lwd = 3,\n  fill = c(\"cornflowerblue\", \"yellowgreen\", \"thistle3\"),\n  filename = NULL,\n  cat.cex = 1,\n  cat.fontface = \"bold\",\n  output=TRUE\n)\ngrid.draw(vd)"
  },
  {
    "objectID": "nb/03_bulk_RNA_analysis.html#explore-dge-results",
    "href": "nb/03_bulk_RNA_analysis.html#explore-dge-results",
    "title": "Bulk RNA Analysis",
    "section": "Explore DGE results",
    "text": "Explore DGE results\n\nSelect the genes which appear only in the analysis using both genotypes for further examination.\nWe can use the “anti_join” function from the dplyr package to keep only the unique genes that appear only when using both genotypes.\n\nS10_Ti_unique &lt;- anti_join(DEG_S10_Ti_filtered, DEG_S10_filtered, by=\"gene_ID\") %&gt;%\n                       anti_join(DEG_Ti_filtered, by=\"gene_ID\")\nS10_Ti_unique\n\n\n\nLinking the genes selected as differentially expressed back to the raw read counts\nHow do the counts look for these genes, does it make sense that they are differentially expressed only when using the two genotypes?\n\nRead_counts &lt;- rownames_to_column(Read_counts) %&gt;% rename(gene_ID = rowname)\nS10_Ti_unique_counts &lt;- inner_join(S10_Ti_unique[,c(1,2,6)], Read_counts, by=\"gene_ID\")\nS10_Ti_unique_counts\n\n\n\nAdding functional annotation to DEGs\nUntil now we looked only at gene IDs, but we can also add functional annotations to the DEGs. The functional annotations were generated using protein sequences and the EggNOG software.\nIdentifying the molecular function of the differentially expressed genes can help us do a literature survey in order to check if any of the genes discovered have been previously identified as being involved in the cold response.\n\nFunctional_annotations &lt;- read.delim(\"../Data/Clover_Data/Functional_Annotations.txt\")\nS10_Ti_unique_FA &lt;- inner_join(S10_Ti_unique[,c(1,2,6)], Functional_annotations, by=\"gene_ID\")\nS10_Ti_unique_FA\n\n\n  Tasks and Questions  \n\n\nBased on the results obtained in the analysis so far, would you change the cut-off for the FDR and logFC to be more strict or more permissive? Look back at the raw counts for different FDR and logFC values and set the thresholds as you find appropriate.\n\nYou can also plot histograms with the FDR and logFC values.\n\n hist(DEG_S10$table$FDR , main = \"\", xlab = \"FDR\",  breaks= 200, xlim = range(c(0, 0.1)))\n\n\n hist(DEG_S10$table$logFC , main = \"\", xlab = \"logFC\",  breaks= 50, xlim = range(c(-6, 6)))\n\n\nSeparate the upregulated and downregulated genes for each genotype and append functional annotations to them.\nIdentify the genes that are commonly upregulated in S10 and Tienshan samples and the uniquely upregulated genes for each genotype.\nWhy do you think some of the proteins appear in duplicates? \n\nTo answer these questions, it may be convenient to save summary tables from R and open them in excel. See the code below for examples of how to do this. Files can be downloaded by right-clicking on the file name.\nIf you are familiar with R functions, you are welcome to use those for counting.\n\ndir.create(\"DEG_Output_tables\", showWarnings = FALSE)\n\n\n#Create the table with the DEGs, Raw counts(just for the Ti samples in this case, change to columns (2:7) for the S10 samples) and Functional annotations\nDEG_Ti_counts_FA &lt;- inner_join(DEG_Ti_filtered[,c(1, 2, 6)], Read_counts[, c(1, 8:13)], by=\"gene_ID\") %&gt;%\n                 inner_join(Functional_annotations, by=\"gene_ID\")\n#Write the table to file\nwrite.table(DEG_Ti_counts_FA, file = \"DEG_Output_tables/Ti_Treatment_Control_DGE.txt\", quote = FALSE, row.names = FALSE, sep = \"\\t\")\n#Display the first 10 rows of the table\nhead(DEG_Ti_counts_FA, n=10)\n\nExample for filtering and counting the Up/Down genes. You can easily filter using the “filter()” function just by specifying the dataframe and a logical argument.\n\nDEG_Ti_up &lt;- filter(DEG_Ti_counts_FA, logFC &gt; 0)\nprint(\"Nr of upregulated genes:\")\nprint(nrow(DEG_Ti_up))\nDEG_Ti_down &lt;- filter(DEG_Ti_counts_FA, logFC &lt; 0)\nprint(\"Nr of downregulated genes:\")\nprint(nrow(DEG_Ti_down))\n\nYou can use the “inner_join” and the “anti_join” functions from the dplyr package to select the common and unique genes for each genotype:\nexample_file_joined &lt;- inner_join(file1, file2, by=\"gene_ID\")\n\n\n\n\n\n\nWrapping up\n\n\n\nIn this notebook, you have worked with RNA-seq results for two white clover genotypes exposed to one night of cold treatment, aiming to identify genes that change their expression in response to the cold treatment. You have learned to perform exploratory data analysis of raw and normalized RNA-seq read counts. You have also performed differential gene expression using edgeR.\nDo you want to look for more analysis? We have an introductory course on bulkRNA analysis at the Danish Health Data Science Sandbox (held periodically in Copenhagen, keep an eye on the webpage where they list courses). You can also find the material on the Transcriptomics Sandbox on uCloud (for danish users of uCloud), otherwise the course is documented in web format at the respective webpage.\n \n\n Transcriptomics Sandbox \n\n \n\n bulkRNA analysis course"
  },
  {
    "objectID": "nb/01_raw_data_alignment.html",
    "href": "nb/01_raw_data_alignment.html",
    "title": "Raw data alignment",
    "section": "",
    "text": "Tutorial description\n\n\n\nThis tutorial will cover the steps for performing the alignment of raw RNA- and HiFi-sequencing data. You will need to use the software IGV on your computer to visualize some of the output files, which can be easily downloaded once they are produced. At the end of this tutorial you will be able to:\n\nperform and discuss quality control on raw data in fastq format using FastQC and MultiQC\nalign HiFi and RNA sequencing data with dedicated tools such as MiniMap2 and STAR\nanalyze the quality the alignment with qualimap\nThe output of this notebook will be used for the Variant calling analysis and the bulk RNA-sequencing analysis. If you do not want to run this notebook, you can alternatively use the free interactive tool Galaxy to perform the alignment steps. We have uploaded the data on Galaxy, and the manual to perform the exercise is found at the course webpage.\nThe present tutorial, like the rest of the course material, is available at our open-source github repository."
  },
  {
    "objectID": "nb/01_raw_data_alignment.html#quality-control",
    "href": "nb/01_raw_data_alignment.html#quality-control",
    "title": "Raw data alignment",
    "section": "Quality Control",
    "text": "Quality Control\nWe run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis. You can find the report for each file into the folder results/fastqc_output/. The output is in HTML format and can be opened in any browser or in jupyterlab. It is however not easy to compare the various libraries by opening separate reports. To aggregate all the results, we apply the MultiQC software to the reports’ folder. The output of MultiQC is in the directory results/multiqc_output/fastqc_data.\n\n%%bash\n#run fastqc\nmkdir -p results/fastqc_output\nfastqc -q -o results/fastqc_output ../Data/Clover_Data/*.fastq  &gt; /dev/null 2&gt;&1\n\nNote: fastqc prints a lot of output conisting of a simple confirmation of execution without error, even when using the option -q, which means quiet. Therefore we added &gt; /dev/null 2&gt;&1 to the command to mute the printing of that output.\n\n%%bash\n#run multiqc\nmultiqc --outdir results/multiqc_output/fastqc_data results/fastqc_output\n\n\n  Questions  \n\nVisualize the Webpage generated by MultiQC.\nHint: You can find a Help button that offers additional information about the plots for each panel. Focus on the following panels: “Per base sequence quality”, “Per sequence quality scores”…. (“Per base sequence content” always gives a FAIL for RNA-seq data).\n\nWhat do you notice with respect to the sequence quality scores?\nAre there any other quality issues worth noting?"
  },
  {
    "objectID": "nb/01_raw_data_alignment.html#hifi-data-mapping",
    "href": "nb/01_raw_data_alignment.html#hifi-data-mapping",
    "title": "Raw data alignment",
    "section": "Hifi data mapping",
    "text": "Hifi data mapping\nWe map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contig1&2) using minimap2. We run two mapping rounds, using two different preset options (-x in the command) for the technology: * PacBio/Oxford Nanopore read to reference mapping: map-pb * Long assembly to reference mapping. Divergence is below 20%” settings asm20. Next, we create reports of the mapping results by running QualiMap on the two obtained SAM files.\nWe first need to index the reference fasta files using samtools faidx. This produces files in .fai format containing informations about length of the reference sequence, offset for the quality scores, name of the reference sequence. Click here for a detailed overview.\n\n%%bash\n#copy the reference data in the folder reference_data, so that you can write the indexing files\nmkdir -p reference_data\ncp ../Data/Clover_Data/DNA_Contig1_2.fasta ../Data/Clover_Data/DNA_Contig1.fasta ../Data/Clover_Data/DNA_Contig2.fasta reference_data\n\n\n%%bash\nsamtools faidx reference_data/DNA_Contig1_2.fasta\nsamtools faidx reference_data/DNA_Contig1.fasta\nsamtools faidx reference_data/DNA_Contig2.fasta\n\nwe create an output folder for the HIFI alignment, and run minimap2 with the settings explained before.\n\n%%bash \nmkdir -p results/HIFI_alignment/\nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sam \\\n                            reference_data/DNA_Contig1_2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq \n\nminimap2 -a -x asm20 -o results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sam \\\n                            reference_data/DNA_Contig1_2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\nsamtools sort is used to sort the alignment with left-to-right coordinates. The output is in .bam format, with .sam files in input (Note that you could have gotten .bam files from minimap2 with a specific option).\n\n%%bash\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sam \\\n                -o results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam\n\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sam \\\n                -o results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam\n\nsamtools index creates the index for the bam file, stored in .bai format. The index file lets programs access any position into the aligned data without reading the whole file, which would take too much time.\n\n%%bash\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam\n\nRun quality control on both files\n\n%%bash\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam \\\n                 -outdir results/qualimap_output/PacBio_clover_alignment_1_2_mappb\n\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam \\\n                 -outdir results/qualimap_output/PacBio_clover_alignment_1_2_asm20\n\nFor easier comparison, we can again collapse the two reports into a single one using MultiQC, in the same way we did for putting together the other reports from fastQC.\n\n%%bash\n\n#run multiqc\nmultiqc --outdir results/qualimap_output results/qualimap_output\n\nNow you can visualize the report generated, which is in results/qualimap_output/multiqc_report.html.\nNext, we map the white clover PacBio Hifi reads to contig1 and contig2 separately, using the setting you selected at the previous step (let’s say map-pb was chosen, but you are free to change this setting in the commands). As the two contigs represent the two white clover subgenomes, this mapping will allow you to see the two subgenome haplotypes and call subgenome SNPs.\n\n%%bash \nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1.sam \\\n                            reference_data/DNA_Contig1.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\n\n%%bash \nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_2.sam \\\n                            reference_data/DNA_Contig2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\nSort the bam files and create their index using samtools\n\n%%bash\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1.sam -o results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_2.sam -o results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam\n\n\n%%bash\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam\n\nPerform quality control\n\n%%bash\nmkdir -p results/qualimap_output\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam -outdir results/qualimap_output/PacBio_clover_alignment_1\n\n\n%%bash\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam -outdir results/qualimap_output/PacBio_clover_alignment_2\n\n\n%%bash\n\n#run multiqc\nmultiqc --outdir results/qualimap_output results/qualimap_output\n\n\n  Task: IGV visualization and Questions  \n\nNow you can inspect the alignment files in IGV.\n\nFirst, you will need to download the reference fasta sequence in ../Data/Clover_Data/DNA_Contig1_2.fasta and import it into IGV. You can do the same for the files DNA_Contig1.fasta and DNA_Contig2.fasta that you might need later. In IGV, this is done with the menu Genomes --&gt; Load Genome from file menu and by selecting the relevant fasta file. Then, choose the reference you need from the drop-down menu (see figure below).  You will not yet see much, but you can choose one of the two subgenomes (contig 1 or 2) and double click on a chromosome position to inspect the reference sequence. The next step will visualize the mapped files on IGV.\nEach mapped genome can be seen in IGV against the reference file of choice. To load an aligned file, first download it together with the index file in .bai format. For example, you need to download both results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam and results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam.bai to see this alignment (you need to open only the .bam file with IGV). If you open more files, their alignments will be distributed in the IGV interface, and you can change the size of each visualization yourself (below shown with only one opened alignment). \n\nNow compare in IGV the two bam files PacBio_clover_alignment_1.sort.bam and PacBio_clover_alignment_2.sort.bam.\n\nWhat do you observe when comparing the two BAM files?\nHave a look at the polymorphic regions in IGV. Are they true polymorphisms?\n\nAdd to the visualization the third alignment PacBio_clover_alignment_1_2_mappb.sort.bam in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences?"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor’s slides from 2022.\n\n\n\nTopic\nSlide\nNotebook\n\n\n\n\nSequencing technologies\nlink\n–\n\n\nMapping to reference\nlink\nNotebook\n\n\nData visualization\nlink\n–\n\n\nSNPs and structural variants\nlink\nNotebook\n\n\nRNA sequencing\nlink\nNotebook\n\n\nDe-novo assembly\nlink\n–\n\n\nMicrobiomes and metagenomics\nlink\n–\n\n\nSingle cell RNA sequencing\nlink\nNotebook\n\n\n\n\n\n\nHere you find a table with the instructor’s slides and a link to the compiled notebooks, that you can also run on your own following the instructions in this webpage. Data alignment can also be performed on the Galaxy interactive webpage (see the galaxy exercise in this webpage)."
  },
  {
    "objectID": "slides.html#course-material-2022",
    "href": "slides.html#course-material-2022",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor’s slides from 2022.\n\n\n\nTopic\nSlide\nNotebook\n\n\n\n\nSequencing technologies\nlink\n–\n\n\nMapping to reference\nlink\nNotebook\n\n\nData visualization\nlink\n–\n\n\nSNPs and structural variants\nlink\nNotebook\n\n\nRNA sequencing\nlink\nNotebook\n\n\nDe-novo assembly\nlink\n–\n\n\nMicrobiomes and metagenomics\nlink\n–\n\n\nSingle cell RNA sequencing\nlink\nNotebook"
  },
  {
    "objectID": "slides.html#course-material-2024",
    "href": "slides.html#course-material-2024",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor’s slides and a link to the compiled notebooks, that you can also run on your own following the instructions in this webpage. Data alignment can also be performed on the Galaxy interactive webpage (see the galaxy exercise in this webpage)."
  },
  {
    "objectID": "access/genomedk.html",
    "href": "access/genomedk.html",
    "title": "Accessing the NGS summer school on GenomeDK",
    "section": "",
    "text": "If you are using GenomeDK, you have two options. One is to use a pre-packaged Docker container, which contains jupyterlab and the necessary packages to run all the notebooks. GenomeDK comes with singularity, which can import and execute Docker containers and is able to ensure full reproducibility of the analysis. The second option is to download the github repository of the course and create your own conda environment: this solution works also on any computing cluster where you can have conda installed and is shown in the page dedicate to the access with any computing cluster."
  },
  {
    "objectID": "access/genomedk.html#singularity-container",
    "href": "access/genomedk.html#singularity-container",
    "title": "Accessing the NGS summer school on GenomeDK",
    "section": "Singularity container",
    "text": "Singularity container\n1. Log into the cluster using the command line, and substituting USERNAME with your actual user name:\nssh USERNAME@login.genome.au.dk\nand be sure to run those two commands to remove space-filling cache data, which can make everything slower after a few times you run tutorials\n\nrm -rf ~/.apptainer/cache/*\nrm -rf ~/.singularity/cache/*\n2. Get into a folder inside your project, for example\n\ncd MYPROJECT/ngsSummerSchool\n\n\n\n\n\n\nWarning\n\n\n\nDo not work directly in your home folder /home/username, as this has a limit of 100GB of space available. Work instead inside a previously established project folder.\n\n\n3. Use singularity to download the container of the course. This will take some time and show a lot of text, and at the end a file called course.sif is created into the folder.\n\nsingularity pull course.sif docker://hdssandbox/ngssummerschool:2024.07\n\n\n\n\n\n\nWarning\n\n\n\nYou need to do this step only once!\n\n\n4. Activate tmux: this will make things run in backround. If you lose your internet connection, the course material will still be up and running when the connection is back on your pc! Use the command\n\ntmux\nThe command line will change a bit its aspect. Now it’s time to get a few resources to run all the material. We suggest one CPU and 32GB of RAM for the first three modules, and 2 CPUs and 64GB of RAM for the single-cell analysis. For the first configuration suggested, for example, you get resources using\n\n\nsrun --mem=32g --cores=1 --time=4:0:0  --account=MYPROJECT --pty /bin/bash\n\n\n\n\n\n\nNote\n\n\n\nNote you always need your project name, and you can also choose for how long you want the resources to be available to you. Asking for resources means waiting for some time in a queue before they are assigned.\nIn the example above time is 4 hours. After this time, whatever you are doing will be closed, so be sure to save your work in progress.\n\n\n5. execute the container with\nsingularity exec course.sif /bin/bash\nNote that the command line shows now Apptainer&gt; on its left. We are inside the container and the tools we need are now available into it.\n6. Now we need to run a configuration script, which will setup the last details and execute jupyterlab. If a folder called Data exists, it will not be downloaded again (also meaning that you can use our container with your own data folder for your own analysis in future)\ngit config --global http.sslVerify false\nwget -qO-  https://raw.githubusercontent.com/hds-sandbox/NGS_summer_course_Aarhus/docker/scripts/courseMaterial.sh | bash\n7. You will see a lot of messages, which is normal. At the end of the messages, you are provided two links looking as in the image below. Write down the node name and the user id highlighted in the circles.\n\nWrote down node and ID? Last step is to create a tunnel between your computer and genomeDK to be able to see jupyterlab in your browser. Now you need to use the node name and the user id you wrote down before! Open a new terminal window on your laptop and write\n\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nwhere you substitute USERID and NODENAME as you wrote down before, and then USERNAME is your account name on GenomeDK. For example ssh -L 6835:s21n81:6835 samuele@login.genome.au.dk according to the figure above for a user with name samuele.\n8. Open your browser and go to the address http://127.0.0.1:USERID/lab, where you need your user id again instead of USERID. For example http://127.0.0.1:6835/lab from the figure above. Jupyterlab opens in your browser.\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\n\n\n\n\n\nTip\n\n\n\nRight click on a notebook or a saved results file, and use the download option to save it locally on your computer.\n\n\n\nWhat if my internet connection drops?\nNow worries, tmux kept your material up and running. You only need a new terminal window to run the tunneling\n\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nas you did before, so you can continue working!\n\n\nRecovering the material from your previous session\nDo you want to work again on the course material, or recover some analysis? Everything is saved in the folder you were working in. Next time, follow the whole procedure again (without step number 3.) and you can be up and running the course in no time."
  },
  {
    "objectID": "access/UCloud.html",
    "href": "access/UCloud.html",
    "title": "Accessing the NGS summer school on UCloud",
    "section": "",
    "text": "1. User accounts on UCloud are enabled by university login credentials using WAYF (Where Are You From). Access the WAYF login portal with the button below here, and then find your affiliated university or institution using the search bar.\n \n\n UCloud Access - click here \n\n \n\n\n\n\n\n\nNGS summer school\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, click AFTER logging in on the button below. This will add you to a project on uCloud, where we have data and extra computing credit for the course. You should see a message on your browser where you have to accept the invitation to the project. The link expires 30 days after the course.\n \n\n Invite link for the course \n\n \n\n\n2. Once you are an approved user of UCloud, you are met with a dashboard interface as below. Here you can see a summary of the workspace you are using, like the hours of computing, the storage available, and other informations. The workspace you are working on is shown in the top-right corner (red circle). On the left side of the screen you have a toolbar menu.\n\n \n\n\n\n\n\n\nNGS summer school\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, choose the workspace NGS summer school.\n\n\n\n3. The left-side menu can be used to access the stored data, applications, running programs and settings. Use the Applications symbol (red circle) and click on the Health Science store (green circle).\n\n5. Your screen will show some apps falling in the Health Science subcategory. Click on the Genomics Sandbox application to open its settings.\n\n6. Choose any Job Name (Nr 1 in the figure below), how many hours you want to use for the job (Nr 2, choose at least 2 hours, you can increase this later), and how many CPUs (Nr 3, choose at least 4 CPUs for the first three exercises, but use at least 8 CPUs to run the single cell analysis). Select the Introduction to NGS Data Analysis as course (Nr 4). Then click on Submit (Nr 5).\n\n7. You will be waiting in a queue looking like this\n\n8. As soon as there are resources, you will have them available, and in a short time the course will be ready to run. The screen you get is in the image below. Here you can increase the number of hours you want the session to run (red circle), close the session (green circle) and open the interface for coding (blue circle)\n\n\n\n\n\n\n\nTip\n\n\n\nOnce you open the coding interface, it does not matter if you close the browser tab with the countdown timer. You can always access it again from the toolbar menu of uCloud. Simply click on jobs and choose your session from the list of running softwares:\n\n\n\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\nRecovering the material from your previous session\nIt would be annoying to start from scratch at each session, with all the analysis to be executed again. You can of course find all the notebooks and results in your personal user folder in the workspace in which you are working.\nTo retrieve your work add the folders Data and Notebooks in the submission page of the Genomics App. Those are inside your user folder (called member Files: NameSurname#Number) under Jobs/Genomics Sandbox/SessionName. For example, look at how the Data folder is added from a previous session:\n\nYou need to do the same thing for the folder Notebooks. In the end you should have two folders added in your setup page just as below:"
  },
  {
    "objectID": "access/index.html",
    "href": "access/index.html",
    "title": "HPC access",
    "section": "",
    "text": "The Sandbox is collaborating with the two major academic high performance computing platforms in Denmark. Computerome is located at the Technical University of Denmark (and co-owned by the University of Copenhagen) while UCloud is owned by the University of Southern Denmark. These HPC platforms each have their own strengths which we leverage in the Sandbox in different ways."
  },
  {
    "objectID": "access/index.html#ucloud",
    "href": "access/index.html#ucloud",
    "title": "HPC access",
    "section": "UCloud",
    "text": "UCloud\nUCloud is a relatively new HPC platform that can be accessed by students at Danish universities (via a WAYF university login). It has a user friendly graphical user interface that supports straightforward project, user, and resource management. UCloud provides access to many tools via selectable Apps matched with a range of flexible compute resources, and the Sandbox is deploying training modules in this form such that any UCloud user can easily access Sandbox materials independently. The Sandbox is also hosting workshops and training events on UCloud in conjunction with in-person training.\n\n\n\n\n\n\nAccess Sandbox Apps on UCloud\n\n\n\nFind detailed instructions on accessing Sandbox apps here via UCloud. Check out UCloud’s extensive user docs here."
  },
  {
    "objectID": "access/index.html#computerome",
    "href": "access/index.html#computerome",
    "title": "HPC access",
    "section": "Computerome",
    "text": "Computerome\nComputerome is the home of many sensitive health datasets via collaborations between DTU, KU, Rigshospitalet, and other major health sector players in the Capital Region of Denmark. Computerome has recently launched their secure cloud platform, DELPHI, and in collaboration with the Sandbox has built a Course Platform on the same backbone such that courses and training can be conducted in the same environment as real research would be performed in the secure cloud. The Sandbox is supporting courses in the Course Platform, but it is also available for independent use by educators at Danish universities. Please see their website for more information on independent use and pricing, and contact us if you’d like to collaborate on hosting a course on Computerome. We can help with tool installation, environment testing, and user support (ranging from using the environment to course content if we have Sandbox staff with matching expertise).\nParticipants in courses co-hosted by the Sandbox can check here for access instructions."
  },
  {
    "objectID": "access/index.html#genomedk",
    "href": "access/index.html#genomedk",
    "title": "HPC access",
    "section": "GenomeDK",
    "text": "GenomeDK\nIn development."
  },
  {
    "objectID": "access/index.html#any-other-computing-cluster",
    "href": "access/index.html#any-other-computing-cluster",
    "title": "HPC access",
    "section": "Any other computing cluster",
    "text": "Any other computing cluster\nIn development."
  },
  {
    "objectID": "access/index.html#your-local-pc",
    "href": "access/index.html#your-local-pc",
    "title": "HPC access",
    "section": "Your local PC",
    "text": "Your local PC\nIn development."
  },
  {
    "objectID": "access/ngssummer.html",
    "href": "access/ngssummer.html",
    "title": "Course days 2024 - access on GenomeDK",
    "section": "",
    "text": "For the course days we are using containers on GenomeDK to execute the analysis. A container includes jupyterlab (interface for coding) and the necessary packages to run all the code. GenomeDK comes with singularity, which can import and execute containers (made with Docker in this case) and is able to ensure full reproducibility of the analysis."
  },
  {
    "objectID": "access/ngssummer.html#singularity-container",
    "href": "access/ngssummer.html#singularity-container",
    "title": "Course days 2024 - access on GenomeDK",
    "section": "Singularity container",
    "text": "Singularity container\n1. Log into the cluster using the command line, and substituting USERNAME with your actual user name:\nssh USERNAME@login.genome.au.dk\nand be sure to run those two commands to remove space-filling cache data, which can make everything slower after a few times you run tutorials\nrm -rf ~/.apptainer/cache/*\nrm -rf ~/.singularity/cache/*\n2. Get into a folder inside the course project\ncd ngssummer2024/`whoami`\n\n\n\n\n\n\nWarning\n\n\n\nYou need to do this step only once!\n\n\n3. Activate tmux: this will make things run in backround. If you lose your internet connection, the course material will still be up and running when the connection is back on your pc! Use the command\ntmux\nThe command line will change a bit its aspect. Now it’s time to get a few resources to run all the material. We suggest one CPU and 32GB of RAM for the first three modules, and 2 CPUs and 64GB of RAM for the single-cell analysis. For the first configuration suggested, for example, you get resources using\nsrun --mem=32g --cores=1 --time=4:0:0  --account=ngssummer2024 --pty /bin/bash\n\n\n\n\n\n\nNote\n\n\n\nYou can also choose for how long you want the resources to be available to you. Asking for more resources means waiting for longer time in a queue before they are assigned.\nIn the example above time is 4 hours. After this time, whatever you are doing will be closed, so be sure to save your work in progress.\n\n\n4. execute the container with\nsingularity exec course.sif /bin/bash\nNote that the command line shows now Apptainer&gt; on its left. We are inside the container and the tools we need are now available into it.\n5. Now we need to run a configuration script, which will setup the last details and execute jupyterlab. If a folder called Data exists, it will not be downloaded again (also meaning that you can use our container with your own data folder for your own analysis in future)\ngit config --global http.sslVerify false\nwget -qO-  https://raw.githubusercontent.com/hds-sandbox/NGS_summer_course_Aarhus/docker/scripts/courseMaterial.sh | bash\n6. You will see a lot of messages, which is normal. At the end of the messages, you are provided two links looking as in the image below. Write down the node name and the user id highlighted in the circles.\n\nWrote down node and ID? Last step is to create a tunnel between your computer and genomeDK to be able to see jupyterlab in your browser. Now you need to use the node name and the user id you wrote down before! Open a new terminal window on your laptop and write\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nwhere you substitute USERID and NODENAME as you wrote down before, and then USERNAME is your account name on GenomeDK. For example ssh -L 6835:s21n81:6835 samuele@login.genome.au.dk according to the figure above for a user with name samuele.\n7. Open your browser and go to the address http://127.0.0.1:USERID/lab, where you need your user id again instead of USERID. For example http://127.0.0.1:6835/lab from the figure above. Jupyterlab opens in your browser.\n8. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\n\n\n\n\n\nTip\n\n\n\nRight click on a notebook or a saved results file, and use the download option to save it locally on your computer.\n\n\n\nWhat if my internet connection drops?\nNow worries, tmux kept your material up and running. You only need a new terminal window to run the tunneling\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nas you did before, so you can continue working.\n\n\n\n\n\n\nTip\n\n\n\nPress the up-arrow key in the terminal to see the last command you used, such as the tunneling command, and press enter to use it again\n\n\n\n\nRecovering the material from your previous session\nDo you want to work again on the course material, or recover some analysis? Everything is saved in the folder you were working in. Next time, follow the whole procedure again (without step number 3.) and you can be up and running the course in no time."
  },
  {
    "objectID": "nb/02_VCF_variant_calling_analysis.html",
    "href": "nb/02_VCF_variant_calling_analysis.html",
    "title": "Variant calling and VCF files",
    "section": "",
    "text": "Tutorial description\n\n\n\nThis tutorial will cover the steps for performing Variant calling and working on the resulting VCF file format. We will be using the Hifi and RNA-seq mapping data obtained from Galaxy. At the end of this tutorial you will be able to:\n\ncall variants using alignment files\nextract data from VCF files using Python\nfilter and count variants\nThe present tutorial, like the rest of the course material, is available at our open-source github repository.\nTo use this notebook, use the NGS (python) kernel that contains the packages. Choose it by selecting Kernel -&gt; Change Kernel in the menu on top of the window.\nImport the necessary Python libraries:\nimport pandas\nimport allel\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSome of the commands used in the course are functions we implement to simplify reading the code of this course. Mostly, those are commands requiring lines of code that would not add anything to your learning curve (management of plots, trivial calculations, few management of the notebook layout). However, you are free to look at the code into the file Scripts/pythonScripts.py and to reuse our code in your own work (citing our course).\n%run ../Scripts/pythonScripts.py\nCreate a folder for the data necessary to VCF data analysis\n%%bash\nmkdir -p Data_for_VCF_analysis"
  },
  {
    "objectID": "nb/02_VCF_variant_calling_analysis.html#call-subgenome-snps-using-the-hifi-alignments-and-the-reference-genome",
    "href": "nb/02_VCF_variant_calling_analysis.html#call-subgenome-snps-using-the-hifi-alignments-and-the-reference-genome",
    "title": "Variant calling and VCF files",
    "section": "Call subgenome SNPs using the Hifi alignments and the reference genome",
    "text": "Call subgenome SNPs using the Hifi alignments and the reference genome\nWe will use the bcftools software to call SNPs from alignment files. bcftools is a toolkit for variant calling and manipulating VCF files. If you are interested, you can find all the functionalities here http://samtools.github.io/bcftools/bcftools.html#call.\nWe mainly need two commands for this step, first bcftools mpileup which takes as input the alignment and the genome reference files, followed by bcftools call to produce VCF files.\nThe cell below will generate 3 VCF files stored in the folder results/VCF_Files using the Hifi alignment files uploaded from Galaxy.\n\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_1.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_1.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_2.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_2.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_1_2.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_1_2.vcf\n\n\n  TASK  \n\n\nInspect the VCF files using IGV, comparing them to the specific alignment BAM files. (You can download the VCF files to your computer from the results/VCF_Files folder)\nAre there any problematic positions that may not represent true SNPs?\nHow can you use the HiFi reads aligned to Contigs1+2 identify potential problems?\n\nHint: Try scrolling to the ends of the contigs."
  },
  {
    "objectID": "nb/02_VCF_variant_calling_analysis.html#call-snps-using-the-two-rna-seq-genotypes-s10-and-ti",
    "href": "nb/02_VCF_variant_calling_analysis.html#call-snps-using-the-two-rna-seq-genotypes-s10-and-ti",
    "title": "Variant calling and VCF files",
    "section": "Call SNPs using the two RNA-seq genotypes, S10 and Ti",
    "text": "Call SNPs using the two RNA-seq genotypes, S10 and Ti\nWe will repeat the same step as above this time using the RNA-seq alignment files for the two white clover genotypes (S10 and Ti). These commands will produce another two VCF files, stored in the same folder.\n\n!bcftools mpileup --threads 4 -Ou --skip-indels -f reference_data/DNA_Contig1_2.fasta Data_for_VCF_analysis/RNA_S10_merged.bam | bcftools call -mv -Ov -o results/VCF_Files/RNA_S10_merged.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f reference_data/DNA_Contig1_2.fasta Data_for_VCF_analysis/RNA_TI_merged.bam | bcftools call -mv -Ov -o results/VCF_Files/RNA_TI_merged.vcf\n\n\n  TASK  \n\n\nInspect one of the VCFs and the corresponding alignment files in IGV.\nIs it relevant to filter for false positives in this case, and what parameters would you look further into?"
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html",
    "href": "nb/04_scRNAseq_analysis.html",
    "title": "Single cell analysis workflow",
    "section": "",
    "text": "Tutorial description\n\n\n\nThis tutorial will cover the basic steps of single cell analysis from preprocessing to the final results production. at the end of this tutorial you will be able to use python to\n\nFilter your data selecting specific criteria\nPreprocess your data for advanced analysis\nIdentify potential cell types\nPerform differential gene expression\nVisualize the basic differentiation dynamics of your data\nMerge datasets and do cross-data analysis\nThe present tutorial, like the rest of the course material, is available at our open-source github repository and will be kept up-to-date as long as the course will be renewed.\nTo use this notebook, use the NGS (python) kernel that contains the packages. Choose it by selecting Kernel -&gt; Change Kernel in the menu on top of the window."
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#the-raw-data-in-practice",
    "href": "nb/04_scRNAseq_analysis.html#the-raw-data-in-practice",
    "title": "Single cell analysis workflow",
    "section": "The raw data in practice",
    "text": "The raw data in practice\nLet’s look at a specific read and its UMI and cell barcode. The data is organized in paired-end reads (written on fastq files), where the first fastq file contains reads in the following format\n@SRR8363305.1 1 length=26\nNTGAAGTGTTAAGACAAGCGTGAACT\n+SRR8363305.1 1 length=26\n#AAFFJJJJJJJJJJJJJJJJFJJJJ\nHere, the first 16 characters NTGAAGTGTTAAGACA represent the cell barcode, while the last 10 characters AGCGTGAACT are the transcript UMI tag. The last line represents the quality scores of the 26 characters of barcode+UMI.\nThe associated second fastq file contains reads of 98nt as the following\n@SRR8363305.1 1 length=98\nNCTAAAGATCACACTAAGGCAACTCATGGAGGGGTCTTCAAAGACCTTGCAAGAAGTACTAACTATGGAGTATCGGCTAAGTCAANCNTGTATGAGAT\n+SRR8363305.1 1 length=98\n#A&lt;77AFJJFAAAJJJ7-7-&lt;7FJ-7----&lt;77--7FAAA--&lt;JFFF-7--7&lt;&lt;-F77---FF---7-7A-777777A-&lt;-7---#-#A-7-7--7--\nThe 98nt-long string of characters in the second line is a partial sequence of the cDNA transcript. Specifically, the 10X chromium protocol used for sequencing the data is biased towards the 3’ end, because the sequencing happens from the 3’ to the 5’ end of the transcripts. The last line contains the corresponding quality scores."
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#alignment-and-expression-matrix",
    "href": "nb/04_scRNAseq_analysis.html#alignment-and-expression-matrix",
    "title": "Single cell analysis workflow",
    "section": "Alignment and expression matrix",
    "text": "Alignment and expression matrix\nOnce the data is sequenced, it is possible to align the reads to the transcriptome. This is done with tools that are sensible to the presence of spliced transcripts. We will skip the alignment step because it is quite trivial (it requires a pipeline implemented by 10X if you are using 10X data, otherwise you can use one of the available pipelines available on NextFlow), and because it would require too much time and memory for the scope of a one-day tutorial. Instead, we start from the transcript count matrix that results as the output from the transcriptome alignment."
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#preprocessing",
    "href": "nb/04_scRNAseq_analysis.html#preprocessing",
    "title": "Single cell analysis workflow",
    "section": "Preprocessing",
    "text": "Preprocessing\nWe preprocess the dataset by filtering cells and genes according to various quality measures and removing doublets. Note that we are working with all the samples at once. It is more correct to filter one sample at a time, and then merge them together prior to normalization, but we are keeping the samples merged for simplicity, and because the various samples are technically quite homogeneous.\n\nQuality Filtering\nUsing the prefix MT- in the gene names we calculate the percentage of mithocondrial genes in each cell, and store this value as an observation in adata.obs. Cells with high MT percentage are often broken cells that spilled out mithocondrial content (in this case they will often have low gene and transcript counts), cells captured together with residuals of broken cells (more unlikely if a good job in the sequencing lab has been done) or empty droplets containing only ambient RNA.\n\nMT = ['MT-' in i for i in adata.var_names] #a vector with True and False to find MT genes\nperc_mito = np.sum( adata[:,MT].X, 1 ).A1 / np.sum( adata.X, 1 ).A1\nadata.obs['perc_mito'] = perc_mito.copy()\n\nOne can identify cells to be filtered out by looking at the relation between number of transcripts (horizontal axis) and number of genes per cell (vertical axis), coloured by percent of MT genes. We can see that high percentages of mitocondrial genes are present for cells that have less than 1000 detected genes (vertical axis).\n\nsc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='perc_mito', \n              title='Transcript vs detected genes coloured by mitochondrial content')\n\nWe can zoom into the plot by selecting cells with less than 3000 genes\n\nsc.pl.scatter(adata[adata.obs['n_genes_by_counts']&lt;3000], x='total_counts', y='n_genes_by_counts', color='perc_mito',\n             title='Transcript vs detected genes coloured by mitochondrial content\\nfor &lt;3000 genes')\n\nAnother useful visualization is the distribution of each quality feature of the data. We look at the amount of transcripts per cell zooming into the interval (0,20000) transcripts to find a lower threshold. Usually, there is a peak with low quality cells on the left side of the histogram, or a descending tail. The threshold whould select such peak (or tail). In our case we can select 2000 as threshold. Hover on the plots with the mouse to see the value of each bar of the histogram.\n\nfig = px.histogram(adata[adata.obs['total_counts']&lt;20000].obs, x='total_counts', nbins=100,\n                  title='distribution of total transcripts per cell for &lt;20000 transcripts')\nfig.show()\n\n                                                \n\n\nFor the upper threshold of the number of transcripts, we can choose 40000\n\nfig = px.histogram(adata.obs, x='total_counts', nbins=100, \n                   title='distribution of total transcripts per cell')\nfig.show()\n\n                                                \n\n\nRegarding the number of detected genes, a lower threshold could be around 800 genes. An Upper threshold can be 8000 genes, to remove the tail on the right side of the histogram\n\nfig = px.histogram(adata.obs, x='n_genes_by_counts', nbins=100, title='distribution of detected genes per cell')\nfig.show()\n\n                                                \n\n\nCells with too much mitochondrial content might be broken cells spilling out MT content, or ambient noise captured into the droplet. Standard values of the threshold are between 5% and 20%. We select 20%.\n\nfig = px.histogram(adata.obs, x='perc_mito', nbins=100, title='distribution of mitochondrial content per cell')\nfig.show()\n\n                                                \n\n\nFinally, we look at the percentage of transcripts expressing genes in each cell. We plot the genes showing the highest percentages in a barplot. We can see MALAT1 is expressed in up to 60% of the transcripts in some cells. This can be an indicator of cells with too low quality. Other genes that are highly expressed are of the mitocondrial type and will be filtered out already with the mitochondrial threshold. PRM1, PRM2, PTGDS are typical of spermatogonial processes, and we do not consider those as unusual.\nThe expression matrix is in compressed format (a so-called sparse matrix), but from now on we will need only the uncompressed matrix. We made a little function to decompress the matrix (array_and_densify).\n\nadata.X = array_and_densify(adata.X)\n\ndensified\n\n\n\n%matplotlib inline\n\nfig, ax = plt.subplots(1,1)\nax.set_title('Top genes in terms of percentage of transcripts explained in each cell')\nfig = sc.pl.highest_expr_genes(adata, n_top=20, ax=ax)\nfig\n\n\n\n\n\n\n\n\nWe save the percentages of transcripts expressing MALAT1 and select a threshold for this values. We choose 10% as threshold to cut out the upper tail.\n\nperc_malat = np.sum( adata[:,'MALAT1'].X, 1 ) / np.sum( adata.X, 1 )\nadata.obs['perc_MALAT1'] = perc_malat.copy()\n\n\nfig = px.histogram(adata.obs, x='perc_MALAT1', nbins=100, title='Distribution of the amount of MALAT1 transcripts in each cell')\nfig.show()\n\n                                                \n\n\nNote also how cells with high amount of MALAT1 expression are usually cells of low quality, containing a low amount of transcripts (position the mouse on some of the dots to see the values). This means that many of the cells with high content of MALAT1 will be also filtered out when removing cells with low amount of transcripts. This is compatible with the fact that MALAT1 can indicate dead cells who underwent apoptosis.\n\npx.scatter(data_frame=adata.obs, x='total_counts', y='perc_MALAT1', \n           title='Relationship between amount of MALAT1 gene and transcripts per cell')\n\n                                                \n\n\nWe use the following commands to implement some of the thresholds discussed in the plots above\n\nsc.preprocessing.filter_cells(adata, max_genes=8000)\n\n\nsc.preprocessing.filter_cells(adata, min_genes=800)\n\n\nsc.preprocessing.filter_cells(adata, max_counts=40000)\n\n\nadata = adata[adata.obs['perc_mito']&lt;0.2].copy()\n\n\nadata = adata[adata.obs['perc_MALAT1']&lt;0.1].copy()\n\nIt is good practice to also remove those genes found in too few cells (for example in 10 or less cells). Any cell type clustering 10 or less cells will be undetected in the data, but in any case it would be irrelevant to have such tiny clusters, since statistical analysis on those would be unreliable.\n\nsc.preprocessing.filter_genes(adata, min_cells=10)\n\n\nprint('There are now', adata.shape[0], 'cells and', adata.shape[1],'genes after filtering')\n\nThere are now 49243 cells and 29830 genes after filtering\n\n\n\n\nDoublets removal\nAnother important step consists in filtering out multiplets. We will use the package scrublet (Wolock et al, 2019), that simulates doublets from the data and compare the simulations to the real data to find any doublet-like cells in it.\n\n\n\nFigure: schematics of the scrublet algorithm, from the related paper.\n\n&lt;/figure&gt;\n\n\n\nFigure: doublet rates for various setting in a single cell experiment with 10X technology.\n\n&lt;/figure&gt;\n\n\n\n\n\n\nNote\n\n\n\nMultiplets are in the almost totality of the cases doublets, because triplets and higher multiplets are extremely rare. We will thus talk only about doublets instead of multiplets. Read this more technical blog post for deeper explanations about this fact.\nAs a rule of thumb, you can have a look at this table to see what is the expected amount of doublets rate for different amounts of cells loaded in a single cell 10X experiment. In our case, each sample ranges somewhere between 3000 and 5000 cells, meaning there were somewhere between 8000 and 10000 loaded cells in each experiment (assuming efficiency of cell capture between 50% and 70%), so one could use 6-8% as a guess.\n\n\n\nFigure: doublet rates for various setting in a single cell experiment with 10X technology.\n\n\nBelow, we run the detection and obtain a score between 0 and 1 for each doublet. We will use that score for filtering\n\nimport scrublet\nscrub = scrublet.Scrublet(adata.X, expected_doublet_rate=0.08, random_state=123,  )\ndoublet_score, _ = scrub.scrub_doublets(verbose=True)\n\nPreprocessing...\nSimulating doublets...\nEmbedding transcriptomes using PCA...\nCalculating doublet scores...\nAutomatically set threshold at doublet score = 0.36\nDetected doublet rate = 1.5%\nEstimated detectable doublet fraction = 57.3%\nOverall doublet rate:\n    Expected   = 8.0%\n    Estimated  = 2.5%\nElapsed time: 120.3 seconds\n\n\nWe gave 8% as expected doublet rate, but note how the algorithm estimated that the doublet rate is estimated to be actually 2-3%. Not far away from what one could guess using the doublet rates’ table, meaning that, in this regard, the data has been produced pretty well.\nWe now plot the doublet scores assigned to each cell by the algorithm. We can see that most cells have a low score (the score is a value between 0 and 1, where 1 is a theoretically perfect doublet). Datasets with many doublets show a more bimodal distribution (look for example at this jupyter notebook from the scrublet tutorial), while here we just have a light tail beyond 0.1. Therefore we will filter out the cells above this threshold\n\nfig = px.histogram(adata.obs, x=doublet_score, title='Distribution of doublet scores per cell')\nfig.show()\n\n                                                \n\n\n\nadata = adata[ doublet_score &lt; .1 ].copy()\n\n\nData Normalization\nBiologically similar cells are not necessarily directly comparable in a dataset because of different technical biases - amongst many the different percentage of captured transcripts (capture efficiency), the presence of technical replicates, the presence of noisy transcripts. The capture efficiency can be influenced by many factors, i.e. the different transcript tags leading to different capture efficiency, the type of protocol used in the laboratory, the amount of PCR performed on different transcripts. Biological biases might as well alter the transcript proportion in a cell, for example in case of different points in the cell cycles altering the expression of specific genes.\nTo avoid these differences, a normalization approach is needed. Normalization is one of the main topics of scRNAseq data preprocessing, and many advanced techniques take into account the statistical distribution of counts and the presence of technical/biological features of interest (Lytal et al, 2020).\nThe most standard approach is the TMP (Transcript Per Million) normalization. Here, the transcripts is each cell are rescaled by a factor such that each cell has the same number of transcripts. After TPM rescaling, the data is usually logarithmized, so that a transcript \\(x\\) becomes \\(log(x+1)\\). Logarithmization is known to help reducing the technical bias induced by the amount of transcripts in each cell. Finally, the data is standardized with mean 0 and variance 1. This is necessary since the PCA assumes implicitly that datapoints are normally distributed.\nAs a rule of thumb, TPM works fine but might introduce biases in the data, mostly due to technical differences that are not always removed by normalization. It is possible to use more advanced methods for considering technical and biological covariates as part of a statistical model for the transcripts. One of the current state-of-the-art method is scTransform (Hafemeister and Satija, 2019). This is currently implemented in R.\n\n\nEffect of normalization on technical features\nBefore normalizing we look at the highest correlation between the PCA of the raw data and some technical features. The first component of the PCA has the highest \\(R^2\\) when correlated with the total amount of transcripts. PC5 is mostly correlated with the amount of mitochondrial transcripts. This means that the two PC components mostly describe variations in the technical features and misses the description of biological variation. We will see after normalization that these correlations are reduced. Note that we are plotting the correlations for one specific sample, Guo1, but the concept holds for the remaining samples.\n\nsc.preprocessing.pca(adata, svd_solver='arpack', random_state=12345)\ndependentFeatures(adata=adata[adata.obs['batch']=='Guo1'], obs_subset=['total_counts','perc_mito'])\n\n\n\n\n\n\n\n\n###\n\n  Optional task  \n\nTry to look at other samples and see if there are some principal components highly dependent with technical features. You might also want to choose other technical features from the data.\nThe available samples are\n\nprint( list(adata.obs['batch'].cat.categories) )\n\n['Sohni1_und', 'Sohni2_und', 'Sohni1_I', 'Sohni2_I', 'Guo1', 'Guo2', 'Guo3', 'Her1_Spg', 'Her2_Spg', 'Her3_Spg', 'Her4', 'Her5', 'Her6', 'Her7_Spt', 'Her8_Spc']\n\n\nand the technical features\n\nprint( list( adata.obs.columns ) )\n\n['batch', 'super_batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'n_counts', 'perc_mito', 'perc_MALAT1', 'n_genes']\n\n\n\ndependentFeatures(adata=adata[adata.obs['batch'] == ''], #sample name\n                  obs_subset=['total_counts','perc_mito']) #technical features\n\n\n\n\n\n\n\n\n\n  End of optional task  \n\nHere we execute the normalization steps. We use the standard TPM normalization and evaluate the result looking at the data projections later on - our datasets are of very good quality, so there will be no problems with the simple TMP normalization. We select also the most variable genes to avoid considering genes that have very constant expression across all the dataset, and are therefore not informative. The most variable genes are used to create the PCA projection of the data, and we can use them also in other parts of the analysis.\nWhen doing normalization, we also want to choose the amount of most variable genes. To do so, we plot the histogram of each gene’s variance, choose a threshold and see how many genes go above that threshold.\n\nvariance = np.ravel(np.log1p(np.var(adata.X, axis=0)))\npx.histogram(variance, title='Log-variance of each gene')\n\n                                                \n\n\nWe zoom between 0 and 1, from which we can see decide to set a minimum threshold of 0.05, since we can also see that around 13000 genes have the three smallest variance values in the histograms. 0.05 is the threshold above those bars. There will be around 15000 genes with a variance above 0.05. Keep in mind this value, you will see it is used in the normalization step. Using the most variable genes is useful to avoid noise from genes which do not vary along the data when calculating PCA.\n\npx.histogram(variance, range_x=(0,1), nbins=1000, title='Log-variance of each gene (zoom up to 1)')\n\n                                                \n\n\n\nprint(f'{sum(variance&gt;0.05)} genes have a variance above 0.05')\n\n14956 genes have a variance above 0.05\n\n\nFinally! Now we can normalize, label the 15000 most variable genes and scale the data\n\n# save raw data matrix\nadata.layers['raw_counts'] = adata.X.copy()\n# TPM normalization\nsc.pp.normalize_per_cell(adata)\n# matrix logarithmization\nsc.pp.log1p(adata)\n# most variable genes\nsc.pp.highly_variable_genes(adata, n_top_genes=15000)\n#scale\nsc.pp.scale(adata)\nadata.layers['scaled_counts'] = adata.X.copy()\n\nAfter normalization the linear correlations with technical features are visibly much reduced.\n\nsc.preprocessing.pca(adata, svd_solver='arpack', random_state=123, use_highly_variable=True)\ndependentFeatures(adata=adata[adata.obs['batch']=='Guo1'], obs_subset=['total_counts','perc_mito'])\n\n\n\n\n\n\n\n\n\n\nDimensionality reduction\nWith the term dimensionality reduction, we intend the projection of each data point (cell) x=[x_1, x_2, , x_{N_{cell}}] into a data point \\(y\\) in \\(D\\) dimensions, so that \\(y=[y_1, y_2, \\dots, y_D]\\), where \\(D &lt;&lt; N_{cell}\\).\nDimensionality reduction is meaningful for single cell data analysis, since we know that the genes are expressed in modules of co-expression, meaning that the behaviour of many co-expressed genes can be compressed into the same dimension.\nMoreover, using computationally heavy algorithms on the reduced data will help speeding up calculations and reduce memory use, though using a reliable approximation of the full-dimension dataset.\n\n\nPCA\nPCA is one of the most used dimensionality reduction methods. It projects the data by identifying the axis of maximum variation. Since axis are orthogonal, PCA is best for data that has a linear behaviour. However, it has proved to be a reliable method for single cell data, especially to establish the PCA projection as the starting point for computational methods. We calculated the PCA already few lines above, when we checked the correlation with technical variables after normalization.\nYou can visualize the ratio of variances of each subsequent pair of principal components, where you can see which number of dimensions is best to consider for further applications. Low variance ratios illustrate that along their principal components only little information is represented, probably mostly backgound noise of the dataset. Here we can for example say that 15 dimensions mostly explain the meaningful biological variation in the data. We will use the option n_pcs=15 in some of the functions of scanpy that are based on the PCA.\n\nsc.plotting.pca_variance_ratio(adata)\n\n\n\n\n\n\n\n\nYou can plot any dimensionality reduction and colour cells by elements of adata.obs or by gene expression. Below we plot the PCA coloured by different samples composing the dataset, the total number of transcripts and the expression of gene SYCP1. Note how the various samples overlap into the PCA plot. In some cases you can see that the PCA plot is composed of chunks separated by sample, but fortunately this is not our situation.\nIn such case more advanced techniques for normalization are needed, so that the samples are taken into account. Scanpy has the function sc.pp.combat to normalize accounting samples, but there are many other possibilities such as the package mnnCorrect.\n\nplt.rcParams['figure.figsize'] = (6,6) #reduce figure size\nsc.pl.pca(adata, color=['batch','total_counts','SYCP1'])\n\n\n\n\n\n\n\n\n\n\nUMAP projection\nUMAP (McInnes et al, 2018) is another projection algorithm that finds the optimal formulation of the projection criteria according to some topological theory, aiming at preserving the structure of the high-dimensional graph describing the data. This projection technique has become one of the most used and appreciated, and is structured in a way that calculations are faster than in other algorithms, and scale less than exponentially with the number of dimensions. Explore this “paper with code” to learn about UMAP and its extension applied to neural networks. UMAP has also a manual page with other examples in python.\n\nWe calculate first the neighborhood of each cell (the distance between the most similar cells). We use the package bbknn to take samples into account and reduce any remaining difference between samples, even though we can see a good overlapping in the PCA plot. In case you haven’t multiple samples, you can use the function sc.pp.neighbors. Note that we impose the use of 15 PCA components.\n\nbbknn.bbknn(adata, n_pcs=15)\n\nWe calculate and plot the UMAP projection. We calculate three components, so we can also produce a 3d plot. The parameters a and b can be used to strech and compress the projection. Usually they are decided automatically, but you can play with values around 1 to find the plot that is fanciest to you. You are welcome to try various combinations and keep the one you prefere.\n\nsc.tools.umap(adata, random_state=12345, n_components=3, a=.9, b=.9)\n\nThe plot is made for different pairs of dimensions (1,2 - 1,3 - 2,3) and coloured by a single gene expressed in spermatids. You can observe how there are some smaller clusters separated from a main block of cells looking like a long “snake”. Note also that clusters that seem close to each other, might actually end up being far away when rotating our point of view.\n\nsc.plotting.umap(adata, color=['TNP2'], components=['1,2','1,3','2,3'])\n\n\n\n\n\n\n\n\nWe can look better at the projection in 3D. Here the colour represents the total transcripts per cell. The main group of cells seems twisting at least twice without overlapping, but we do not see any branching. This might mean that there is only one differentiation path. Use the mouse to rotate and zoom in and out the interactive plot.\n\nX = adata.obsm['X_umap']\nfig = px.scatter_3d(adata.obsm, x=X[:,0], y=X[:,1], z=X[:,2], color=adata.obs['total_counts'], opacity=.5, height=800)\nfig.show()\n\n                                                \n\n\nWe can also colour by a specific gene. Try any gene you want (inserted here instead of TNP2)\n\nX = adata.obsm['X_umap']\nfig = px.scatter_3d(adata.obsm, x=X[:,0], y=X[:,1], z=X[:,2], color=np.ravel(adata[:,'TNP2'].X), height=1000)\nfig.show()\n\n                                                \n\n\nYou can also use a standard plotting command to visualize the 3d plot, but it cannot be rotated interactively\n\nsc.plotting.umap(adata, color=['TNP2'], projection='3d', components=['1,2,3'] )\n\n\n\n\n\n\n\n\n###\n\n  Exercise: tSNE projection  \n\nPCA and UMAP are two of the many projection methods available at the moment. Before UMAP, a very popular method was (and still is) tSNE van der Maaten and Hinton, 2008. tSNE tries to match the statistical distribution of the high-dimensional data and its projection. The statistical distribution modeling high-dimensional data is Cryptoled by a parameter called perplexity, defining how far away cells are considered to be in the neighbourhood of a cell. The largest the perplexity, the farther away cells are going to be pulled close to each other in the tSNE projection. In general, tSNE is not very good at keeping the global behaviour of the data into account, while it often pulls cells together in separate chunks.\nChanging the perplexity can change a lot the output of tSNE, even though it has shown empirically being stable with values between 5 and 50. Here you can experiment different values of the perplexity and plot tSNE. You will see how - for lower perplexities - tSNE cannot keep the dataset together as in the UMAP projection, dividing it instead into many chunks covering a large 2D space. The tSNE algorithm is actually quite slow, especially with increasing perplexity, so we will subsample the dataset to be only 5000 cells. If you must wait too long to get the code executed, reduce this number even more.\nYou can also change the method measuring distances between points. The standard distance is euclidean, and you can change this parameter with cityblock, cosine, euclidean, l1, l2, manhattan, braycurtis, canberra, chebyshev, correlation, dice, hamming, jaccard, kulsinski, mahalanobis, minkowski, rogerstanimoto, russellrao, seuclidean, sokalmichener, sokalsneath, sqeuclidean, yule. Some of those distances are well-known for people handy with data science or mathematics, others are more obscure.\n\nYOUR_NAME = 'WRITE YOUR NAME HERE'\nPERPLEXITY = 5\nDISTANCE_METRIC = 'euclidean'\n\n\nadata_sub = sc.pp.subsample(adata, random_state=54321, n_obs=5000, copy=True)\n\n\nsc.tools.tsne(adata_sub, random_state=54321, perplexity=PERPLEXITY, metric=f'{DISTANCE_METRIC}')\n\n\nsc.plotting.tsne(adata_sub, color=['batch'], legend_loc=None, frameon=False, title=f'{YOUR_NAME}\\nPerplexity={PERPLEXITY} Metrix={DISTANCE_METRIC}')\n\n\n\n\n\n\n\n\nThis saves the plot in the folder figures using your name, perplexity parameter and distance metric, so that you can save all your tSNE attempts.\n\nsc.plotting.tsne(adata_sub, color=['batch'], legend_loc=None, frameon=False, \n                 title=f'{YOUR_NAME}\\nPerplexity={PERPLEXITY} Metric={DISTANCE_METRIC}', show=False,  \n                 save=f'{YOUR_NAME}Perplexity={PERPLEXITY}Metric={DISTANCE_METRIC}.png')\n\nWARNING: saving figure to file figures/tsneWRITE YOUR NAME HEREPerplexity=5Metric=euclidean.png\n\n\n&lt;AxesSubplot: title={'center': 'WRITE YOUR NAME HERE\\nPerplexity=5 Metric=euclidean'}, xlabel='tSNE1', ylabel='tSNE2'&gt;\n\n\n\n\n\nClusters Identification\nCell types can be identified and then assigned to clusters calculated by one of the many available clustering techniques. When identifying a cluster, we can assign that to a likely cell type by visualizing known markers on a projection plot, e.g. an UMAP plot. Similarly, one can score cells for a set of markers. Finally, if an atlas of cell types is available, one can use it for a supervised assignment of cell types (see for example the R package scmap) and the ingest tool from scanpy.\nBe aware that clusters do not necessarily match perfectly cell types (especially if cells change in a continuous way, hard clusters are not the best solution, though an acceptable one).\n\nPrint markers’ scores\nThe first step to identify various cell types is to print markers on the UMAP plot. We will print markers’ scores, that is the average expression of a list of markers, subtracted of the average expression of some random genes. We provide a python dictionary including some cell types and a few of their marker genes.\nA dictionary is a python object in which you can allocate different objects (matrices, vectors, lists, …), each having an assigned name. Here, we have lists of marker genes, where each list is identified by the name of the corresponding cell type. To remember the different stages of spermatogenesis, a scheme is attached below, and you can read more about the spermatogenic process at this page\n\n\nmarkers = dict() #make an empty dictionary\n### SPERMATOCYTOGENESIS\nmarkers['SpermatogoniaA'] = ['ID4','HMGA1']\nmarkers['SpermatogoniaB'] = ['MKI67','DMRT1','STRA8'] \nmarkers['SpermatocytesI'] = ['MEIOB','PRSS50','SYCP1','TEX101']\nmarkers['SpermatocytesII'] = ['PIWIL1','ACRV1','SPATA16','CLGN']\n### SPERMIOGENESIS\nmarkers['Round.Spt'] = ['SPATA9','SPAM1'] #Round spermatids\nmarkers['Elong.Spt'] = ['PRM1','PRM2'] #Elongated spermatids\n### SOMATIC CELLS\nmarkers['Sertoli'] = ['CTSL', 'VIM']\nmarkers['Macroph'] = ['CD163','TYROBP']\nmarkers['Leydig'] = ['CFD']\nmarkers['Endothelial'] = ['CD34']\nmarkers['Myoid'] = ['ACTA2']\nmarkers['Smooth_Muscle'] = ['RGS5']\n\nWe calculate the scores for the markers\n\nmarkers_scores, adata = marker_score(markers, adata)\n\nMake a separate UMAP plot for every cell type. You should be able to see quite clearly some clusters where the marker’s expressions are stronger. Sertoli cells are usually hard to identify - their markers are expressed also in other cell types, and often Sertoli cells are not captured due to their size. It seems that there aren’t sertoli cells into our dataset.\n\nsc.plotting.umap(adata, color=markers_scores, components=['1,2'], ncols=2, vmax=5, s=30, cmap='Blues')\n\n\n\n\n\n\n\n\n\n\nLeiden clustering algorithm\nScanpy contains the leiden algorithm (Traag et al, 2019), making clusters whose points are well connected and at the same time mostly disconnected from other clusters. Other approaches, e.g. k-means, can be performed on the data or on its PCA/tSNE/UMAP projection. The leiden algorithm is however considered to be one of the best techniques at the moment to find communities of similar datapoints, and we will therefore use that. Read more about the leiden algorithm here.\n\n\n\nFigure: refinement steps used by the leiden algorithm to find communities of well-connected points.\n\n&lt;/figure&gt;\nWe calculate some clusterings at various resolution, and choose the one matching best the clusters we have visualized from the markers’ score. The amount of clusters depend on the chosen resolution. Later in this tutorial, we will integrate this dataset with another one, showing how to cluster the new data using ours as a “reference” clustering.\n\n#leiden clustering at various resolutions\nsc.tools.leiden(adata, resolution=1, random_state=12345, key_added='leiden_R1')\nsc.tools.leiden(adata, resolution=0.5, random_state=12345, key_added='leiden_R.5')\nsc.tools.leiden(adata, resolution=0.25, random_state=12345, key_added='leiden_R.25')\nsc.tools.leiden(adata, resolution=0.1, random_state=12345, key_added='leiden_R.1')\n\nWe can see that at resolution 1 we have many clusters, and their number decreases with decreasing resolution. We choose resolution 0.5 which has enough clusters to have a fine grained cell type assignment.\n\nsc.plotting.umap(adata, color=['leiden_R1','leiden_R.5','leiden_R.25', 'leiden_R.1'], legend_loc='on data', ncols=2)\n\n\n\n\n\n\n\n\n\n\nDifferential Gene expression\nIt is not always easy to assign clusters from marker scores. For example, cluster 12 at resolution 0.25 is not immediately recognizable as pericyte cells. Sometimes it is good to double check which genes are most expressed in a cluster compared to all the others before assigning cell types. Here we look at the 50 most expressed genes in each cluster from the Leiden algorithm.\nDifferential gene expression is also the way of making a sound argument in a publication or report. Showing fancy UMAP plots coloured by gene expression is sadly not enough :) A standard way to do it, is to test if each gene has mean expression higher in a cluster than in all the others. Scanpy does that by using a t-test or the wilcoxon test. While the t-test is somewhat less powerful, the wilcoxon test is not best behaved with very sparse data, so we simply apply the default t-test to the dataset. Note that, for the standard t-test in scanpy, you need to use logarithmized data.\nMore advanced techniques that model the statistical properties of the data, such as its sparsity, are available for differential expression. See for example the package MAST (Finak et al, 2015) and the following review on differential expression methods: (Squair et al, 2021).\n\n#Perform the test on logarithmized data\nadata.X = adata.layers['raw_counts'] #raw data\nsc.pp.normalize_total(adata) #TPM normalization\nsc.pp.log1p(adata) #logarithm\nsc.tl.rank_genes_groups(adata, groupby='leiden_R.5', n_genes=50) #Top 50 diff.expressed genes in each cluster\nadata.X = adata.layers['scaled_counts'] #Set again the scaled data as standard data matrix\n\nWARNING: adata.X seems to be already log-transformed.\n\n\nOrganize result in a table. Each column has the cluster numbers with _N, _P, _L representing respectively the gene Names, their P-values and the Log-fold change of each gene expression compared to the other clusters. Many clusters show markers typical of spermatogenesis processes (MYL9, TEX-genes, …)\n\nresult = adata.uns['rank_genes_groups']\ngroups = result['names'].dtype.names\nX = pd.DataFrame(\n    {group + '_' + key[:1].upper(): result[key][group]\n    for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\nX.head() #print only first five lines\n\n\n\n\n\n\n\n\n0_N\n0_P\n0_L\n1_N\n1_P\n1_L\n2_N\n2_P\n2_L\n3_N\n...\n13_L\n14_N\n14_P\n14_L\n15_N\n15_P\n15_L\n16_N\n16_P\n16_L\n\n\n\n\n0\nLYPLA1\n0.0\n2.635769\nZNF428\n0.0\n3.806565\nPTGDS\n0.0\n7.961807\nMT-CO2\n...\n8.849788\nANKRD7\n0.0\n5.520726\nTMSB4X\n0.0\n5.302206\nMALAT1\n0.000000e+00\n3.612107\n\n\n1\nSRSF9\n0.0\n2.288302\nHMGA1\n0.0\n3.570310\nIGFBP7\n0.0\n6.235969\nSBNO1\n...\n6.715557\nCMTM2\n0.0\n5.160422\nB2M\n0.0\n5.034176\nMYL9\n2.031513e-297\n6.074902\n\n\n2\nSMS\n0.0\n2.876471\nRPS12\n0.0\n2.645890\nACTA2\n0.0\n7.899968\nMT-CO1\n...\n5.880414\nTEX40\n0.0\n5.001250\nTMSB10\n0.0\n4.341215\nCALD1\n9.825148e-295\n4.660460\n\n\n3\nHMGA1\n0.0\n2.629156\nRAC3\n0.0\n4.114265\nAPOE\n0.0\n6.465453\nMT-CYB\n...\n5.738638\nROPN1L\n0.0\n4.393602\nTYROBP\n0.0\n10.120045\nTMSB4X\n0.000000e+00\n3.789072\n\n\n4\nPFN1\n0.0\n2.365119\nGNB2L1\n0.0\n2.468919\nCALD1\n0.0\n4.854297\nMT-ND4\n...\n5.993700\nTSACC\n0.0\n4.597932\nCD74\n0.0\n7.758448\nADIRF\n1.545145e-272\n6.255490\n\n\n\n\n5 rows × 51 columns\n\n\n\nThe table can also be exported into csv format in the folder results_scrna. It can be opened using jupyterlab as well Excel if you download it and set the comma character , as separator\n\n!mkdir -p results_scrna\n\n\nX.to_csv('./results_scrna/DiffExpression_NoAnnotation.csv', sep=',', index=None)\n\n\n\nCluster assignment\nDefining the most likely cell type present in a cluster is sometimes a very complicated task, especially in big datasets where the cells change from one type to another in a very continuous fashion, making the “hard clustering” not a completely realistic model. However, for many applications, a hard clustering associated with a careful markers analysis is a well-accepted technique in the scientific community, and is used in basically the totality of the state-of-the-art publications. To avoid the subjectivity of assigning clusters by hand, we get the best score for each cell type in each of the clusters. To do that, we average the markers scores calculated before with an ad-hoc function we wrote\n\nadata.obs['spermatogenesis_types'] = clustersByScores(adata, markers_scores, leidenClusters=adata.obs['leiden_R.5'])\n\nLet’s see how things look like! It seems we have a pretty uniform cluster naming!\n\nplt.rcParams['figure.figsize'] = (12,12)\nsc.pl.umap( adata, color=['spermatogenesis_types'], \n           legend_loc='on data', \n           legend_fontsize=16,\n           frameon=False,\n           size=60,\n           add_outline=True,\n           ncols=1,\n           components=['1,2','2,3','1,3'] \n           )\n\n\n\n\n\n\n\n\n###\n\n  Exercise: Gene Enrichment Analysis  \n\nGene enrichment analysis consists in testing a set of genes to see if it overlaps significantly with lists of genes contained in a database (Maleki et al, 2020). There are all sorts of databases related to biological pathways, Tissue types, Transcription factors coexpression, Illnesses, … that contain a priori information about sets of genes.\nWe will try to find enrichment of genes for pathways, ontologies or diseases from the differentially expressed genes of a cluster, and we will create a “consensus ontology” collected from all the people in the course. We will use Enrichr (Chen et al, 2013), that has a web interface of easy use. In this exercise, you will - choose one of the identified clusters - printout a file with a list of differentially expressed genes from the chosen cluster - open the txt file (in the folder results_scrna) and copy the whole list - paste the list in the Enrichr website - find up to 5 terms you consider to be related to spermatogenesis\nThere are a lot of databases shown in the results from Enrichr, separated in various tabs, so many terms will not be necessarily related to spermatogenesis, or they will be related to basic cellular processes common to many tissues.\nRemember the available clusters:\n\nprint( list( adata.obs['spermatogenesis_types'].cat.categories ) ) \n\n['Elong.Spt', 'Endothelial', 'Leydig', 'Macroph', 'Myoid', 'Round.Spt', 'Smooth', 'SpermatocytesI', 'SpermatocytesII', 'SpermatogoniaA', 'SpermatogoniaB']\n\n\nChoose the cluster name (write it between the two quotes)\n\nCHOSEN_CLUSTER = 'Myoid'\n\nRun differential expression\n\n#Perform the test on logarithmized data\nadata.X = adata.layers['raw_counts']\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.tl.rank_genes_groups(adata, groupby='spermatogenesis_types', n_genes=50)\n#Use again the scaled data as standard\nadata.X = adata.layers['scaled_counts']\n\nWARNING: adata.X seems to be already log-transformed.\n\n\nCreate the table and print the gene names. Highlight and copy them, so they are ready to be pasted.\n\nresult = adata.uns['rank_genes_groups']\ngroups = result['names'].dtype.names\nX = pd.DataFrame(\n    {group + '_' + key[:1].upper(): result[key][group]\n    for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\nfor i in X[f'{CHOSEN_CLUSTER}_N'].values:\n    print(i)\n\nACTA2\nPTGDS\nIGFBP7\nAPOE\nCALD1\nMYL9\nTMSB4X\nTPM2\nLGALS1\nFHL2\nMYL6\nSPARCL1\nMYH11\nTIMP1\nTIMP3\nSMOC2\nENG\nVIM\nCD63\nB2M\nSPARC\nDPEP1\nITM2B\nDCN\nEEF1A1\nAEBP1\nACTB\nRPL10\nNGFRAP1\nCPE\nOSR2\nTCEAL4\nFTL\nMGP\nMALAT1\nNR2F2\nNEAT1\nCST3\nNUPR1\nRPL13A\nRPS4X\nTSHZ2\nRPS8\nRPL7\nC11orf96\nTPM1\nBST2\nIFITM3\nTAGLN\nRPL10A\n\n\nNow paste the genes into the Enrichr website, then find possible interesting enriched terms.\n\n\n\n\nData dynamics\nKnowing the beginning of a differentiation process for the cells of an organ, we can model how the development proceeds. This is done by the pseudotimes, based on the statistical concept of diffusion maps (Ronald Coifman and Stephane Lafon, 2006, Angerer et al, 2016): given the cells at the beginning of the differentiation, pseudotimes are a special distance-based measure - imagine being able to walk along the 3D UMAP plot starting from SpermatogoniaA, measuring how much you have walked along the plot. Here we subset the dataset to consider only spermatogenic cells excluding somatic cells.\n\nsubdata = adata[ [i not in ['Endothelial','Macroph','Myoid','Smooth','Leydig'] \n                  for i in adata.obs['spermatogenesis_types']] ].copy()\n\n\nsubdata.uns['iroot'] = np.flatnonzero(subdata.obs['spermatogenesis_types'] == 'SpermatogoniaA')[1]\n\n\nsc.tl.dpt(subdata, n_dcs=2)\n\nWARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.\n\n\n\nplt.rcParams['figure.figsize'] = (8,8)\nsc.pl.umap( subdata, color=['dpt_pseudotime'],\n           legend_loc='right margin', \n           legend_fontsize=16,\n           frameon=False,\n           size=60,\n           add_outline=True,\n           ncols=1,\n           cmap='Blues'\n           )\n\n\n\n\n\n\n\n\n\nplt.rcParams['figure.figsize'] = (8,8)\nX = subdata.obsm['X_umap']\nfig = px.scatter_3d(subdata.obsm, x=X[:,0], y=X[:,1], z=X[:,2], color=subdata.obs['dpt_pseudotime'], \n                    hover_name=subdata.obs['spermatogenesis_types'],\n                    height=1000)\nfig.show()\n\n                                                \n\n\nNote how some clusters have a small variance in pseudotime. This is because those clusters show a lower variability in gene expressions than in cell types where a wide range of differentiation events happen.\n\nsc.pl.violin(subdata, keys='dpt_pseudotime', groupby='spermatogenesis_types', rotation=90,\n             order=['SpermatogoniaA','SpermatogoniaB','SpermatocytesI','SpermatocytesII','Round.Spt','Elong.Spt'])\n\n\n\n\n\n\n\n\nCopy pseudotimes in the main object, leaving somatic cells at a negative value as a default, since they have not a calculated pseudotime\n\nadata.obs['dpt_pseudotime'] = np.repeat(-1, adata.shape[0])\nadata.obs['dpt_pseudotime'][subdata.obs_names] = subdata.obs['dpt_pseudotime']\n\nremove subdata and use the gc garbage collector to free up memory\n\n#remove subdata as it is no longer used\ndel subdata\ngc.collect() \n\n83077\n\n\n\n\nComparisons across different datasets\nIn this last part of the analysis we import a dataset of testis tissues from infertile men (affected by cryptozoospermia). The data has already been preprocessed in advance. We will first annotated the new dataset using our spermatogenesis data as a reference, so that cluster names and pseudotimes are assigned accordingly. Then we will compare gene expressions using statistical tests.\n\nReference-based annotation\nWe read the new data\n\ncrypto = sc.read_h5ad('../Data/scrna_data/crypto_azoospermia.h5ad')\n\n\n#use only genes present in both datasets\nvar_names = adata.var_names.intersection(crypto.var_names)\nadata = adata[:, var_names]\ncrypto = crypto[:, var_names]\n\nThe tool ingest included in scanpy allows the annotation of a dataset starting from a reference. Look here for further examples about the use of ingest. We choose the clustering and the pseudotimes as observations to transfer to the new data. It takes some time to do the annotation.\n\nsc.tl.ingest(crypto, adata, obs=['spermatogenesis_types','dpt_pseudotime'])\n\nKeep the same cluster colours in the new data\n\nadata\n\nView of AnnData object with n_obs × n_vars = 46253 × 12316\n    obs: 'batch', 'super_batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'n_counts', 'perc_mito', 'perc_MALAT1', 'n_genes', 'SpermatogoniaA_score', 'SpermatogoniaB_score', 'SpermatocytesI_score', 'SpermatocytesII_score', 'Round.Spt_score', 'Elong.Spt_score', 'Sertoli_score', 'Macroph_score', 'Leydig_score', 'Endothelial_score', 'Myoid_score', 'Smooth_Muscle_score', 'leiden_R1', 'leiden_R.5', 'leiden_R.25', 'leiden_R.1', 'spermatogenesis_types', 'dpt_pseudotime'\n    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'pca', 'log1p', 'hvg', 'batch_colors', 'neighbors', 'umap', 'leiden_R1', 'leiden_R.5', 'leiden_R.25', 'leiden_R.1', 'leiden_R1_colors', 'leiden_R.5_colors', 'leiden_R.25_colors', 'leiden_R.1_colors', 'rank_genes_groups', 'spermatogenesis_types_colors'\n    obsm: 'X_pca', 'X_umap'\n    varm: 'PCs'\n    layers: 'raw_counts', 'scaled_counts'\n    obsp: 'distances', 'connectivities'\n\n\n\ncrypto.uns['spermatogenesis_types_colors'] = adata.uns['spermatogenesis_types_colors']  # fix colors\n\nMake pseudotimes as a numeric array\n\ncrypto.obs['dpt_pseudotime'] = np.array(crypto.obs['dpt_pseudotime'])\n\nIngest adapts also the UMAP plot of the new data to the reference one. Note how pseudotimes are off for some cell, especially for the Elongated Spermatids cluster. This might be due to reduced spermatogenic functionality of cells in infertile men.\n\nsc.pl.umap(crypto, color=['spermatogenesis_types', 'dpt_pseudotime'], wspace=0.5,\n          title=['atlas-based clustering of azoospermic data', 'atlas-based pseudotimes of azoospermic data'])\n\n\n\n\n\n\n\n\nNow we merge the two datasets together. Note that the expression matrix will not be integrated. Ingest is used only for reference-based annotation and UMAP alignment, but it cannot integrate the expression matrices removing biases (such as sample bias). For this there are other tools such as scVI-tools, CCA and rPCA and others. However, a good and computationally lighter alternative is to keep the matrices as they are and model the differences when applying tools on them, as we will do with differential expression testing.\n\nmerged = sc.AnnData.concatenate(adata, crypto, batch_key='condition', batch_categories=['Healthy','Crypto'])\n\n\nmerged.uns['spermatogenesis_types_colors'] = adata.uns['spermatogenesis_types_colors']  # fix category colors\n\nThe UMAP shows a nice overlapping of the datasets and cluster names, apart from a few cell types that are off\n\nsc.pl.umap(merged, color=['condition','spermatogenesis_types','dpt_pseudotime'], wspace=0.3, s=30)\n\n\n\n\n\n\n\n\nAs already noticed before, pseudotimes are quite different between the two conditions\n\nfig, (ax1) = plt.subplots(1, 1, figsize=(12,8), gridspec_kw={'wspace':0.5})\nax = sns.violinplot(x=\"spermatogenesis_types\", y=\"dpt_pseudotime\", hue=\"condition\", scale=\"width\", palette=\"Set2\", split=True, ax=ax1,                    \n                    data=merged[merged.obs['dpt_pseudotime']&gt;=0].obs[ ['condition', 'dpt_pseudotime', 'spermatogenesis_types'] ], \n                    order=['SpermatogoniaA','SpermatogoniaB','SpermatocytesI', 'SpermatocytesII','Round.Spt','Elong.Spt'])\n\n\n\n\n\n\n\n\nFree some memory up\n\ndel adata, crypto\ngc.collect() \n\n140277\n\n\nYou can save the data like this\n\nmerged.write('merged.h5ad')\n\n\n\nCross-dataset differential expression\nWe will perform the differential expression testing between the two conditions. Just to give a very quick overview, you can find three ways in which differential gene expression is done with scRNA-seq data:\n\nusing tests that are analogous to the ones for bulkRNA data. This has been the standard for some years, but generates a lot of false positives, because each cell is used as a bulk sample with very low amount of transcripts.\nusing statistical models that take into accounts technical biases in the data (e.g. D3E and MAST) and should be more reliable than standard bulkRNA methods. Squair et al, 2021 show how those methods are much less effective than previously thought, probably because we still consider each cell as a bulk sample in the test, and the technical differences between cells are just too many to model them.\nusing groups of cells (in our case grouped by sample, condition and cell type) as a single bulk sample by summing the cells’ transcriptomes. Squair et al, 2021 show how already standard bulkRNA methods applied on the pseudobulk data are very effective and reduce false positives. Right now, this is probably the state-of-the-art way to proceed. Look also at (this other course) for an application of the pseudobulk technique.\n\nWe will apply the latter method. To do this we create pseudobulk samples by the sum of the transcriptomes from multiple cells in the data. In other words, we are doing nothing much different than the bulk RNA analysis done in Notebook 3 of this course. We will code only in python, but in future, when working on your own data, you can use any bulkRNA analysis tool with the pseudobulk matrix.\nAfter creating the pseudobulk matrix, we use a standard t-test for differential gene expression. More advanced tools like pydeseq2 have features for including factors in the analysis.\n\nmerged = sc.read('merged.h5ad') #read the data\n\n\nmerged.X\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 575392627 stored elements and shape (48400, 12316)&gt;\n\n\nWe remove mitochondrial and ribosomal genes to focus only on genes of interest.\n\nMT_RP = [('MT-' not in i)and(re.match('^RP[A-Za-z]', i) is None) for i in merged.var_names] #a vector with True and False to find mitocondrial/ribosomal genes\nmerged = merged[:, MT_RP].copy()\n\nWe select the raw count matrix for the analysis, and subset the dataset into a new one including the cluster of interest. First, let’s also look at how many cells there are in each cluster of the healthy and azoospermic sample:\n\nmerged.X = merged.layers['raw_counts'].copy()\n\n\nmerged[merged.obs['condition']=='Healthy'].obs['spermatogenesis_types'].value_counts() #healthy sample\n\nSpermatogoniaA     17512\nMyoid               4921\nSpermatocytesII     3972\nEndothelial         3752\nLeydig              3312\nRound.Spt           3268\nElong.Spt           3150\nSpermatogoniaB      2835\nSpermatocytesI      2176\nMacroph              946\nSmooth               409\nName: spermatogenesis_types, dtype: int64\n\n\nWe can see there are many cells in each cell type, but we must also check that each condition has enough. Note that the azoospermia sample is quite little and have few cells in some clusters:\n\nmerged[merged.obs['condition']=='Crypto'].obs['spermatogenesis_types'].value_counts()\n\nSpermatogoniaA     791\nSpermatocytesII    396\nLeydig             317\nMyoid              275\nSpermatogoniaB     162\nRound.Spt           58\nElong.Spt           55\nSpermatocytesI      47\nEndothelial         43\nSmooth               2\nMacroph              1\nName: spermatogenesis_types, dtype: int64\n\n\nWe renormalize the data and take some significant genes. Less variable genes will not be useful for differential expression analysis.\n\nsc.pp.log1p(merged)\nsc.pp.normalize_per_cell(merged)\nsc.pp.highly_variable_genes(merged, n_top_genes=5000)\n\nNow we subset by most significant genes. Afterwards, we use a script to generate the bulk matrix for both conditions. This script always uses the raw counts matrix even if we normalized the data above to find the most variable genes.\n\nmatrix = merged[:,merged.var['highly_variable']].X.copy()\n\n\nmatrix_bulk, clusters, conditions = pseudobulk_matrix(adata=merged, \n                                          batch_key='batch', \n                                          condition_key='condition', \n                                          cluster_key='spermatogenesis_types')\n\nGuo1\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nGuo2\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nGuo3\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer1_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer2_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 1 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer3_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer4\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer5\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer6\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 1 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer7_Spt\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer8_Spc\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSAM_1\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\nSAM_2\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\nOnly 1 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\nSAM_3\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 1 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\nSohni1_I\n----Healthy\n--------Elong.Spt\nOnly 1 cells: skipping\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni1_und\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni2_I\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni2_und\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n\n\nThe bulk matrix looks like this. It shows the total expression of each gene in every cluster, sample and condition. Those are represented in the bulk sample name, together with a number. Our script actually creates 10 pseudobulk samples per each group of cells, by randomly subsampling them. In this way we still keep some of the single cell variability. This is why each pseudobulk sample has a number. For example: Healthy_Guo1_Elong_Spermatids_2 is the pseudobulk sample number 2 from cells in the healthy condition, sample name Guo1 and cluster Elongated spermatids.\n\nmatrix_bulk.head()\n\n\n\n\n\n\n\n\nHealthy_Guo1_Elong.Spt_0\nHealthy_Guo1_Elong.Spt_1\nHealthy_Guo1_Elong.Spt_2\nHealthy_Guo1_Elong.Spt_3\nHealthy_Guo1_Elong.Spt_4\nHealthy_Guo1_Elong.Spt_5\nHealthy_Guo1_Elong.Spt_6\nHealthy_Guo1_Elong.Spt_7\nHealthy_Guo1_Elong.Spt_8\nHealthy_Guo1_Elong.Spt_9\n...\nHealthy_Sohni2_und_SpermatogoniaB_0\nHealthy_Sohni2_und_SpermatogoniaB_1\nHealthy_Sohni2_und_SpermatogoniaB_2\nHealthy_Sohni2_und_SpermatogoniaB_3\nHealthy_Sohni2_und_SpermatogoniaB_4\nHealthy_Sohni2_und_SpermatogoniaB_5\nHealthy_Sohni2_und_SpermatogoniaB_6\nHealthy_Sohni2_und_SpermatogoniaB_7\nHealthy_Sohni2_und_SpermatogoniaB_8\nHealthy_Sohni2_und_SpermatogoniaB_9\n\n\n\n\nFAM41C\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.000000\n0.000000\n0.000000\n1.305737\n1.159709\n0.000000\n0.000000\n0.000000\n0.486395\n0.000000\n\n\nSAMD11\n0.0\n0.0\n0.822\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.989435\n0.602223\n0.588762\n0.966829\n1.158253\n0.623572\n1.040643\n0.304657\n0.924624\n1.218390\n\n\nNOC2L\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.743657\n0.0\n0.000000\n0.0\n0.0\n...\n5.744185\n2.700832\n5.782676\n3.852823\n3.552665\n5.052505\n6.785296\n3.531232\n6.631590\n3.002781\n\n\nKLHL17\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.489320\n0.000000\n1.139032\n0.000000\n0.782108\n0.000000\n0.000000\n0.000000\n0.437053\n0.000000\n\n\nISG15\n0.0\n0.0\n0.000\n0.0\n0.861346\n0.000000\n0.0\n0.481781\n0.0\n0.0\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.163019\n0.000000\n0.000000\n\n\n\n\n5 rows × 1520 columns\n\n\n\nFor practical purpose we exchange rows and columns by rotating the matrix.\n\nmatrix_bulk = matrix_bulk.T\nmatrix_bulk.head()\n\n\n\n\n\n\n\n\nFAM41C\nSAMD11\nNOC2L\nKLHL17\nISG15\nC1orf159\nSDF4\nUBE2J2\nSCNN1D\nACAP3\n...\nMCM3AP\nYBEY\nC21orf58\nPCNT\nDIP2A\nPRMT2\nAC136616.1\nAC007325.4\nAC023491.2\nAC240274.1\n\n\n\n\nHealthy_Guo1_Elong.Spt_0\n0.0\n0.000\n0.0\n0.0\n0.000000\n0.524757\n0.000000\n7.200664\n0.0\n0.0\n...\n0.000000\n2.478227\n0.000000\n0.493104\n0.728248\n0.0\n1.682502\n8.850147\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_1\n0.0\n0.000\n0.0\n0.0\n0.000000\n2.869721\n0.000000\n6.047873\n0.0\n0.0\n...\n0.000000\n3.559190\n3.714458\n0.000000\n0.000000\n0.0\n0.864075\n8.230722\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_2\n0.0\n0.822\n0.0\n0.0\n0.000000\n1.604822\n0.000000\n6.691433\n0.0\n0.0\n...\n0.000000\n2.366015\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n5.639266\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_3\n0.0\n0.000\n0.0\n0.0\n0.000000\n0.509491\n0.680446\n5.043328\n0.0\n0.0\n...\n0.680446\n3.762988\n0.000000\n1.710508\n0.680446\n0.0\n1.416343\n7.605245\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_4\n0.0\n0.000\n0.0\n0.0\n0.861346\n0.420644\n0.000000\n6.480343\n0.0\n0.0\n...\n0.000000\n1.620871\n0.000000\n0.000000\n0.420644\n0.0\n0.920444\n4.049621\n0.0\n0.0\n\n\n\n\n5 rows × 12173 columns\n\n\n\nWe create a scanpy object to be able to do statistical testing.\n\nimport anndata as ad\n\n\npbulk = ad.AnnData(matrix_bulk)\n\n\npbulk\n\nAnnData object with n_obs × n_vars = 1520 × 12173\n\n\nWe just remove those genes never expressed in the pseudobulk data\n\nsc.pp.filter_genes(pbulk, min_cells=1)\n\nWe create some metadata\n\npbulk.obs['condition'] = conditions\npbulk.obs['spermatogenesis_types'] = clusters \n\nand normalize depth of each pseudobulk replicate and logarithmize, similarly to what was done in Notebook 3 of the course\n\nsc.pp.normalize_per_cell(pbulk)\nsc.pp.log1p(pbulk)\n\nOut of curiosity, why not plotting a PCA of the pseudobulk data? We can see how it looks similar to the single cell data, with a decent overlapping of the conditions, meaning the pseudobulk process kept the differences between types, and also the data structure overall.\n\nsc.pp.pca(pbulk)\n\n\nsc.pl.pca(pbulk, color=['condition','spermatogenesis_types'], s=50)\n\n\n\n\n\n\n\n\nWe can finally run the statistical test by condition. We will do a list with ALL genes, so we can explore it at any time afterwards. We will use the condition Healthy as reference, so the results will give how changes are in Crypto against Healthy\n\nsc.tl.rank_genes_groups(pbulk, groupby=\"condition\", reference='Healthy', n_genes=pbulk.shape[1])\n\nWe use a script to extract the results in a matrix. We will also calculate some other values under the hood and add them in the table.\n\nDEG_matrix = pseudobulk_extract_DEG(pbulk=pbulk, adata=merged)\n\n---Extracting results\nWARNING: adata.X seems to be already log-transformed.\n---done\n\n\nWhat does the resulting matrix contain? Apart from genes names, we can see in how many bulk samples those are expressed (in percentage for healthy and crypto cells), the fold-change and log-fold-change, the pvalues and adjusted pvalues. Note: those results are for Crypto vs Healthy. For values with Healthy as a reference, just change the sign to all fold-changes and log-fold-changes, and you have changed your reference!\n\nDEG_matrix.head()\n\n\n\n\n\n\n\n\nCrypto_NAMES\nCrypto_PVALS\nCrypto_PVALS_ADJ\nCrypto_LOGFOLDCHANGES\nHealthy_PCT\nCrypto_PCT\nCrypto_FOLDCHANGES\nCrypto_LOGPVALS_ADJ\nCrypto_LOGPVALS\n\n\n\n\n0\nEEF1G\n4.557527e-188\n1.849293e-184\n7.720026\n3.664627\n97.345133\n210.843109\n50.0\n50.0\n\n\n1\nMRPS24\n4.462642e-173\n1.358094e-169\n6.370932\n2.181480\n80.763857\n82.764008\n50.0\n50.0\n\n\n2\nGABARAP\n5.121595e-194\n3.117259e-190\n5.045707\n14.256373\n97.438286\n33.030037\n50.0\n50.0\n\n\n3\nH3F3B\n2.158483e-139\n2.919468e-136\n2.287395\n97.323417\n99.906847\n4.881739\n50.0\n50.0\n\n\n4\nPSMA6\n9.807033e-158\n1.705443e-154\n3.847374\n22.273150\n89.287378\n14.393784\n50.0\n50.0\n\n\n\n\n\n\n\nWe just want to make a volcano plot of the result table. We consider as significant genes with p-value below 0.001 (log p-value of 3) and a log-fold-change below -2 and above 2 for this plot. The dot size is the percentege of cells expressing each gene.\nAs underexpressed genes we find amongst others CXCL2 (upregulated only when azoospermia is together with inflamation) and ZNRF3 (involved in disorder of sex development). Upregulated are for example CMTM1 (involved in fertility, whose knockout has no effect on it), SPATS1 (involved in sperm development) and DLGAP2 (associated to male infertility)\n\npseudobulk_volcano(DEG_matrix, logfold_threshold=2, logpval_threshold=3, plot_size=(800,800))\n\n                                                \n\n\nFinally, you can save the table and download it, to view very easily in Excel.\n\nDEG_matrix.to_csv('./pseudobulk_markers.csv', sep='\\t', index=None)\n\n\n\n\n\n\n\nWrapping up\n\n\n\nYou executed the whole analysis to the very end of this notebook!\nIt has been a pretty long one, but I hope you learnt new things and you will benefit from them in your future scRNA-seq analysis. Remember that the scanpy webpage has a lot of tutorials and very good documentation for all the functions implemented. The universe of available tools for single cell RNA data is growing constantly and is difficult to navigate - I suggest you to try tools that seem interesting, are usable without too many dificulties, and then stick only to those that are really relevant. Fortunately the community revolving around scRNA-seq data analysis is huge and rather helpful and open-source. It is mostly a matter of googling yourself to relevant forums and github repositories to find useful answers to doubts, available tools, and guides.\nDo you want to look for more advanced analysis? We have an introduction to single cell RNA sequencing also in R and advanced topics in scRNA-seq analysis. You can find those in our Transcriptomics Sandbox on uCloud (for danish users of uCloud), otherwise the tutorials are all documented in web format at their respective webpages:\n \n\n Transcriptomics Sandbox \n\n \n\n Advanced Single Cell Analysis \n\n \n\n Intro to scRNA-seq in R"
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#clusters-identification",
    "href": "nb/04_scRNAseq_analysis.html#clusters-identification",
    "title": "Single cell analysis workflow",
    "section": "Clusters Identification",
    "text": "Clusters Identification\nCell types can be identified and then assigned to clusters calculated by one of the many available clustering techniques. When identifying a cluster, we can assign that to a likely cell type by visualizing known markers on a projection plot, e.g. an UMAP plot. Similarly, one can score cells for a set of markers. Finally, if an atlas of cell types is available, one can use it for a supervised assignment of cell types (see for example the R package scmap) and the ingest tool from scanpy.\nBe aware that clusters do not necessarily match perfectly cell types (especially if cells change in a continuous way, hard clusters are not the best solution, though an acceptable one).\n\nPrint markers’ scores\nThe first step to identify various cell types is to print markers on the UMAP plot. We will print markers’ scores, that is the average expression of a list of markers, subtracted of the average expression of some random genes. We provide a python dictionary including some cell types and a few of their marker genes.\nA dictionary is a python object in which you can allocate different objects (matrices, vectors, lists, …), each having an assigned name. Here, we have lists of marker genes, where each list is identified by the name of the corresponding cell type. To remember the different stages of spermatogenesis, a scheme is attached below, and you can read more about the spermatogenic process at this page\n\n\nmarkers = dict() #make an empty dictionary\n### SPERMATOCYTOGENESIS\nmarkers['SpermatogoniaA'] = ['ID4','HMGA1']\nmarkers['SpermatogoniaB'] = ['MKI67','DMRT1','STRA8'] \nmarkers['SpermatocytesI'] = ['MEIOB','PRSS50','SYCP1','TEX101']\nmarkers['SpermatocytesII'] = ['PIWIL1','ACRV1','SPATA16','CLGN']\n### SPERMIOGENESIS\nmarkers['Round.Spt'] = ['SPATA9','SPAM1'] #Round spermatids\nmarkers['Elong.Spt'] = ['PRM1','PRM2'] #Elongated spermatids\n### SOMATIC CELLS\nmarkers['Sertoli'] = ['CTSL', 'VIM']\nmarkers['Macroph'] = ['CD163','TYROBP']\nmarkers['Leydig'] = ['CFD']\nmarkers['Endothelial'] = ['CD34']\nmarkers['Myoid'] = ['ACTA2']\nmarkers['Smooth_Muscle'] = ['RGS5']\n\nWe calculate the scores for the markers\n\nmarkers_scores, adata = marker_score(markers, adata)\n\nMake a separate UMAP plot for every cell type. You should be able to see quite clearly some clusters where the marker’s expressions are stronger. Sertoli cells are usually hard to identify - their markers are expressed also in other cell types, and often Sertoli cells are not captured due to their size. It seems that there aren’t sertoli cells into our dataset.\n\nsc.plotting.umap(adata, color=markers_scores, components=['1,2'], ncols=2, vmax=5, s=30, cmap='Blues')\n\n\n\n\n\n\n\n\n\n\nLeiden clustering algorithm\nScanpy contains the leiden algorithm (Traag et al, 2019), making clusters whose points are well connected and at the same time mostly disconnected from other clusters. Other approaches, e.g. k-means, can be performed on the data or on its PCA/tSNE/UMAP projection. The leiden algorithm is however considered to be one of the best techniques at the moment to find communities of similar datapoints, and we will therefore use that. Read more about the leiden algorithm here.\n\n\n\nFigure: refinement steps used by the leiden algorithm to find communities of well-connected points.\n\n&lt;/figure&gt;\nWe calculate some clusterings at various resolution, and choose the one matching best the clusters we have visualized from the markers’ score. The amount of clusters depend on the chosen resolution. Later in this tutorial, we will integrate this dataset with another one, showing how to cluster the new data using ours as a “reference” clustering.\n\n#leiden clustering at various resolutions\nsc.tools.leiden(adata, resolution=1, random_state=12345, key_added='leiden_R1')\nsc.tools.leiden(adata, resolution=0.5, random_state=12345, key_added='leiden_R.5')\nsc.tools.leiden(adata, resolution=0.25, random_state=12345, key_added='leiden_R.25')\nsc.tools.leiden(adata, resolution=0.1, random_state=12345, key_added='leiden_R.1')\n\nWe can see that at resolution 1 we have many clusters, and their number decreases with decreasing resolution. We choose resolution 0.5 which has enough clusters to have a fine grained cell type assignment.\n\nsc.plotting.umap(adata, color=['leiden_R1','leiden_R.5','leiden_R.25', 'leiden_R.1'], legend_loc='on data', ncols=2)\n\n\n\n\n\n\n\n\n\n\nDifferential Gene expression\nIt is not always easy to assign clusters from marker scores. For example, cluster 12 at resolution 0.25 is not immediately recognizable as pericyte cells. Sometimes it is good to double check which genes are most expressed in a cluster compared to all the others before assigning cell types. Here we look at the 50 most expressed genes in each cluster from the Leiden algorithm.\nDifferential gene expression is also the way of making a sound argument in a publication or report. Showing fancy UMAP plots coloured by gene expression is sadly not enough :) A standard way to do it, is to test if each gene has mean expression higher in a cluster than in all the others. Scanpy does that by using a t-test or the wilcoxon test. While the t-test is somewhat less powerful, the wilcoxon test is not best behaved with very sparse data, so we simply apply the default t-test to the dataset. Note that, for the standard t-test in scanpy, you need to use logarithmized data.\nMore advanced techniques that model the statistical properties of the data, such as its sparsity, are available for differential expression. See for example the package MAST (Finak et al, 2015) and the following review on differential expression methods: (Squair et al, 2021).\n\n#Perform the test on logarithmized data\nadata.X = adata.layers['raw_counts'] #raw data\nsc.pp.normalize_total(adata) #TPM normalization\nsc.pp.log1p(adata) #logarithm\nsc.tl.rank_genes_groups(adata, groupby='leiden_R.5', n_genes=50) #Top 50 diff.expressed genes in each cluster\nadata.X = adata.layers['scaled_counts'] #Set again the scaled data as standard data matrix\n\nWARNING: adata.X seems to be already log-transformed.\n\n\nOrganize result in a table. Each column has the cluster numbers with _N, _P, _L representing respectively the gene Names, their P-values and the Log-fold change of each gene expression compared to the other clusters. Many clusters show markers typical of spermatogenesis processes (MYL9, TEX-genes, …)\n\nresult = adata.uns['rank_genes_groups']\ngroups = result['names'].dtype.names\nX = pd.DataFrame(\n    {group + '_' + key[:1].upper(): result[key][group]\n    for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\nX.head() #print only first five lines\n\n\n\n\n\n\n\n\n0_N\n0_P\n0_L\n1_N\n1_P\n1_L\n2_N\n2_P\n2_L\n3_N\n...\n13_L\n14_N\n14_P\n14_L\n15_N\n15_P\n15_L\n16_N\n16_P\n16_L\n\n\n\n\n0\nLYPLA1\n0.0\n2.635769\nZNF428\n0.0\n3.806565\nPTGDS\n0.0\n7.961807\nMT-CO2\n...\n8.849788\nANKRD7\n0.0\n5.520726\nTMSB4X\n0.0\n5.302206\nMALAT1\n0.000000e+00\n3.612107\n\n\n1\nSRSF9\n0.0\n2.288302\nHMGA1\n0.0\n3.570310\nIGFBP7\n0.0\n6.235969\nSBNO1\n...\n6.715557\nCMTM2\n0.0\n5.160422\nB2M\n0.0\n5.034176\nMYL9\n2.031513e-297\n6.074902\n\n\n2\nSMS\n0.0\n2.876471\nRPS12\n0.0\n2.645890\nACTA2\n0.0\n7.899968\nMT-CO1\n...\n5.880414\nTEX40\n0.0\n5.001250\nTMSB10\n0.0\n4.341215\nCALD1\n9.825148e-295\n4.660460\n\n\n3\nHMGA1\n0.0\n2.629156\nRAC3\n0.0\n4.114265\nAPOE\n0.0\n6.465453\nMT-CYB\n...\n5.738638\nROPN1L\n0.0\n4.393602\nTYROBP\n0.0\n10.120045\nTMSB4X\n0.000000e+00\n3.789072\n\n\n4\nPFN1\n0.0\n2.365119\nGNB2L1\n0.0\n2.468919\nCALD1\n0.0\n4.854297\nMT-ND4\n...\n5.993700\nTSACC\n0.0\n4.597932\nCD74\n0.0\n7.758448\nADIRF\n1.545145e-272\n6.255490\n\n\n\n\n5 rows × 51 columns\n\n\n\nThe table can also be exported into csv format in the folder results_scrna. It can be opened using jupyterlab as well Excel if you download it and set the comma character , as separator\n\n!mkdir -p results_scrna\n\n\nX.to_csv('./results_scrna/DiffExpression_NoAnnotation.csv', sep=',', index=None)\n\n\n\nCluster assignment\nDefining the most likely cell type present in a cluster is sometimes a very complicated task, especially in big datasets where the cells change from one type to another in a very continuous fashion, making the “hard clustering” not a completely realistic model. However, for many applications, a hard clustering associated with a careful markers analysis is a well-accepted technique in the scientific community, and is used in basically the totality of the state-of-the-art publications. To avoid the subjectivity of assigning clusters by hand, we get the best score for each cell type in each of the clusters. To do that, we average the markers scores calculated before with an ad-hoc function we wrote\n\nadata.obs['spermatogenesis_types'] = clustersByScores(adata, markers_scores, leidenClusters=adata.obs['leiden_R.5'])\n\nLet’s see how things look like! It seems we have a pretty uniform cluster naming!\n\nplt.rcParams['figure.figsize'] = (12,12)\nsc.pl.umap( adata, color=['spermatogenesis_types'], \n           legend_loc='on data', \n           legend_fontsize=16,\n           frameon=False,\n           size=60,\n           add_outline=True,\n           ncols=1,\n           components=['1,2','2,3','1,3'] \n           )\n\n\n\n\n\n\n\n\n###\n\n  Exercise: Gene Enrichment Analysis  \n\nGene enrichment analysis consists in testing a set of genes to see if it overlaps significantly with lists of genes contained in a database (Maleki et al, 2020). There are all sorts of databases related to biological pathways, Tissue types, Transcription factors coexpression, Illnesses, … that contain a priori information about sets of genes.\nWe will try to find enrichment of genes for pathways, ontologies or diseases from the differentially expressed genes of a cluster, and we will create a “consensus ontology” collected from all the people in the course. We will use Enrichr (Chen et al, 2013), that has a web interface of easy use. In this exercise, you will - choose one of the identified clusters - printout a file with a list of differentially expressed genes from the chosen cluster - open the txt file (in the folder results_scrna) and copy the whole list - paste the list in the Enrichr website - find up to 5 terms you consider to be related to spermatogenesis\nThere are a lot of databases shown in the results from Enrichr, separated in various tabs, so many terms will not be necessarily related to spermatogenesis, or they will be related to basic cellular processes common to many tissues.\nRemember the available clusters:\n\nprint( list( adata.obs['spermatogenesis_types'].cat.categories ) ) \n\n['Elong.Spt', 'Endothelial', 'Leydig', 'Macroph', 'Myoid', 'Round.Spt', 'Smooth', 'SpermatocytesI', 'SpermatocytesII', 'SpermatogoniaA', 'SpermatogoniaB']\n\n\nChoose the cluster name (write it between the two quotes)\n\nCHOSEN_CLUSTER = 'Myoid'\n\nRun differential expression\n\n#Perform the test on logarithmized data\nadata.X = adata.layers['raw_counts']\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.tl.rank_genes_groups(adata, groupby='spermatogenesis_types', n_genes=50)\n#Use again the scaled data as standard\nadata.X = adata.layers['scaled_counts']\n\nWARNING: adata.X seems to be already log-transformed.\n\n\nCreate the table and print the gene names. Highlight and copy them, so they are ready to be pasted.\n\nresult = adata.uns['rank_genes_groups']\ngroups = result['names'].dtype.names\nX = pd.DataFrame(\n    {group + '_' + key[:1].upper(): result[key][group]\n    for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\nfor i in X[f'{CHOSEN_CLUSTER}_N'].values:\n    print(i)\n\nACTA2\nPTGDS\nIGFBP7\nAPOE\nCALD1\nMYL9\nTMSB4X\nTPM2\nLGALS1\nFHL2\nMYL6\nSPARCL1\nMYH11\nTIMP1\nTIMP3\nSMOC2\nENG\nVIM\nCD63\nB2M\nSPARC\nDPEP1\nITM2B\nDCN\nEEF1A1\nAEBP1\nACTB\nRPL10\nNGFRAP1\nCPE\nOSR2\nTCEAL4\nFTL\nMGP\nMALAT1\nNR2F2\nNEAT1\nCST3\nNUPR1\nRPL13A\nRPS4X\nTSHZ2\nRPS8\nRPL7\nC11orf96\nTPM1\nBST2\nIFITM3\nTAGLN\nRPL10A\n\n\nNow paste the genes into the Enrichr website, then find possible interesting enriched terms."
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#data-dynamics",
    "href": "nb/04_scRNAseq_analysis.html#data-dynamics",
    "title": "Single cell analysis workflow",
    "section": "Data dynamics",
    "text": "Data dynamics\nKnowing the beginning of a differentiation process for the cells of an organ, we can model how the development proceeds. This is done by the pseudotimes, based on the statistical concept of diffusion maps (Ronald Coifman and Stephane Lafon, 2006, Angerer et al, 2016): given the cells at the beginning of the differentiation, pseudotimes are a special distance-based measure - imagine being able to walk along the 3D UMAP plot starting from SpermatogoniaA, measuring how much you have walked along the plot. Here we subset the dataset to consider only spermatogenic cells excluding somatic cells.\n\nsubdata = adata[ [i not in ['Endothelial','Macroph','Myoid','Smooth','Leydig'] \n                  for i in adata.obs['spermatogenesis_types']] ].copy()\n\n\nsubdata.uns['iroot'] = np.flatnonzero(subdata.obs['spermatogenesis_types'] == 'SpermatogoniaA')[1]\n\n\nsc.tl.dpt(subdata, n_dcs=2)\n\nWARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.\n\n\n\nplt.rcParams['figure.figsize'] = (8,8)\nsc.pl.umap( subdata, color=['dpt_pseudotime'],\n           legend_loc='right margin', \n           legend_fontsize=16,\n           frameon=False,\n           size=60,\n           add_outline=True,\n           ncols=1,\n           cmap='Blues'\n           )\n\n\n\n\n\n\n\n\n\nplt.rcParams['figure.figsize'] = (8,8)\nX = subdata.obsm['X_umap']\nfig = px.scatter_3d(subdata.obsm, x=X[:,0], y=X[:,1], z=X[:,2], color=subdata.obs['dpt_pseudotime'], \n                    hover_name=subdata.obs['spermatogenesis_types'],\n                    height=1000)\nfig.show()\n\n                                                \n\n\nNote how some clusters have a small variance in pseudotime. This is because those clusters show a lower variability in gene expressions than in cell types where a wide range of differentiation events happen.\n\nsc.pl.violin(subdata, keys='dpt_pseudotime', groupby='spermatogenesis_types', rotation=90,\n             order=['SpermatogoniaA','SpermatogoniaB','SpermatocytesI','SpermatocytesII','Round.Spt','Elong.Spt'])\n\n\n\n\n\n\n\n\nCopy pseudotimes in the main object, leaving somatic cells at a negative value as a default, since they have not a calculated pseudotime\n\nadata.obs['dpt_pseudotime'] = np.repeat(-1, adata.shape[0])\nadata.obs['dpt_pseudotime'][subdata.obs_names] = subdata.obs['dpt_pseudotime']\n\nremove subdata and use the gc garbage collector to free up memory\n\n#remove subdata as it is no longer used\ndel subdata\ngc.collect() \n\n83077"
  },
  {
    "objectID": "nb/04_scRNAseq_analysis.html#comparisons-across-different-datasets",
    "href": "nb/04_scRNAseq_analysis.html#comparisons-across-different-datasets",
    "title": "Single cell analysis workflow",
    "section": "Comparisons across different datasets",
    "text": "Comparisons across different datasets\nIn this last part of the analysis we import a dataset of testis tissues from infertile men (affected by cryptozoospermia). The data has already been preprocessed in advance. We will first annotated the new dataset using our spermatogenesis data as a reference, so that cluster names and pseudotimes are assigned accordingly. Then we will compare gene expressions using statistical tests.\n\nReference-based annotation\nWe read the new data\n\ncrypto = sc.read_h5ad('../Data/scrna_data/crypto_azoospermia.h5ad')\n\n\n#use only genes present in both datasets\nvar_names = adata.var_names.intersection(crypto.var_names)\nadata = adata[:, var_names]\ncrypto = crypto[:, var_names]\n\nThe tool ingest included in scanpy allows the annotation of a dataset starting from a reference. Look here for further examples about the use of ingest. We choose the clustering and the pseudotimes as observations to transfer to the new data. It takes some time to do the annotation.\n\nsc.tl.ingest(crypto, adata, obs=['spermatogenesis_types','dpt_pseudotime'])\n\nKeep the same cluster colours in the new data\n\nadata\n\nView of AnnData object with n_obs × n_vars = 46253 × 12316\n    obs: 'batch', 'super_batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'n_counts', 'perc_mito', 'perc_MALAT1', 'n_genes', 'SpermatogoniaA_score', 'SpermatogoniaB_score', 'SpermatocytesI_score', 'SpermatocytesII_score', 'Round.Spt_score', 'Elong.Spt_score', 'Sertoli_score', 'Macroph_score', 'Leydig_score', 'Endothelial_score', 'Myoid_score', 'Smooth_Muscle_score', 'leiden_R1', 'leiden_R.5', 'leiden_R.25', 'leiden_R.1', 'spermatogenesis_types', 'dpt_pseudotime'\n    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'pca', 'log1p', 'hvg', 'batch_colors', 'neighbors', 'umap', 'leiden_R1', 'leiden_R.5', 'leiden_R.25', 'leiden_R.1', 'leiden_R1_colors', 'leiden_R.5_colors', 'leiden_R.25_colors', 'leiden_R.1_colors', 'rank_genes_groups', 'spermatogenesis_types_colors'\n    obsm: 'X_pca', 'X_umap'\n    varm: 'PCs'\n    layers: 'raw_counts', 'scaled_counts'\n    obsp: 'distances', 'connectivities'\n\n\n\ncrypto.uns['spermatogenesis_types_colors'] = adata.uns['spermatogenesis_types_colors']  # fix colors\n\nMake pseudotimes as a numeric array\n\ncrypto.obs['dpt_pseudotime'] = np.array(crypto.obs['dpt_pseudotime'])\n\nIngest adapts also the UMAP plot of the new data to the reference one. Note how pseudotimes are off for some cell, especially for the Elongated Spermatids cluster. This might be due to reduced spermatogenic functionality of cells in infertile men.\n\nsc.pl.umap(crypto, color=['spermatogenesis_types', 'dpt_pseudotime'], wspace=0.5,\n          title=['atlas-based clustering of azoospermic data', 'atlas-based pseudotimes of azoospermic data'])\n\n\n\n\n\n\n\n\nNow we merge the two datasets together. Note that the expression matrix will not be integrated. Ingest is used only for reference-based annotation and UMAP alignment, but it cannot integrate the expression matrices removing biases (such as sample bias). For this there are other tools such as scVI-tools, CCA and rPCA and others. However, a good and computationally lighter alternative is to keep the matrices as they are and model the differences when applying tools on them, as we will do with differential expression testing.\n\nmerged = sc.AnnData.concatenate(adata, crypto, batch_key='condition', batch_categories=['Healthy','Crypto'])\n\n\nmerged.uns['spermatogenesis_types_colors'] = adata.uns['spermatogenesis_types_colors']  # fix category colors\n\nThe UMAP shows a nice overlapping of the datasets and cluster names, apart from a few cell types that are off\n\nsc.pl.umap(merged, color=['condition','spermatogenesis_types','dpt_pseudotime'], wspace=0.3, s=30)\n\n\n\n\n\n\n\n\nAs already noticed before, pseudotimes are quite different between the two conditions\n\nfig, (ax1) = plt.subplots(1, 1, figsize=(12,8), gridspec_kw={'wspace':0.5})\nax = sns.violinplot(x=\"spermatogenesis_types\", y=\"dpt_pseudotime\", hue=\"condition\", scale=\"width\", palette=\"Set2\", split=True, ax=ax1,                    \n                    data=merged[merged.obs['dpt_pseudotime']&gt;=0].obs[ ['condition', 'dpt_pseudotime', 'spermatogenesis_types'] ], \n                    order=['SpermatogoniaA','SpermatogoniaB','SpermatocytesI', 'SpermatocytesII','Round.Spt','Elong.Spt'])\n\n\n\n\n\n\n\n\nFree some memory up\n\ndel adata, crypto\ngc.collect() \n\n140277\n\n\nYou can save the data like this\n\nmerged.write('merged.h5ad')\n\n\n\nCross-dataset differential expression\nWe will perform the differential expression testing between the two conditions. Just to give a very quick overview, you can find three ways in which differential gene expression is done with scRNA-seq data:\n\nusing tests that are analogous to the ones for bulkRNA data. This has been the standard for some years, but generates a lot of false positives, because each cell is used as a bulk sample with very low amount of transcripts.\nusing statistical models that take into accounts technical biases in the data (e.g. D3E and MAST) and should be more reliable than standard bulkRNA methods. Squair et al, 2021 show how those methods are much less effective than previously thought, probably because we still consider each cell as a bulk sample in the test, and the technical differences between cells are just too many to model them.\nusing groups of cells (in our case grouped by sample, condition and cell type) as a single bulk sample by summing the cells’ transcriptomes. Squair et al, 2021 show how already standard bulkRNA methods applied on the pseudobulk data are very effective and reduce false positives. Right now, this is probably the state-of-the-art way to proceed. Look also at (this other course) for an application of the pseudobulk technique.\n\nWe will apply the latter method. To do this we create pseudobulk samples by the sum of the transcriptomes from multiple cells in the data. In other words, we are doing nothing much different than the bulk RNA analysis done in Notebook 3 of this course. We will code only in python, but in future, when working on your own data, you can use any bulkRNA analysis tool with the pseudobulk matrix.\nAfter creating the pseudobulk matrix, we use a standard t-test for differential gene expression. More advanced tools like pydeseq2 have features for including factors in the analysis.\n\nmerged = sc.read('merged.h5ad') #read the data\n\n\nmerged.X\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 575392627 stored elements and shape (48400, 12316)&gt;\n\n\nWe remove mitochondrial and ribosomal genes to focus only on genes of interest.\n\nMT_RP = [('MT-' not in i)and(re.match('^RP[A-Za-z]', i) is None) for i in merged.var_names] #a vector with True and False to find mitocondrial/ribosomal genes\nmerged = merged[:, MT_RP].copy()\n\nWe select the raw count matrix for the analysis, and subset the dataset into a new one including the cluster of interest. First, let’s also look at how many cells there are in each cluster of the healthy and azoospermic sample:\n\nmerged.X = merged.layers['raw_counts'].copy()\n\n\nmerged[merged.obs['condition']=='Healthy'].obs['spermatogenesis_types'].value_counts() #healthy sample\n\nSpermatogoniaA     17512\nMyoid               4921\nSpermatocytesII     3972\nEndothelial         3752\nLeydig              3312\nRound.Spt           3268\nElong.Spt           3150\nSpermatogoniaB      2835\nSpermatocytesI      2176\nMacroph              946\nSmooth               409\nName: spermatogenesis_types, dtype: int64\n\n\nWe can see there are many cells in each cell type, but we must also check that each condition has enough. Note that the azoospermia sample is quite little and have few cells in some clusters:\n\nmerged[merged.obs['condition']=='Crypto'].obs['spermatogenesis_types'].value_counts()\n\nSpermatogoniaA     791\nSpermatocytesII    396\nLeydig             317\nMyoid              275\nSpermatogoniaB     162\nRound.Spt           58\nElong.Spt           55\nSpermatocytesI      47\nEndothelial         43\nSmooth               2\nMacroph              1\nName: spermatogenesis_types, dtype: int64\n\n\nWe renormalize the data and take some significant genes. Less variable genes will not be useful for differential expression analysis.\n\nsc.pp.log1p(merged)\nsc.pp.normalize_per_cell(merged)\nsc.pp.highly_variable_genes(merged, n_top_genes=5000)\n\nNow we subset by most significant genes. Afterwards, we use a script to generate the bulk matrix for both conditions. This script always uses the raw counts matrix even if we normalized the data above to find the most variable genes.\n\nmatrix = merged[:,merged.var['highly_variable']].X.copy()\n\n\nmatrix_bulk, clusters, conditions = pseudobulk_matrix(adata=merged, \n                                          batch_key='batch', \n                                          condition_key='condition', \n                                          cluster_key='spermatogenesis_types')\n\nGuo1\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nGuo2\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nGuo3\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer1_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer2_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 1 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer3_Spg\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer4\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer5\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer6\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 1 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer7_Spt\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nHer8_Spc\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSAM_1\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\nSAM_2\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\nOnly 1 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\nSAM_3\n----Healthy\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n----Crypto\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\nOnly 1 cells: skipping\n--------Myoid\n--------Round.Spt\n--------Smooth\nOnly 1 cells: skipping\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\nSohni1_I\n----Healthy\n--------Elong.Spt\nOnly 1 cells: skipping\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni1_und\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni2_I\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\nSohni2_und\n----Healthy\n--------Elong.Spt\n--------Endothelial\n--------Leydig\n--------Macroph\n--------Myoid\n--------Round.Spt\n--------Smooth\n--------SpermatocytesI\n--------SpermatocytesII\n--------SpermatogoniaA\n--------SpermatogoniaB\n----Crypto\n--------Elong.Spt\nOnly 0 cells: skipping\n--------Endothelial\nOnly 0 cells: skipping\n--------Leydig\nOnly 0 cells: skipping\n--------Macroph\nOnly 0 cells: skipping\n--------Myoid\nOnly 0 cells: skipping\n--------Round.Spt\nOnly 0 cells: skipping\n--------Smooth\nOnly 0 cells: skipping\n--------SpermatocytesI\nOnly 0 cells: skipping\n--------SpermatocytesII\nOnly 0 cells: skipping\n--------SpermatogoniaA\nOnly 0 cells: skipping\n--------SpermatogoniaB\nOnly 0 cells: skipping\n\n\nThe bulk matrix looks like this. It shows the total expression of each gene in every cluster, sample and condition. Those are represented in the bulk sample name, together with a number. Our script actually creates 10 pseudobulk samples per each group of cells, by randomly subsampling them. In this way we still keep some of the single cell variability. This is why each pseudobulk sample has a number. For example: Healthy_Guo1_Elong_Spermatids_2 is the pseudobulk sample number 2 from cells in the healthy condition, sample name Guo1 and cluster Elongated spermatids.\n\nmatrix_bulk.head()\n\n\n\n\n\n\n\n\nHealthy_Guo1_Elong.Spt_0\nHealthy_Guo1_Elong.Spt_1\nHealthy_Guo1_Elong.Spt_2\nHealthy_Guo1_Elong.Spt_3\nHealthy_Guo1_Elong.Spt_4\nHealthy_Guo1_Elong.Spt_5\nHealthy_Guo1_Elong.Spt_6\nHealthy_Guo1_Elong.Spt_7\nHealthy_Guo1_Elong.Spt_8\nHealthy_Guo1_Elong.Spt_9\n...\nHealthy_Sohni2_und_SpermatogoniaB_0\nHealthy_Sohni2_und_SpermatogoniaB_1\nHealthy_Sohni2_und_SpermatogoniaB_2\nHealthy_Sohni2_und_SpermatogoniaB_3\nHealthy_Sohni2_und_SpermatogoniaB_4\nHealthy_Sohni2_und_SpermatogoniaB_5\nHealthy_Sohni2_und_SpermatogoniaB_6\nHealthy_Sohni2_und_SpermatogoniaB_7\nHealthy_Sohni2_und_SpermatogoniaB_8\nHealthy_Sohni2_und_SpermatogoniaB_9\n\n\n\n\nFAM41C\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.000000\n0.000000\n0.000000\n1.305737\n1.159709\n0.000000\n0.000000\n0.000000\n0.486395\n0.000000\n\n\nSAMD11\n0.0\n0.0\n0.822\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.989435\n0.602223\n0.588762\n0.966829\n1.158253\n0.623572\n1.040643\n0.304657\n0.924624\n1.218390\n\n\nNOC2L\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.743657\n0.0\n0.000000\n0.0\n0.0\n...\n5.744185\n2.700832\n5.782676\n3.852823\n3.552665\n5.052505\n6.785296\n3.531232\n6.631590\n3.002781\n\n\nKLHL17\n0.0\n0.0\n0.000\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n...\n0.489320\n0.000000\n1.139032\n0.000000\n0.782108\n0.000000\n0.000000\n0.000000\n0.437053\n0.000000\n\n\nISG15\n0.0\n0.0\n0.000\n0.0\n0.861346\n0.000000\n0.0\n0.481781\n0.0\n0.0\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.163019\n0.000000\n0.000000\n\n\n\n\n5 rows × 1520 columns\n\n\n\nFor practical purpose we exchange rows and columns by rotating the matrix.\n\nmatrix_bulk = matrix_bulk.T\nmatrix_bulk.head()\n\n\n\n\n\n\n\n\nFAM41C\nSAMD11\nNOC2L\nKLHL17\nISG15\nC1orf159\nSDF4\nUBE2J2\nSCNN1D\nACAP3\n...\nMCM3AP\nYBEY\nC21orf58\nPCNT\nDIP2A\nPRMT2\nAC136616.1\nAC007325.4\nAC023491.2\nAC240274.1\n\n\n\n\nHealthy_Guo1_Elong.Spt_0\n0.0\n0.000\n0.0\n0.0\n0.000000\n0.524757\n0.000000\n7.200664\n0.0\n0.0\n...\n0.000000\n2.478227\n0.000000\n0.493104\n0.728248\n0.0\n1.682502\n8.850147\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_1\n0.0\n0.000\n0.0\n0.0\n0.000000\n2.869721\n0.000000\n6.047873\n0.0\n0.0\n...\n0.000000\n3.559190\n3.714458\n0.000000\n0.000000\n0.0\n0.864075\n8.230722\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_2\n0.0\n0.822\n0.0\n0.0\n0.000000\n1.604822\n0.000000\n6.691433\n0.0\n0.0\n...\n0.000000\n2.366015\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n5.639266\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_3\n0.0\n0.000\n0.0\n0.0\n0.000000\n0.509491\n0.680446\n5.043328\n0.0\n0.0\n...\n0.680446\n3.762988\n0.000000\n1.710508\n0.680446\n0.0\n1.416343\n7.605245\n0.0\n0.0\n\n\nHealthy_Guo1_Elong.Spt_4\n0.0\n0.000\n0.0\n0.0\n0.861346\n0.420644\n0.000000\n6.480343\n0.0\n0.0\n...\n0.000000\n1.620871\n0.000000\n0.000000\n0.420644\n0.0\n0.920444\n4.049621\n0.0\n0.0\n\n\n\n\n5 rows × 12173 columns\n\n\n\nWe create a scanpy object to be able to do statistical testing.\n\nimport anndata as ad\n\n\npbulk = ad.AnnData(matrix_bulk)\n\n\npbulk\n\nAnnData object with n_obs × n_vars = 1520 × 12173\n\n\nWe just remove those genes never expressed in the pseudobulk data\n\nsc.pp.filter_genes(pbulk, min_cells=1)\n\nWe create some metadata\n\npbulk.obs['condition'] = conditions\npbulk.obs['spermatogenesis_types'] = clusters \n\nand normalize depth of each pseudobulk replicate and logarithmize, similarly to what was done in Notebook 3 of the course\n\nsc.pp.normalize_per_cell(pbulk)\nsc.pp.log1p(pbulk)\n\nOut of curiosity, why not plotting a PCA of the pseudobulk data? We can see how it looks similar to the single cell data, with a decent overlapping of the conditions, meaning the pseudobulk process kept the differences between types, and also the data structure overall.\n\nsc.pp.pca(pbulk)\n\n\nsc.pl.pca(pbulk, color=['condition','spermatogenesis_types'], s=50)\n\n\n\n\n\n\n\n\nWe can finally run the statistical test by condition. We will do a list with ALL genes, so we can explore it at any time afterwards. We will use the condition Healthy as reference, so the results will give how changes are in Crypto against Healthy\n\nsc.tl.rank_genes_groups(pbulk, groupby=\"condition\", reference='Healthy', n_genes=pbulk.shape[1])\n\nWe use a script to extract the results in a matrix. We will also calculate some other values under the hood and add them in the table.\n\nDEG_matrix = pseudobulk_extract_DEG(pbulk=pbulk, adata=merged)\n\n---Extracting results\nWARNING: adata.X seems to be already log-transformed.\n---done\n\n\nWhat does the resulting matrix contain? Apart from genes names, we can see in how many bulk samples those are expressed (in percentage for healthy and crypto cells), the fold-change and log-fold-change, the pvalues and adjusted pvalues. Note: those results are for Crypto vs Healthy. For values with Healthy as a reference, just change the sign to all fold-changes and log-fold-changes, and you have changed your reference!\n\nDEG_matrix.head()\n\n\n\n\n\n\n\n\nCrypto_NAMES\nCrypto_PVALS\nCrypto_PVALS_ADJ\nCrypto_LOGFOLDCHANGES\nHealthy_PCT\nCrypto_PCT\nCrypto_FOLDCHANGES\nCrypto_LOGPVALS_ADJ\nCrypto_LOGPVALS\n\n\n\n\n0\nEEF1G\n4.557527e-188\n1.849293e-184\n7.720026\n3.664627\n97.345133\n210.843109\n50.0\n50.0\n\n\n1\nMRPS24\n4.462642e-173\n1.358094e-169\n6.370932\n2.181480\n80.763857\n82.764008\n50.0\n50.0\n\n\n2\nGABARAP\n5.121595e-194\n3.117259e-190\n5.045707\n14.256373\n97.438286\n33.030037\n50.0\n50.0\n\n\n3\nH3F3B\n2.158483e-139\n2.919468e-136\n2.287395\n97.323417\n99.906847\n4.881739\n50.0\n50.0\n\n\n4\nPSMA6\n9.807033e-158\n1.705443e-154\n3.847374\n22.273150\n89.287378\n14.393784\n50.0\n50.0\n\n\n\n\n\n\n\nWe just want to make a volcano plot of the result table. We consider as significant genes with p-value below 0.001 (log p-value of 3) and a log-fold-change below -2 and above 2 for this plot. The dot size is the percentege of cells expressing each gene.\nAs underexpressed genes we find amongst others CXCL2 (upregulated only when azoospermia is together with inflamation) and ZNRF3 (involved in disorder of sex development). Upregulated are for example CMTM1 (involved in fertility, whose knockout has no effect on it), SPATS1 (involved in sperm development) and DLGAP2 (associated to male infertility)\n\npseudobulk_volcano(DEG_matrix, logfold_threshold=2, logpval_threshold=3, plot_size=(800,800))\n\n                                                \n\n\nFinally, you can save the table and download it, to view very easily in Excel.\n\nDEG_matrix.to_csv('./pseudobulk_markers.csv', sep='\\t', index=None)\n\n\n\n\n\n\n\nWrapping up\n\n\n\nYou executed the whole analysis to the very end of this notebook!\nIt has been a pretty long one, but I hope you learnt new things and you will benefit from them in your future scRNA-seq analysis. Remember that the scanpy webpage has a lot of tutorials and very good documentation for all the functions implemented. The universe of available tools for single cell RNA data is growing constantly and is difficult to navigate - I suggest you to try tools that seem interesting, are usable without too many dificulties, and then stick only to those that are really relevant. Fortunately the community revolving around scRNA-seq data analysis is huge and rather helpful and open-source. It is mostly a matter of googling yourself to relevant forums and github repositories to find useful answers to doubts, available tools, and guides.\nDo you want to look for more advanced analysis? We have an introduction to single cell RNA sequencing also in R and advanced topics in scRNA-seq analysis. You can find those in our Transcriptomics Sandbox on uCloud (for danish users of uCloud), otherwise the tutorials are all documented in web format at their respective webpages:\n \n\n Transcriptomics Sandbox \n\n \n\n Advanced Single Cell Analysis \n\n \n\n Intro to scRNA-seq in R"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "Computing and didactical support from the Danish Health Data Science Sandbox\n\nThis course introduces you to NGS data (short-reads and long-reads) alignment, variant analysis, bulk-RNA analysis and single-cell RNA analysis.\n\n\nThe material for this course is organized in four separated jupyter notebooks in both bash, python and R where you will benefit of an interactive coding setup on jupyterlab.\n\n\nThe first exercise lesson is executed with the web interface usegalaxy.org. Click on 1.Galaxy Exercise in the menu Exercises to get started)\n\n\n\nThe following exercise lessons will work on a computing environment with jupyterlab. Use the menu Access and the drop-down menu selecting the computing environment you need (danish clusters uCloud and GenomeDK, your PC, or another cluster).\n\n\n\n\nif you need to have a look at the exercises as a reference, then the menu Exercises contains all the compiled exercises on jupyterlab in a document format, from which you can also copy-paste the code.\n \n\n \n\n\n\n\n\n\nCourse overview\n\n\n\n\nAbstract: After the course, you will be able to apply bioinformatics methods for analyzing genomes and transcriptomes using NGS data. This includes knowledge of the existing types of genome data, how they can be displayed and analyzed, the current methods for genome assembly and analysis, their accuracy and how they can be used.\nPrerequisites: This is an introductory course that needs a basic understanding of the biology behind sequencing, and just basic programming experience would help.\nSyllabus:\n\nDescribe key challenges in the analysis of NGS data\nExplain the theoretical foundation for methods that use NGS for assembly and analysis of genomes\nDiscuss the bioinformatic methods for genome analysis and hypothesize what drives the outcome of the methods\nReview original literature within the subjects and relate the discussed topics to analysis scenarios\nApply bioinformatics tools within the selected application areas and reflect on the results, formulating your own conclusion in the proposed tasks\n\nTime: 20 hours (for reading through the code, executing it, answering questions). The material fits 4-5 days of lessons.\nSupporting Materials:\n\njupyter notebooks for interactive coding\nlecture slides from the instructor (Slides button in the menu)\n\nCourse authors\n\nMikkel H Schierup\nStig U Andersen\nSamuele Soraggi\n\nLicense: Course Content is licensed under Creative Commons Attribution 4.0 International License\nCitation: If you use any of this material for your research, please cite this course with the DOI below, and acknowledge the Health Data Science Sandbox project of the Novo Nordisk Foundation (grant number NNF20OC0063268). It is of great help to support the project. \nContact: Samuele Soraggi (samuele at birc.au.dk) for technical issues in using the material."
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "The material for this course is organized in four separated jupyter notebooks in both bash, python and R where you will benefit of an interactive coding setup on jupyterlab.\n\n\nThe first exercise lesson is executed with the web interface usegalaxy.org. Click on 1.Galaxy Exercise in the menu Exercises to get started)\n\n\n\nThe following exercise lessons will work on a computing environment with jupyterlab. Use the menu Access and the drop-down menu selecting the computing environment you need (danish clusters uCloud and GenomeDK, your PC, or another cluster)."
  },
  {
    "objectID": "index.html#compiled-exercises",
    "href": "index.html#compiled-exercises",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "if you need to have a look at the exercises as a reference, then the menu Exercises contains all the compiled exercises on jupyterlab in a document format, from which you can also copy-paste the code.\n \n\n \n\n\n\n\n\n\nCourse overview\n\n\n\n\nAbstract: After the course, you will be able to apply bioinformatics methods for analyzing genomes and transcriptomes using NGS data. This includes knowledge of the existing types of genome data, how they can be displayed and analyzed, the current methods for genome assembly and analysis, their accuracy and how they can be used.\nPrerequisites: This is an introductory course that needs a basic understanding of the biology behind sequencing, and just basic programming experience would help.\nSyllabus:\n\nDescribe key challenges in the analysis of NGS data\nExplain the theoretical foundation for methods that use NGS for assembly and analysis of genomes\nDiscuss the bioinformatic methods for genome analysis and hypothesize what drives the outcome of the methods\nReview original literature within the subjects and relate the discussed topics to analysis scenarios\nApply bioinformatics tools within the selected application areas and reflect on the results, formulating your own conclusion in the proposed tasks\n\nTime: 20 hours (for reading through the code, executing it, answering questions). The material fits 4-5 days of lessons.\nSupporting Materials:\n\njupyter notebooks for interactive coding\nlecture slides from the instructor (Slides button in the menu)\n\nCourse authors\n\nMikkel H Schierup\nStig U Andersen\nSamuele Soraggi\n\nLicense: Course Content is licensed under Creative Commons Attribution 4.0 International License\nCitation: If you use any of this material for your research, please cite this course with the DOI below, and acknowledge the Health Data Science Sandbox project of the Novo Nordisk Foundation (grant number NNF20OC0063268). It is of great help to support the project. \nContact: Samuele Soraggi (samuele at birc.au.dk) for technical issues in using the material."
  },
  {
    "objectID": "galaxy/images/galaxy.html",
    "href": "galaxy/images/galaxy.html",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "This first exercise will be executed on Galaxy, an interactive platform to run bioinformatics workflows. We will replicate this lesson with computer code later in this course. Galaxy has the possibility of working with a free account.\n\n\nWhite clover (Trifolium repens) is an allotetraploid. This means that it contains genomes originating from two different species within the same nucleus. Normally, white clover is an outbreeding species, but a self-compatible line was used for sequencing the white clover genome. This line is designated S10 in your data, indicating that this is the 10th self-fertilized generation. In addition, you have data from a wild clover accession (ecotype) called Tienshan (Ti), which is collected from Chinese mountains and is adapted to alpine conditions.\n Figure: Characterisation of the white clover population. T.Repens is a hybrid of T.Occidentale and T.Pallescens\n\n\n\n\n\n\nInstall IGV on your computer from here. This is a genome browser you will use to look at some files.\nCreate an account at usegalaxy.org and log into galaxy.\nFind the course data by going to this web address and by clicking on Import this history (top left corner of the page).\n\nNote: If usegalaxy.org has availability problems, you can use the other server https://usegalaxy.eu/ and get the data at this link. You might need to create an account there as well.\n\n\nYou will be working with two types of sequencing data. The first is PacBio Hifi reads, which are long and accurate. You can find them under Hifi_reads_white_clover.fastq. The second type is Illumina RNA-seq reads, which are short and accurate and should be aligned using a spliced aligner, such as STAR.\nThere are 24 of these files, 12 for each of the two genotypes mentioned before. The files are named [genotype]_[treatment]_[replicate].fastq. Treatment 1 is before and treatment 2 is after exposure to frost, respectively.\nIn addition to the sequencing data, there are also three reference files: one for homologous contig 1 (referencing T. occidentale-derived subgenome), one for contig 2 (T. pallescens-derived subgenome) and one for both Contigs 1 and 2. The reference files are in fasta format.\nThe file white_clover_genes.gtf contains the gene annotations for the two contigs.\n\n\n\nThrough Galaxy, we build a workflow applying tools to the data. We will look at the quality of the raw reads for both PacBio HiFi and Illumina RNA-seq reads. Afterwards, we align to references, using two different tools for the two types of data. Finally, we will look at the alignments on a genome browser. We will work then on a computing cluster through uCloud to analyze the aligned data in some of the upcoming lessons of the course.\n\n\n\n\n\nWhen you import the files, what you actually import is a History - a sequence of files and softwares applied on the data. You can see the history on the right side of your usegalaxy.org webpage with green panels. Here, we only have the starting data, and you will build the rest of your history through various tools.\n\nOn the left side of the screen, you have a menu with various available tools organized by category. All those softwares are also available on a classical computing command line (we will try those as well).\n\n\n\n1 Run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis.\nIn the tool menu, click on FASTQ quality control --&gt; FASTQC read quality reports. You will see a window with tool parameters: for the first option (raw read data from history), choose multiple files and select Hifi_reads_white_clover.fastq plus other fastq files you want to see the quality of (example in figure below). Then click on the button Run Tool. \nYou will notice that some new elements are added to your history. Part of them are FastQC producing a text file, while others are FastQC producing a webpage report. The reports are ready when coloured in green: click on the eye symbol of a history item to read a report.\n2 FastQC provides a report for each sample. To have a better comparison between the Hifi and Illumina data, we would combine the three FastQC reports into one using MultiQC.\nChoose the MultiQC tool from FASTQ quality control --&gt; MultiQC aggregate results from .... In the options, select FastQC as the used tool for the logsselect FastQC as the tool used to generate the output, and then select the items of FastQC of your history producing RawData (Figure below). In this way, you build a pipeline from the previous reports to the new tool you are using. Now click on Run Tool.\n\nThe tool will be now running in your history. When it is done, click on the eye symbol to see the report.\nselect the three “RawData” outputs generated by FastQC. Visualize the Webpage generated by MultiQC. Hint: You can find a “Help” button that offers additional information about the plots for each panel.\n\nQuestions:\n\nFocus on the following panels: “Per base sequence quality”, “Per sequence quality scores”…. (“Per base sequence content” always gives a FAIL for RNA-seq data). What do you notice with respect to the sequence quality scores? And are there any other quality issues worth noting? \n\n\n\n\n\n3 Map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contigs 1 and 2) using minimap2 (Map with minimap2). Find Genomics Analysis --&gt; Mapping --&gt; Map with minimap2. In the options, do not leave Use a built-in genome index, but select the option for having a genome from history. Choose then DNA_Contig1_2.fasta as the reference sequence.\nUnder the profile with preset options, choose PacBio/Oxford Nanopore read to reference mapping (map-pb). Then click on Run Tool.\n\n4 Run the same alignment, but choose as preset options Long assembly to reference mapping. Divergence is far below 20% (asm20).\nRename then the two alignments using the edit function (pen symbol in the history). Use for example names Contig1_2_mappb and Contig1_2_asm20, to distinguish alignment options and reference genome.\n5 The aligned genomes are not sorted by coordinates. Sort the alignments using Samtools sort (Find the tool under Genomic file manipulation --&gt; SAM/BAM --&gt; Samtools sort ...). In the options, choose the two aligned files with multiple selection. Then click on Run Tool.\n6 Download the two alignments to your computer. To do so, click on the disk symbol of each file in your history, and for each download both the Dataset (alignments in bam format) and their index files (in bai format). Download as well the reference genome in fasta format (DNA_Contig1_2.fasta from the history).\n7 Open IGV on your computer. Load the reference first: go on Genome --&gt; Load genome from file and select the fasta file you downloaded. Then load the two alignments: go on File --&gt; Load from file and select the bam and bai files you downloaded, together. You can now visualize the alignments.\n\n\nQuestions:\n\n Look at the alignments in IGV. What do you notice about the alignments? What is the difference between the two alignments? Do you think one of them is better than the other? Choose on of the two alignments for the next steps. \n\n\n8 Repeat the alignment with Minimap2 (using the chosen alignment option from the question above) and the sorting, but using the reference genomes for Contig 1 and for Contig 2 searaately. Note: you can run all at once by choosing multiple reference genomes in the options!\n\nQuestions:\n\n Download the two references for Contig 1 and 2, and the two sorted alignments. Load the references from the menu Genomes in IGV, and then open the two alignments using the menu File in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences? \n\n\n\n\n\n\n9 First, group the 24 RNA-seq libraries into two dataset lists, one list of pairs for S10 libraries and another for Tienshan libraries. so we can work with multiple samples simultaneously. You can do this by selecting the libraries for each genotype and choosing Build Lists of Dataset Pairs.\n\nThe grouping suggested by Galaxy is wrong, because the paired reads are paired according to _1 and _2 in their names. Change those two with R1 and R2, click on Unpair all, and then click on the suggested corrected pairs with the buttons Pair these datasets.\n\nYour sequences will be substituted by two elements in your history. Here we chose for example to name them S10 and TI.\n\n10 Do alignment of the RNA-seq lists of raw files to the reference DNA_Contig1_2.fasta using STAR. Go to Genomics analysis --&gt; RNA-seq --&gt; RNA STAR Gapped-read mapper for RNA-seq data. In the options use:\n\nas data, the parameter Paired-end (as collection), and then choose one of the two collections (you cannot run them all at once)\nas reference, DNA_Contig1_2.fasta, with Length of SA pre-indexing string equal to 9\nas index with gene-model, use white_clover_annotations.gtf\nas output, Per gene read counts (GeneCounts).\n\n11 Use MultiQC to see the quality of the output. The alignment of STAR produces log files which can be used for quality reports. Go on Genomic File Manipulation --&gt; MultiQC. In the options select the tool STAR. Then Insert STAR output, as type of output the Log, and choose the two logs listing collections of STAR alignments. Then click on Run Tool.\n\nView the report to see the alignment statistics.\nFinal note: `Galaxy can also be used to create an automatic workflow that will map the data. This workflow can be useful when running multiple samples. You can generate a workflow from the analysis already completed in a history, by going to Settings → Extract workflow. You can also create a workflow from scratch using the Workflow editor."
  },
  {
    "objectID": "galaxy/images/galaxy.html#biological-introduction",
    "href": "galaxy/images/galaxy.html#biological-introduction",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "White clover (Trifolium repens) is an allotetraploid. This means that it contains genomes originating from two different species within the same nucleus. Normally, white clover is an outbreeding species, but a self-compatible line was used for sequencing the white clover genome. This line is designated S10 in your data, indicating that this is the 10th self-fertilized generation. In addition, you have data from a wild clover accession (ecotype) called Tienshan (Ti), which is collected from Chinese mountains and is adapted to alpine conditions.\n Figure: Characterisation of the white clover population. T.Repens is a hybrid of T.Occidentale and T.Pallescens"
  },
  {
    "objectID": "galaxy/images/galaxy.html#exercise-guide",
    "href": "galaxy/images/galaxy.html#exercise-guide",
    "title": "Quality Control and Alignment of raw reads",
    "section": "",
    "text": "Install IGV on your computer from here. This is a genome browser you will use to look at some files.\nCreate an account at usegalaxy.org and log into galaxy.\nFind the course data by going to this web address and by clicking on Import this history (top left corner of the page).\n\nNote: If usegalaxy.org has availability problems, you can use the other server https://usegalaxy.eu/ and get the data at this link. You might need to create an account there as well.\n\n\nYou will be working with two types of sequencing data. The first is PacBio Hifi reads, which are long and accurate. You can find them under Hifi_reads_white_clover.fastq. The second type is Illumina RNA-seq reads, which are short and accurate and should be aligned using a spliced aligner, such as STAR.\nThere are 24 of these files, 12 for each of the two genotypes mentioned before. The files are named [genotype]_[treatment]_[replicate].fastq. Treatment 1 is before and treatment 2 is after exposure to frost, respectively.\nIn addition to the sequencing data, there are also three reference files: one for homologous contig 1 (referencing T. occidentale-derived subgenome), one for contig 2 (T. pallescens-derived subgenome) and one for both Contigs 1 and 2. The reference files are in fasta format.\nThe file white_clover_genes.gtf contains the gene annotations for the two contigs.\n\n\n\nThrough Galaxy, we build a workflow applying tools to the data. We will look at the quality of the raw reads for both PacBio HiFi and Illumina RNA-seq reads. Afterwards, we align to references, using two different tools for the two types of data. Finally, we will look at the alignments on a genome browser. We will work then on a computing cluster through uCloud to analyze the aligned data in some of the upcoming lessons of the course.\n\n\n\n\n\nWhen you import the files, what you actually import is a History - a sequence of files and softwares applied on the data. You can see the history on the right side of your usegalaxy.org webpage with green panels. Here, we only have the starting data, and you will build the rest of your history through various tools.\n\nOn the left side of the screen, you have a menu with various available tools organized by category. All those softwares are also available on a classical computing command line (we will try those as well).\n\n\n\n1 Run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis.\nIn the tool menu, click on FASTQ quality control --&gt; FASTQC read quality reports. You will see a window with tool parameters: for the first option (raw read data from history), choose multiple files and select Hifi_reads_white_clover.fastq plus other fastq files you want to see the quality of (example in figure below). Then click on the button Run Tool. \nYou will notice that some new elements are added to your history. Part of them are FastQC producing a text file, while others are FastQC producing a webpage report. The reports are ready when coloured in green: click on the eye symbol of a history item to read a report.\n2 FastQC provides a report for each sample. To have a better comparison between the Hifi and Illumina data, we would combine the three FastQC reports into one using MultiQC.\nChoose the MultiQC tool from FASTQ quality control --&gt; MultiQC aggregate results from .... In the options, select FastQC as the used tool for the logsselect FastQC as the tool used to generate the output, and then select the items of FastQC of your history producing RawData (Figure below). In this way, you build a pipeline from the previous reports to the new tool you are using. Now click on Run Tool.\n\nThe tool will be now running in your history. When it is done, click on the eye symbol to see the report.\nselect the three “RawData” outputs generated by FastQC. Visualize the Webpage generated by MultiQC. Hint: You can find a “Help” button that offers additional information about the plots for each panel.\n\nQuestions:\n\nFocus on the following panels: “Per base sequence quality”, “Per sequence quality scores”…. (“Per base sequence content” always gives a FAIL for RNA-seq data). What do you notice with respect to the sequence quality scores? And are there any other quality issues worth noting? \n\n\n\n\n\n3 Map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contigs 1 and 2) using minimap2 (Map with minimap2). Find Genomics Analysis --&gt; Mapping --&gt; Map with minimap2. In the options, do not leave Use a built-in genome index, but select the option for having a genome from history. Choose then DNA_Contig1_2.fasta as the reference sequence.\nUnder the profile with preset options, choose PacBio/Oxford Nanopore read to reference mapping (map-pb). Then click on Run Tool.\n\n4 Run the same alignment, but choose as preset options Long assembly to reference mapping. Divergence is far below 20% (asm20).\nRename then the two alignments using the edit function (pen symbol in the history). Use for example names Contig1_2_mappb and Contig1_2_asm20, to distinguish alignment options and reference genome.\n5 The aligned genomes are not sorted by coordinates. Sort the alignments using Samtools sort (Find the tool under Genomic file manipulation --&gt; SAM/BAM --&gt; Samtools sort ...). In the options, choose the two aligned files with multiple selection. Then click on Run Tool.\n6 Download the two alignments to your computer. To do so, click on the disk symbol of each file in your history, and for each download both the Dataset (alignments in bam format) and their index files (in bai format). Download as well the reference genome in fasta format (DNA_Contig1_2.fasta from the history).\n7 Open IGV on your computer. Load the reference first: go on Genome --&gt; Load genome from file and select the fasta file you downloaded. Then load the two alignments: go on File --&gt; Load from file and select the bam and bai files you downloaded, together. You can now visualize the alignments.\n\n\nQuestions:\n\n Look at the alignments in IGV. What do you notice about the alignments? What is the difference between the two alignments? Do you think one of them is better than the other? Choose on of the two alignments for the next steps. \n\n\n8 Repeat the alignment with Minimap2 (using the chosen alignment option from the question above) and the sorting, but using the reference genomes for Contig 1 and for Contig 2 searaately. Note: you can run all at once by choosing multiple reference genomes in the options!\n\nQuestions:\n\n Download the two references for Contig 1 and 2, and the two sorted alignments. Load the references from the menu Genomes in IGV, and then open the two alignments using the menu File in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences? \n\n\n\n\n\n\n9 First, group the 24 RNA-seq libraries into two dataset lists, one list of pairs for S10 libraries and another for Tienshan libraries. so we can work with multiple samples simultaneously. You can do this by selecting the libraries for each genotype and choosing Build Lists of Dataset Pairs.\n\nThe grouping suggested by Galaxy is wrong, because the paired reads are paired according to _1 and _2 in their names. Change those two with R1 and R2, click on Unpair all, and then click on the suggested corrected pairs with the buttons Pair these datasets.\n\nYour sequences will be substituted by two elements in your history. Here we chose for example to name them S10 and TI.\n\n10 Do alignment of the RNA-seq lists of raw files to the reference DNA_Contig1_2.fasta using STAR. Go to Genomics analysis --&gt; RNA-seq --&gt; RNA STAR Gapped-read mapper for RNA-seq data. In the options use:\n\nas data, the parameter Paired-end (as collection), and then choose one of the two collections (you cannot run them all at once)\nas reference, DNA_Contig1_2.fasta, with Length of SA pre-indexing string equal to 9\nas index with gene-model, use white_clover_annotations.gtf\nas output, Per gene read counts (GeneCounts).\n\n11 Use MultiQC to see the quality of the output. The alignment of STAR produces log files which can be used for quality reports. Go on Genomic File Manipulation --&gt; MultiQC. In the options select the tool STAR. Then Insert STAR output, as type of output the Log, and choose the two logs listing collections of STAR alignments. Then click on Run Tool.\n\nView the report to see the alignment statistics.\nFinal note: `Galaxy can also be used to create an automatic workflow that will map the data. This workflow can be useful when running multiple samples. You can generate a workflow from the analysis already completed in a history, by going to Settings → Extract workflow. You can also create a workflow from scratch using the Workflow editor."
  }
]