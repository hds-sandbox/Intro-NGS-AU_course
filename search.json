[
  {
    "objectID": "nb/align.html",
    "href": "nb/align.html",
    "title": "Alignment of HiFi and RNA sequencing data",
    "section": "",
    "text": "This tutorial will cover the steps for performing the alignment of raw RNA- and HiFi-sequencing data. You will need to use the software IGV on your computer to visualize some of the output files, which can be easily downloaded once they are produced. At the end of this tutorial you will be able to:\nThe output of this notebook will be used for the Variant calling analysis and the bulk RNA-sequencing analysis. If you do not want to run this notebook, you can alternatively use the free interactive tool Galaxy to perform the alignment steps. We have uploaded the data on Galaxy, and the manual to perform the exercise is found at the course webpage.\nThe present tutorial, like the rest of the course material, is available at our open-source github repository."
  },
  {
    "objectID": "nb/align.html#quality-control",
    "href": "nb/align.html#quality-control",
    "title": "Alignment of HiFi and RNA sequencing data",
    "section": "Quality Control",
    "text": "Quality Control\nWe run FastQC on the PacBio Hifi reads and on two of the Illumina RNA-seq libraries. FastQC does quality control of the raw sequence data, providing an overview of the data which can help identify if there are any problems that should be addressed before further analysis. You can find the report for each file into the folder results/fastqc_output/. The output is in HTML format and can be opened in any browser or in jupyterlab. It is however not easy to compare the various libraries by opening separate reports. To aggregate all the results, we apply the MultiQC software to the reports‚Äô folder. The output of MultiQC is in the directory results/multiqc_output/fastqc_data.\n\n%%bash\n#run fastqc\nmkdir -p results/fastqc_output\nfastqc -q -o results/fastqc_output ../Data/Clover_Data/*.fastq  &gt; /dev/null 2&gt;&1\n\nNote: fastqc prints a lot of output conisting of a simple confirmation of execution without error, even when using the option -q, which means quiet. Therefore we added &gt; /dev/null 2&gt;&1 to the command to mute the printing of that output.\n\n%%bash\n#run multiqc\nmultiqc --outdir results/multiqc_output/fastqc_data results/fastqc_output\n\n\n  /// d=903972;https://multiqc.info\u001b\\MultiQC;;\u001b\\ üîç | v1.14\n\n|           multiqc | Search path : /work/SamueleSoraggi/Notebooks/results/fastqc_output\n|         searching | ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 50/50  .html\n|            fastqc | Found 25 reports\n|           multiqc | Compressing plot data\n|           multiqc | Report      : results/multiqc_output/fastqc_data/multiqc_report.html\n|           multiqc | Data        : results/multiqc_output/fastqc_data/multiqc_data\n|           multiqc | MultiQC complete\n\n\n\n  Questions  \n\nVisualize the Webpage generated by MultiQC.\nHint: You can find a Help button that offers additional information about the plots for each panel. Focus on the following panels: ‚ÄúPer base sequence quality‚Äù, ‚ÄúPer sequence quality scores‚Äù‚Ä¶. (‚ÄúPer base sequence content‚Äù always gives a FAIL for RNA-seq data).\n\nWhat do you notice with respect to the sequence quality scores?\nAre there any other quality issues worth noting?"
  },
  {
    "objectID": "nb/align.html#hifi-data-mapping",
    "href": "nb/align.html#hifi-data-mapping",
    "title": "Alignment of HiFi and RNA sequencing data",
    "section": "Hifi data mapping",
    "text": "Hifi data mapping\nWe map the PacBio Hifi reads (Hifi_reads_white_clover.fastq) to the white clover reference sequence (Contig1&2) using minimap2. We run two mapping rounds, using two different preset options (-x in the command) for the technology: * PacBio/Oxford Nanopore read to reference mapping: map-pb * Long assembly to reference mapping. Divergence is below 20%‚Äù settings asm20. Next, we create reports of the mapping results by running QualiMap on the two obtained SAM files.\nWe first need to index the reference fasta files using samtools faidx. This produces files in .fai format containing informations about length of the reference sequence, offset for the quality scores, name of the reference sequence. Click here for a detailed overview.\n\n%%bash\n#copy the reference data in the folder reference_data, so that you can write the indexing files\nmkdir -p reference_data\ncp ../Data/Clover_Data/DNA_Contig1_2.fasta ../Data/Clover_Data/DNA_Contig1.fasta ../Data/Clover_Data/DNA_Contig2.fasta reference_data\n\n\n%%bash\nsamtools faidx reference_data/DNA_Contig1_2.fasta\nsamtools faidx reference_data/DNA_Contig1.fasta\nsamtools faidx reference_data/DNA_Contig2.fasta\n\nwe create an output folder for the HIFI alignment, and run minimap2 with the settings explained before.\n\n%%bash \nmkdir -p results/HIFI_alignment/\nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sam \\\n                            reference_data/DNA_Contig1_2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq \n\nminimap2 -a -x asm20 -o results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sam \\\n                            reference_data/DNA_Contig1_2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\n[M::mm_idx_gen::0.075*1.04] collected minimizers\n[M::mm_idx_gen::0.099*1.52] sorted minimizers\n[M::main::0.099*1.52] loaded/built the index for 2 target sequence(s)\n[M::mm_mapopt_update::0.114*1.45] mid_occ = 11\n[M::mm_idx_stat] kmer size: 19; skip: 10; is_hpc: 1; #seq: 2\n[M::mm_idx_stat::0.118*1.43] distinct minimizers: 203943 (79.05% are singletons); average occurrences: 1.273; average spacing: 8.047; total length: 2089554\n[M::worker_pipeline::11.859*2.89] mapped 4395 sequences\n[M::main] Version: 2.24-r1122\n[M::main] CMD: minimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sam reference_data/DNA_Contig1_2.fasta ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n[M::main] Real time: 11.873 sec; CPU: 34.246 sec; Peak RSS: 1.186 GB\n[M::mm_idx_gen::0.084*1.04] collected minimizers\n[M::mm_idx_gen::0.121*1.62] sorted minimizers\n[M::main::0.121*1.62] loaded/built the index for 2 target sequence(s)\n[M::mm_mapopt_update::0.138*1.54] mid_occ = 50\n[M::mm_idx_stat] kmer size: 19; skip: 10; is_hpc: 0; #seq: 2\n[M::mm_idx_stat::0.143*1.52] distinct minimizers: 298340 (78.21% are singletons); average occurrences: 1.277; average spacing: 5.484; total length: 2089554\n[M::worker_pipeline::18.366*2.88] mapped 4395 sequences\n[M::main] Version: 2.24-r1122\n[M::main] CMD: minimap2 -a -x asm20 -o results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sam reference_data/DNA_Contig1_2.fasta ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n[M::main] Real time: 18.394 sec; CPU: 52.932 sec; Peak RSS: 1.692 GB\n\n\nsamtools sort is used to sort the alignment with left-to-right coordinates. The output is in .bam format, with .sam files in input (Note that you could have gotten .bam files from minimap2 with a specific option).\n\n%%bash\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sam \\\n                -o results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam\n\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sam \\\n                -o results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam\n\nsamtools index creates the index for the bam file, stored in .bai format. The index file lets programs access any position into the aligned data without reading the whole file, which would take too much time.\n\n%%bash\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam\n\nRun quality control on both files\n\n%%bash\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1_2_mappb.sort.bam \\\n                 -outdir results/qualimap_output/PacBio_clover_alignment_1_2_mappb\n\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1_2_asm20.sort.bam \\\n                 -outdir results/qualimap_output/PacBio_clover_alignment_1_2_asm20\n\nJava memory size is set to 1200M\nLaunching application...\n\nQualiMap v.2.2.2-dev\nBuilt on 2019-11-11 14:05\n\nSelected tool: bamqc\nAvailable memory (Mb): 33\nMax memory (Mb): 1258\nStarting bam qc....\nLoading sam header...\nLoading locator...\nLoading reference...\nNumber of windows: 400, effective number of windows: 401\nChunk of reads size: 1000\nNumber of threads: 8\nProcessed 50 out of 401 windows...\nProcessed 100 out of 401 windows...\nProcessed 150 out of 401 windows...\nProcessed 200 out of 401 windows...\nProcessed 250 out of 401 windows...\nProcessed 300 out of 401 windows...\nProcessed 350 out of 401 windows...\nProcessed 400 out of 401 windows...\nTotal processed windows:401\nNumber of reads: 4395\nNumber of valid reads: 4696\nNumber of correct strand reads:0\n\nInside of regions...\nNum mapped reads: 4395\nNum mapped first of pair: 0\nNum mapped second of pair: 0\nNum singletons: 0\nTime taken to analyze reads: 12\nComputing descriptors...\nnumberOfMappedBases: 70274383\nreferenceSize: 2089554\nnumberOfSequencedBases: 70039397\nnumberOfAs: 23621784\nComputing per chromosome statistics...\nComputing histograms...\nOverall analysis time: 12\nend of bam qc\nComputing report...\nWriting HTML report...\nHTML report created successfully\n\nFinished\nJava memory size is set to 1200M\nLaunching application...\n\nQualiMap v.2.2.2-dev\nBuilt on 2019-11-11 14:05\n\nSelected tool: bamqc\nAvailable memory (Mb): 33\nMax memory (Mb): 1258\nStarting bam qc....\nLoading sam header...\nLoading locator...\nLoading reference...\nNumber of windows: 400, effective number of windows: 401\nChunk of reads size: 1000\nNumber of threads: 8\nProcessed 50 out of 401 windows...\nProcessed 100 out of 401 windows...\nProcessed 150 out of 401 windows...\nProcessed 200 out of 401 windows...\nProcessed 250 out of 401 windows...\nProcessed 300 out of 401 windows...\nProcessed 350 out of 401 windows...\nProcessed 400 out of 401 windows...\nTotal processed windows:401\nNumber of reads: 4395\nNumber of valid reads: 4747\nNumber of correct strand reads:0\n\nInside of regions...\nNum mapped reads: 4395\nNum mapped first of pair: 0\nNum mapped second of pair: 0\nNum singletons: 0\nTime taken to analyze reads: 12\nComputing descriptors...\nnumberOfMappedBases: 69947563\nreferenceSize: 2089554\nnumberOfSequencedBases: 69812688\nnumberOfAs: 23541478\nComputing per chromosome statistics...\nComputing histograms...\nOverall analysis time: 12\nend of bam qc\nComputing report...\nWriting HTML report...\nHTML report created successfully\n\nFinished\n\n\nFor easier comparison, we can again collapse the two reports into a single one using MultiQC, in the same way we did for putting together the other reports from fastQC.\n\n%%bash\n\n#run multiqc\nmultiqc --outdir results/qualimap_output results/qualimap_output\n\n\n  /// d=941002;https://multiqc.info\u001b\\MultiQC;;\u001b\\ üîç | v1.14\n\n|           multiqc | Search path : /work/SamueleSoraggi/Notebooks/results/qualimap_output\n|         searching | ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 93/93  nt.t‚Ä¶\n|          qualimap | Found 2 BamQC reports\n|           multiqc | Compressing plot data\n|           multiqc | Report      : results/qualimap_output/multiqc_report.html\n|           multiqc | Data        : results/qualimap_output/multiqc_data\n|           multiqc | MultiQC complete\n\n\nNow you can visualize the report generated, which is in results/qualimap_output/multiqc_report.html.\nNext, we map the white clover PacBio Hifi reads to contig1 and contig2 separately, using the setting you selected at the previous step (let‚Äôs say map-pb was chosen, but you are free to change this setting in the commands). As the two contigs represent the two white clover subgenomes, this mapping will allow you to see the two subgenome haplotypes and call subgenome SNPs.\n\n%%bash \nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1.sam \\\n                            reference_data/DNA_Contig1.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\n[M::mm_idx_gen::0.050*0.96] collected minimizers\n[M::mm_idx_gen::0.071*1.55] sorted minimizers\n[M::main::0.071*1.55] loaded/built the index for 1 target sequence(s)\n[M::mm_mapopt_update::0.079*1.50] mid_occ = 10\n[M::mm_idx_stat] kmer size: 19; skip: 10; is_hpc: 1; #seq: 1\n[M::mm_idx_stat::0.082*1.48] distinct minimizers: 112547 (91.45% are singletons); average occurrences: 1.141; average spacing: 8.031; total length: 1031631\n[M::worker_pipeline::27.024*2.90] mapped 4395 sequences\n[M::main] Version: 2.24-r1122\n[M::main] CMD: minimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_1.sam reference_data/DNA_Contig1.fasta ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n[M::main] Real time: 27.035 sec; CPU: 78.431 sec; Peak RSS: 2.258 GB\n\n\n\n%%bash \nminimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_2.sam \\\n                            reference_data/DNA_Contig2.fasta \\\n                            ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n\n[M::mm_idx_gen::0.048*1.04] collected minimizers\n[M::mm_idx_gen::0.069*1.61] sorted minimizers\n[M::main::0.069*1.61] loaded/built the index for 1 target sequence(s)\n[M::mm_mapopt_update::0.076*1.55] mid_occ = 10\n[M::mm_idx_stat] kmer size: 19; skip: 10; is_hpc: 1; #seq: 1\n[M::mm_idx_stat::0.080*1.53] distinct minimizers: 120722 (93.18% are singletons); average occurrences: 1.087; average spacing: 8.062; total length: 1057923\n[M::worker_pipeline::27.150*2.94] mapped 4395 sequences\n[M::main] Version: 2.24-r1122\n[M::main] CMD: minimap2 -a -x map-pb -o results/HIFI_alignment/PacBio_clover_alignment_2.sam reference_data/DNA_Contig2.fasta ../Data/Clover_Data/Hifi_reads_white_clover.fastq\n[M::main] Real time: 27.162 sec; CPU: 79.819 sec; Peak RSS: 2.058 GB\n\n\nSort the bam files and create their index using samtools\n\n%%bash\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_1.sam -o results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam\nsamtools sort results/HIFI_alignment/PacBio_clover_alignment_2.sam -o results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam\n\n\n%%bash\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam\nsamtools index results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam\n\nPerform quality control\n\n%%bash\nmkdir -p results/qualimap_output\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam -outdir results/qualimap_output/PacBio_clover_alignment_1\n\nJava memory size is set to 1200M\nLaunching application...\n\nQualiMap v.2.2.2-dev\nBuilt on 2019-11-11 14:05\n\nSelected tool: bamqc\nAvailable memory (Mb): 33\nMax memory (Mb): 1258\nStarting bam qc....\nLoading sam header...\nLoading locator...\nLoading reference...\nNumber of windows: 400, effective number of windows: 400\nChunk of reads size: 1000\nNumber of threads: 8\nProcessed 50 out of 400 windows...\nProcessed 100 out of 400 windows...\nProcessed 150 out of 400 windows...\nProcessed 200 out of 400 windows...\nProcessed 250 out of 400 windows...\nProcessed 300 out of 400 windows...\nProcessed 350 out of 400 windows...\nProcessed 400 out of 400 windows...\nTotal processed windows:400\nNumber of reads: 4395\nNumber of valid reads: 9070\nNumber of correct strand reads:0\n\nInside of regions...\nNum mapped reads: 4356\nNum mapped first of pair: 0\nNum mapped second of pair: 0\nNum singletons: 0\nTime taken to analyze reads: 10\nComputing descriptors...\nnumberOfMappedBases: 59058058\nreferenceSize: 1031631\nnumberOfSequencedBases: 54917933\nnumberOfAs: 18508479\nComputing per chromosome statistics...\nComputing histograms...\nOverall analysis time: 11\nend of bam qc\nComputing report...\nWriting HTML report...\nHTML report created successfully\n\nFinished\n\n\n\n%%bash\nqualimap bamqc -bam results/HIFI_alignment/PacBio_clover_alignment_2.sort.bam -outdir results/qualimap_output/PacBio_clover_alignment_2\n\nJava memory size is set to 1200M\nLaunching application...\n\nQualiMap v.2.2.2-dev\nBuilt on 2019-11-11 14:05\n\nSelected tool: bamqc\nAvailable memory (Mb): 33\nMax memory (Mb): 1258\nStarting bam qc....\nLoading sam header...\nLoading locator...\nLoading reference...\nNumber of windows: 400, effective number of windows: 400\nChunk of reads size: 1000\nNumber of threads: 8\nProcessed 50 out of 400 windows...\nProcessed 100 out of 400 windows...\nProcessed 150 out of 400 windows...\nProcessed 200 out of 400 windows...\nProcessed 250 out of 400 windows...\nProcessed 300 out of 400 windows...\nProcessed 350 out of 400 windows...\nProcessed 400 out of 400 windows...\nTotal processed windows:400\nNumber of reads: 4395\nNumber of valid reads: 9462\nNumber of correct strand reads:0\n\nInside of regions...\nNum mapped reads: 4394\nNum mapped first of pair: 0\nNum mapped second of pair: 0\nNum singletons: 0\nTime taken to analyze reads: 13\nComputing descriptors...\nnumberOfMappedBases: 59388453\nreferenceSize: 1057923\nnumberOfSequencedBases: 55867300\nnumberOfAs: 18822184\nComputing per chromosome statistics...\nComputing histograms...\nOverall analysis time: 13\nend of bam qc\nComputing report...\nWriting HTML report...\nHTML report created successfully\n\nFinished\n\n\n\n%%bash\n\n#run multiqc\nmultiqc --outdir results/qualimap_output results/qualimap_output\n\n\n  /// d=999624;https://multiqc.info\u001b\\MultiQC;;\u001b\\ üîç | v1.14\n\n|           multiqc | Search path : /work/SamueleSoraggi/Notebooks/results/qualimap_output\n|         searching | ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 187/187  .t‚Ä¶\n|          qualimap | Found 4 BamQC reports\n|           multiqc | Compressing plot data\n|           multiqc | Previous MultiQC output found! Adjusting filenames..\n|           multiqc | Use -f or --force to overwrite existing reports instead\n|           multiqc | Report      : results/qualimap_output/multiqc_report_1.html\n|           multiqc | Data        : results/qualimap_output/multiqc_data_1\n|           multiqc | MultiQC complete\n\n\n\n  Task: IGV visualization and Questions  \n\nNow you can inspect the alignment files in IGV.\n\nFirst, you will need to download the reference fasta sequence in ../Data/Clover_Data/DNA_Contig1_2.fasta and import it into IGV. You can do the same for the files DNA_Contig1.fasta and DNA_Contig2.fasta that you might need later. In IGV, this is done with the menu Genomes --&gt; Load Genome from file menu and by selecting the relevant fasta file. Then, choose the reference you need from the drop-down menu (see figure below).  You will not yet see much, but you can choose one of the two subgenomes (contig 1 or 2) and double click on a chromosome position to inspect the reference sequence. The next step will visualize the mapped files on IGV.\nEach mapped genome can be seen in IGV against the reference file of choice. To load an aligned file, first download it together with the index file in .bai format. For example, you need to download both results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam and results/HIFI_alignment/PacBio_clover_alignment_1.sort.bam.bai to see this alignment (you need to open only the .bam file with IGV). If you open more files, their alignments will be distributed in the IGV interface, and you can change the size of each visualization yourself (below shown with only one opened alignment). \n\nNow compare in IGV the two bam files PacBio_clover_alignment_1.sort.bam and PacBio_clover_alignment_2.sort.bam.\n\nWhat do you observe when comparing the two BAM files?\nHave a look at the polymorphic regions in IGV. Are they true polymorphisms?\n\nAdd to the visualization the third alignment PacBio_clover_alignment_1_2_mappb.sort.bam in IGV.\n\nWhy do you see fluctuations in coverage and large regions without any apparent subgenome SNPs?\nWhat are the major differences between the stats for the reads mapped to Contigs1&2 versus contig1 and contig2? What is your interpretation of the differences?"
  },
  {
    "objectID": "nb/bulk.html",
    "href": "nb/bulk.html",
    "title": "RNA-seq differential gene expression",
    "section": "",
    "text": "This tutorial will cover the steps for performing Differential Gene Expression on the RNA-seq data obtained from Galaxy. At the end of this tutorial you will be able to use R to\nThe present tutorial, like the rest of the course material, is available at our open-source github repository.\nTo use this notebook, use the NGS (R) kernel that contains the packages. Choose it by selecting Kernel -&gt; Change Kernel in the menu on top of the window.\nLoad the necessary R libraries\nlibrary(VennDiagram)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(formattable)\nlibrary(mixOmics)\nlibrary(pheatmap)\nlibrary(edgeR)\n\nWarning message:\n‚Äúpackage ‚ÄòVennDiagram‚Äô was built under R version 4.1.3‚Äù\nLoading required package: grid\n\nLoading required package: futile.logger\n\nWarning message:\n‚Äúpackage ‚Äòfutile.logger‚Äô was built under R version 4.1.3‚Äù\nWarning message:\n‚Äúpackage ‚Äòdplyr‚Äô was built under R version 4.1.3‚Äù\n\nAttaching package: ‚Äòdplyr‚Äô\n\n\nThe following objects are masked from ‚Äòpackage:stats‚Äô:\n\n    filter, lag\n\n\nThe following objects are masked from ‚Äòpackage:base‚Äô:\n\n    intersect, setdiff, setequal, union\n\n\nWarning message:\n‚Äúpackage ‚Äòtibble‚Äô was built under R version 4.1.3‚Äù\nWarning message:\n‚Äúpackage ‚Äòformattable‚Äô was built under R version 4.1.3‚Äù\nLoading required package: MASS\n\nWarning message:\n‚Äúpackage ‚ÄòMASS‚Äô was built under R version 4.1.3‚Äù\n\nAttaching package: ‚ÄòMASS‚Äô\n\n\nThe following object is masked from ‚Äòpackage:formattable‚Äô:\n\n    area\n\n\nThe following object is masked from ‚Äòpackage:dplyr‚Äô:\n\n    select\n\n\nLoading required package: lattice\n\nWarning message:\n‚Äúpackage ‚Äòlattice‚Äô was built under R version 4.1.3‚Äù\nLoading required package: ggplot2\n\nWarning message:\n‚Äúpackage ‚Äòggplot2‚Äô was built under R version 4.1.3‚Äù\n\nLoaded mixOmics 6.17.26\nThank you for using mixOmics!\nTutorials: http://mixomics.org\nBookdown vignette: https://mixomicsteam.github.io/Bookdown\nQuestions, issues: Follow the prompts at http://mixomics.org/contact-us\nCite us:  citation('mixOmics')\n\n\nWarning message:\n‚Äúpackage ‚Äòpheatmap‚Äô was built under R version 4.1.3‚Äù\nWarning message:\n‚Äúpackage ‚ÄòedgeR‚Äô was built under R version 4.1.3‚Äù\nLoading required package: limma\n\nWarning message:\n‚Äúpackage ‚Äòlimma‚Äô was built under R version 4.1.3‚Äù"
  },
  {
    "objectID": "nb/bulk.html#file-processing",
    "href": "nb/bulk.html#file-processing",
    "title": "RNA-seq differential gene expression",
    "section": "File processing",
    "text": "File processing\nThe data for this exercise comes from the 12 tabular files with Reads per Gene counts generated by STAR Mapping in the raw-data alignment part of this course. We want to create a table where each column is a sample, and the content of the table are the read counts from STAR. We must merge the 12 files with Reads per Gene information into a single file.\n\nIf you aligned datasets in the first notebook with jupyterlab, then you will find the files using the following command:\n\n\nsamples &lt;- sort(system(\"find results/STAR_output/*_align_contigs_1_2 -name \\\"*ReadsPerGene.out.tab\\\"\", intern=TRUE))\nprint(samples)\nRead_counts &lt;- do.call(cbind, lapply(samples, function(x) read.delim(file=x, header = FALSE)))\n\n [1] \"results/STAR_output/S10_align_contigs_1_2/S10_1_1ReadsPerGene.out.tab\"\n [2] \"results/STAR_output/S10_align_contigs_1_2/S10_1_2ReadsPerGene.out.tab\"\n [3] \"results/STAR_output/S10_align_contigs_1_2/S10_1_3ReadsPerGene.out.tab\"\n [4] \"results/STAR_output/S10_align_contigs_1_2/S10_2_1ReadsPerGene.out.tab\"\n [5] \"results/STAR_output/S10_align_contigs_1_2/S10_2_2ReadsPerGene.out.tab\"\n [6] \"results/STAR_output/S10_align_contigs_1_2/S10_2_3ReadsPerGene.out.tab\"\n [7] \"results/STAR_output/TI_align_contigs_1_2/TI_1_1ReadsPerGene.out.tab\"  \n [8] \"results/STAR_output/TI_align_contigs_1_2/TI_1_2ReadsPerGene.out.tab\"  \n [9] \"results/STAR_output/TI_align_contigs_1_2/TI_1_3ReadsPerGene.out.tab\"  \n[10] \"results/STAR_output/TI_align_contigs_1_2/TI_2_1ReadsPerGene.out.tab\"  \n[11] \"results/STAR_output/TI_align_contigs_1_2/TI_2_2ReadsPerGene.out.tab\"  \n[12] \"results/STAR_output/TI_align_contigs_1_2/TI_2_3ReadsPerGene.out.tab\"  \n\n\n\nIf you aligned datasets interactively with Galaxy, then you will need to\n\ncreate the folder tabular_files into the results folder\ncopy the tabular files from STAR into the created folder. Each file must have the sample name and end by ReadsPerGene.out.tab. For example S10_1_1ReadsPerGene.out.tab\nrun the following commands removing the # symbol\n\n\n\n#samples &lt;- sort(system(\"find results/tabular_files/ -name \\\"*ReadsPerGene.out.tab\\\"\", intern=TRUE))\n#print(samples)\n#Read_counts &lt;- do.call(cbind, lapply(samples, function(x) read.delim(file=x, header = FALSE)))\n\nThe data frame has genes as rows and samples as columns and stores the gene expression counts (value representing the total number of sequence reads that originated from a particular gene in a sample) for each of the 12 samples. This data frame should have 12 columns and 366 rows.\n\nrownames(Read_counts) &lt;- Read_counts[,1]\nRead_counts &lt;- Read_counts[c(5:nrow(Read_counts)), c(seq(2, 46, by=4))]\ncolnames(Read_counts) &lt;- c(\"S10_1_1\", \"S10_1_2\", \"S10_1_3\", \"S10_2_1\", \"S10_2_2\", \"S10_2_3\", \n                       \"TI_1_1\", \"TI_1_2\", \"TI_1_3\", \"TI_2_1\", \"TI_2_2\", \"TI_2_3\")\nhead(Read_counts, n=10)\ndim(Read_counts) # dimensions of the data frame\n\n\nA data.frame: 10 √ó 12\n\n\n\nS10_1_1\nS10_1_2\nS10_1_3\nS10_2_1\nS10_2_2\nS10_2_3\nTI_1_1\nTI_1_2\nTI_1_3\nTI_2_1\nTI_2_2\nTI_2_3\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\ng175\n143\n226\n227\n217\n206\n193\n234\n205\n198\n221\n206\n165\n\n\ng176\n17\n12\n15\n8\n14\n18\n29\n19\n30\n6\n11\n23\n\n\ng177\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng178\n0\n0\n0\n0\n0\n0\n0\n0\n2\n2\n1\n2\n\n\ng179\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng180\n2773\n5223\n4350\n4139\n3209\n4644\n1015\n1313\n889\n2675\n1023\n2565\n\n\ng181\n473\n679\n583\n437\n390\n450\n642\n700\n697\n650\n459\n410\n\n\ng182\n19\n15\n20\n9\n8\n4\n13\n7\n8\n6\n5\n4\n\n\ng183\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng184\n30\n22\n50\n57\n103\n83\n36\n29\n18\n107\n69\n89\n\n\n\n\n\n\n36612\n\n\nImport the Metadata table. This file, as its name suggests, contains information about each of the 12 RNA-seq samples, such as the treatment (Condition), genotype and replicate.\nNote that the order of the rows in the Metadata table should be the same as the columns in the Read_counts file generated above.\n\nmetadata &lt;- read.csv(\"../Data/Clover_Data/metadata.csv\", sep =\";\", row.names=1, stringsAsFactors=TRUE)\nmetadata\n\n\nA data.frame: 12 √ó 3\n\n\n\nCondition\nGenotype\nReplicate\n\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;int&gt;\n\n\n\n\nS10_1_1\nControl\nS10\n1\n\n\nS10_1_2\nControl\nS10\n2\n\n\nS10_1_3\nControl\nS10\n3\n\n\nS10_2_1\nTreatment\nS10\n1\n\n\nS10_2_2\nTreatment\nS10\n2\n\n\nS10_2_3\nTreatment\nS10\n3\n\n\nTI_1_1\nControl\nTienshan\n1\n\n\nTI_1_2\nControl\nTienshan\n2\n\n\nTI_1_3\nControl\nTienshan\n3\n\n\nTI_2_1\nTreatment\nTienshan\n1\n\n\nTI_2_2\nTreatment\nTienshan\n2\n\n\nTI_2_3\nTreatment\nTienshan\n3\n\n\n\n\n\nIn order to aid the following steps, we will create a Group for each sample (a new column in the metadata) based on the Genotype&Condition of each sample and assign the three replicates to this group.\n\nGroup &lt;- factor(paste(metadata$Genotype, metadata$Condition, sep=\"_\"))\nmetadata &lt;- cbind(metadata,Group=Group)\nmetadata\n\n\nA data.frame: 12 √ó 4\n\n\n\nCondition\nGenotype\nReplicate\nGroup\n\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;int&gt;\n&lt;fct&gt;\n\n\n\n\nS10_1_1\nControl\nS10\n1\nS10_Control\n\n\nS10_1_2\nControl\nS10\n2\nS10_Control\n\n\nS10_1_3\nControl\nS10\n3\nS10_Control\n\n\nS10_2_1\nTreatment\nS10\n1\nS10_Treatment\n\n\nS10_2_2\nTreatment\nS10\n2\nS10_Treatment\n\n\nS10_2_3\nTreatment\nS10\n3\nS10_Treatment\n\n\nTI_1_1\nControl\nTienshan\n1\nTienshan_Control\n\n\nTI_1_2\nControl\nTienshan\n2\nTienshan_Control\n\n\nTI_1_3\nControl\nTienshan\n3\nTienshan_Control\n\n\nTI_2_1\nTreatment\nTienshan\n1\nTienshan_Treatment\n\n\nTI_2_2\nTreatment\nTienshan\n2\nTienshan_Treatment\n\n\nTI_2_3\nTreatment\nTienshan\n3\nTienshan_Treatment"
  },
  {
    "objectID": "nb/bulk.html#create-the-dgelist-object",
    "href": "nb/bulk.html#create-the-dgelist-object",
    "title": "RNA-seq differential gene expression",
    "section": "Create the DGEList object",
    "text": "Create the DGEList object\nWe will merge the read counts and the metadata into a list-based data object named DGEList, which can be manipulated as any list object in R.\nThe main components of the DGEList object are the matrix ‚Äúcounts‚Äù containing our read per gene counts and a data.frame ‚Äúsamples‚Äù containing the metadata.\nNote that all the genes with zero counts across all samples were eliminated.\n\nDGEList &lt;- DGEList(Read_counts, remove.zeros = TRUE)\nDGEList$samples$Condition &lt;- relevel(metadata$Condition, ref = \"Control\")\nDGEList$samples$Genotype &lt;- metadata$Genotype\nDGEList$samples$group &lt;- metadata$Group\nDGEList\n\nRemoving 99 rows with all zero counts\n\n\n\n\n    $counts\n        \n\nA matrix: 267 √ó 12 of type int\n\n\n\nS10_1_1\nS10_1_2\nS10_1_3\nS10_2_1\nS10_2_2\nS10_2_3\nTI_1_1\nTI_1_2\nTI_1_3\nTI_2_1\nTI_2_2\nTI_2_3\n\n\n\n\ng175\n143\n226\n227\n217\n206\n193\n234\n205\n198\n221\n206\n165\n\n\ng176\n17\n12\n15\n8\n14\n18\n29\n19\n30\n6\n11\n23\n\n\ng178\n0\n0\n0\n0\n0\n0\n0\n0\n2\n2\n1\n2\n\n\ng180\n2773\n5223\n4350\n4139\n3209\n4644\n1015\n1313\n889\n2675\n1023\n2565\n\n\ng181\n473\n679\n583\n437\n390\n450\n642\n700\n697\n650\n459\n410\n\n\ng182\n19\n15\n20\n9\n8\n4\n13\n7\n8\n6\n5\n4\n\n\ng184\n30\n22\n50\n57\n103\n83\n36\n29\n18\n107\n69\n89\n\n\ng185\n0\n2\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n\n\ng186\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng187\n1\n1\n2\n0\n1\n1\n58\n49\n57\n28\n32\n29\n\n\ng188\n316\n285\n417\n200\n184\n322\n1276\n855\n1341\n402\n809\n547\n\n\ng190\n14\n18\n29\n25\n17\n31\n7\n6\n12\n20\n7\n6\n\n\ng191\n2\n2\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng192\n1\n1\n1\n1\n1\n0\n6\n10\n2\n3\n8\n2\n\n\ng193\n208\n231\n301\n289\n161\n279\n70\n61\n60\n128\n160\n91\n\n\ng194\n40\n41\n37\n44\n17\n43\n8\n10\n7\n8\n105\n25\n\n\ng195\n54\n85\n85\n71\n54\n43\n56\n54\n42\n67\n68\n56\n\n\ng196\n77\n120\n118\n186\n152\n177\n5\n9\n5\n42\n20\n34\n\n\ng197\n1\n6\n5\n18\n14\n21\n15\n44\n12\n32\n16\n17\n\n\ng198\n14\n27\n10\n11\n2\n2\n6\n6\n1\n2\n2\n0\n\n\ng199\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\ng200\n57\n80\n94\n11\n8\n23\n89\n47\n67\n5\n47\n5\n\n\ng203\n815\n1188\n1412\n1139\n1034\n1127\n911\n852\n662\n892\n781\n784\n\n\ng204\n250\n312\n348\n277\n275\n264\n125\n104\n133\n119\n91\n130\n\n\ng205\n109\n132\n181\n140\n114\n151\n89\n73\n66\n78\n46\n50\n\n\ng206\n0\n1\n2\n7\n4\n9\n4\n0\n7\n0\n1\n2\n\n\ng207\n0\n1\n0\n0\n4\n3\n1\n3\n4\n4\n3\n3\n\n\ng208\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\ng209\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\ng210\n52\n76\n60\n12\n12\n13\n61\n73\n94\n54\n45\n21\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\ng135\n0\n0\n0\n1\n0\n0\n5\n1\n0\n2\n0\n0\n\n\ng139\n0\n1\n1\n0\n0\n0\n12\n13\n11\n4\n3\n3\n\n\ng140\n0\n5\n1\n0\n0\n2\n5\n4\n0\n0\n2\n0\n\n\ng141\n177\n217\n224\n131\n117\n166\n117\n85\n67\n80\n79\n77\n\n\ng142\n488\n713\n557\n241\n154\n228\n983\n1057\n1023\n1075\n794\n933\n\n\ng144\n3319\n3987\n4763\n2249\n1996\n2260\n4405\n3880\n4585\n5072\n3618\n3590\n\n\ng146\n293\n330\n350\n913\n775\n731\n108\n92\n115\n431\n151\n226\n\n\ng147\n6\n3\n3\n0\n8\n10\n1\n1\n1\n0\n1\n0\n\n\ng148\n19\n30\n24\n15\n4\n12\n23\n19\n25\n10\n19\n8\n\n\ng149\n35\n62\n65\n57\n58\n53\n114\n103\n91\n92\n79\n93\n\n\ng150\n263\n411\n278\n752\n1378\n1300\n106\n112\n70\n516\n200\n508\n\n\ng151\n44\n44\n50\n92\n92\n84\n23\n26\n25\n56\n43\n31\n\n\ng152\n242\n258\n294\n425\n381\n521\n15\n8\n8\n16\n21\n15\n\n\ng153\n142\n144\n181\n233\n177\n233\n31\n49\n50\n50\n45\n57\n\n\ng155\n0\n4\n2\n1\n0\n0\n1\n0\n3\n0\n0\n1\n\n\ng156\n0\n0\n0\n0\n0\n0\n0\n3\n2\n0\n0\n1\n\n\ng157\n6\n1\n3\n223\n52\n152\n4\n7\n4\n153\n47\n155\n\n\ng158\n0\n0\n0\n7\n1\n3\n0\n0\n1\n1\n0\n0\n\n\ng161\n25\n38\n18\n1\n9\n2\n63\n23\n43\n0\n24\n6\n\n\ng162\n31\n43\n38\n43\n25\n28\n0\n0\n0\n0\n0\n0\n\n\ng163\n1\n0\n12\n37\n8\n18\n9\n4\n8\n16\n13\n15\n\n\ng164\n69\n58\n97\n294\n123\n168\n56\n58\n60\n146\n101\n135\n\n\ng165\n203\n376\n594\n1343\n2062\n1610\n265\n229\n214\n488\n270\n490\n\n\ng167\n2\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ng168\n2\n14\n6\n0\n0\n5\n31\n26\n38\n3\n27\n10\n\n\ng169\n0\n0\n1\n0\n1\n1\n0\n0\n0\n0\n0\n0\n\n\ng170\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\ng171\n0\n5\n0\n0\n0\n5\n0\n0\n0\n1\n0\n0\n\n\ng172\n1\n2\n2\n6\n4\n3\n3\n1\n2\n3\n3\n0\n\n\ng173\n80\n107\n120\n78\n138\n121\n67\n86\n69\n96\n105\n105\n\n\n\n\n\n$samples\n\n\n\nA data.frame: 12 √ó 5\n\n\n\ngroup\nlib.size\nnorm.factors\nCondition\nGenotype\n\n\n\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n\n\n\n\nS10_1_1\nS10_Control\n43614\n1\nControl\nS10\n\n\nS10_1_2\nS10_Control\n58803\n1\nControl\nS10\n\n\nS10_1_3\nS10_Control\n62654\n1\nControl\nS10\n\n\nS10_2_1\nS10_Treatment\n59909\n1\nTreatment\nS10\n\n\nS10_2_2\nS10_Treatment\n56761\n1\nTreatment\nS10\n\n\nS10_2_3\nS10_Treatment\n63152\n1\nTreatment\nS10\n\n\nTI_1_1\nTienshan_Control\n43387\n1\nControl\nTienshan\n\n\nTI_1_2\nTienshan_Control\n38355\n1\nControl\nTienshan\n\n\nTI_1_3\nTienshan_Control\n40304\n1\nControl\nTienshan\n\n\nTI_2_1\nTienshan_Treatment\n55509\n1\nTreatment\nTienshan\n\n\nTI_2_2\nTienshan_Treatment\n39909\n1\nTreatment\nTienshan\n\n\nTI_2_3\nTienshan_Treatment\n45008\n1\nTreatment\nTienshan"
  },
  {
    "objectID": "nb/bulk.html#preliminary-data-analysis",
    "href": "nb/bulk.html#preliminary-data-analysis",
    "title": "RNA-seq differential gene expression",
    "section": "Preliminary data analysis",
    "text": "Preliminary data analysis\nFirst, we will calculate the ‚ÄúpseudoCounts‚Äù as log2 of the reads per gene counts.  This is not part of the actual differential gene expression analysis but is helpful for data exploration and quality assessment. We will look at a histogram of one of the samples and a boxplot representation of the log2 counts for all the 12 samples.  Note that there are many genes with a low number of mapped reads and that there are differences between the average read counts for each library.\n\npseudoCounts &lt;- log2(DGEList$counts + 1)\nhead(pseudoCounts)\nhist(pseudoCounts[ ,\"S10_1_1\"], main = \"\", xlab = \"Read counts\")\nboxplot(pseudoCounts, col = \"gray\", las = 3, cex.names = 1)\n\n\nA matrix: 6 √ó 12 of type dbl\n\n\n\nS10_1_1\nS10_1_2\nS10_1_3\nS10_2_1\nS10_2_2\nS10_2_3\nTI_1_1\nTI_1_2\nTI_1_3\nTI_2_1\nTI_2_2\nTI_2_3\n\n\n\n\ng175\n7.169925\n7.826548\n7.832890\n7.768184\n7.693487\n7.599913\n7.876517\n7.686501\n7.636625\n7.794416\n7.693487\n7.375039\n\n\ng176\n4.169925\n3.700440\n4.000000\n3.169925\n3.906891\n4.247928\n4.906891\n4.321928\n4.954196\n2.807355\n3.584963\n4.584963\n\n\ng178\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.584963\n1.584963\n1.000000\n1.584963\n\n\ng180\n11.437752\n12.350939\n12.087131\n12.015415\n11.648358\n12.181463\n9.988685\n10.359750\n9.797662\n11.385862\n10.000000\n11.325305\n\n\ng181\n8.888743\n9.409391\n9.189825\n8.774787\n8.611025\n8.816984\n9.328675\n9.453271\n9.447083\n9.346514\n8.845490\n8.682995\n\n\ng182\n4.321928\n4.000000\n4.392317\n3.321928\n3.169925\n2.321928\n3.807355\n3.000000\n3.169925\n2.807355\n2.584963\n2.321928\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also create a PCA plot of the samples in order to assess the differences between the Genotypes and Conditions, but also between the replicates. In this plot the samples that are similar cluster together, while samples that are different are further apart.  In this type of plot, we would expect samples from the same group (the three replicates for each sample) to exhibit a similar gene expression profile thus clustering together while being separated from the other samples.\n\nresPCA &lt;- pca(t(pseudoCounts), ncomp = 6)\nplotIndiv(resPCA, group = metadata$Genotype, pch=metadata$Condition,\n                  legend = T, legend.title = 'Genotype', legend.title.pch = 'Condition',\n                  title = 'PCA plot raw counts', style = 'ggplot2', size.xlabel = 10, size.ylabel = 10)"
  },
  {
    "objectID": "nb/bulk.html#filtering-the-lowly-expressed-genes",
    "href": "nb/bulk.html#filtering-the-lowly-expressed-genes",
    "title": "RNA-seq differential gene expression",
    "section": "Filtering the lowly expressed genes",
    "text": "Filtering the lowly expressed genes\nAs seen previously, many genes have a low number of read counts in our samples. The genes with very low counts across all libraries provide little evidence for differential expression, thus we should eliminate these genes before the analysis.  One of the filtering methods we can use is the ‚ÄúfilterByExpr‚Äù function provided by the edgeR package. By default, this function keeps only the genes that have at least 10 reads per group, but other cutoffs can also be applied.\n\nkeep &lt;- filterByExpr(DGEList, group=metadata$Group) #create the filter\nDGEList &lt;- DGEList[keep, , keep.lib.sizes=FALSE] #apply the filter to on the DGEList object\ntable(keep) #Check the number of genes that passed the filter\n\nkeep\nFALSE  TRUE \n  104   163"
  },
  {
    "objectID": "nb/bulk.html#normalization",
    "href": "nb/bulk.html#normalization",
    "title": "RNA-seq differential gene expression",
    "section": "Normalization",
    "text": "Normalization\nAs we are working with multiple samples we need to normalize the read counts per gene in order to account for compositional and technical differences between the 12 RNA-seq libraries. For this, we will calculate normalization factors using the trimmed mean of M-values (TMM) method. You can read more about different normalization methods in the user manual.\n Note that running ‚ÄúcalcNormFactors‚Äù does not change the actual reads per gene counts, it just fills the ‚Äúnorm.factors‚Äù column in DGEList$samples.\nThese factors will be used to scale the read counts for each library. From the user guide: ‚ÄúA normalization factor below one indicates that a small number of high count genes are monopolizing the sequencing, causing the counts for other genes to be lower than would be usual given the library size.‚Äù\n\nDGEList &lt;- calcNormFactors(DGEList, method=\"RLE\")\nDGEList$samples\n\n\nA data.frame: 12 √ó 5\n\n\n\ngroup\nlib.size\nnorm.factors\nCondition\nGenotype\n\n\n\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n\n\n\n\nS10_1_1\nS10_Control\n43506\n1.0897129\nControl\nS10\n\n\nS10_1_2\nS10_Control\n58660\n1.0385093\nControl\nS10\n\n\nS10_1_3\nS10_Control\n62512\n1.0362962\nControl\nS10\n\n\nS10_2_1\nS10_Treatment\n59741\n0.9802860\nTreatment\nS10\n\n\nS10_2_2\nS10_Treatment\n56653\n0.8418644\nTreatment\nS10\n\n\nS10_2_3\nS10_Treatment\n63008\n0.8949144\nTreatment\nS10\n\n\nTI_1_1\nTienshan_Control\n43174\n1.0618440\nControl\nTienshan\n\n\nTI_1_2\nTienshan_Control\n38203\n1.0431678\nControl\nTienshan\n\n\nTI_1_3\nTienshan_Control\n40178\n1.0676351\nControl\nTienshan\n\n\nTI_2_1\nTienshan_Treatment\n55391\n0.9048196\nTreatment\nTienshan\n\n\nTI_2_2\nTienshan_Treatment\n39810\n1.1235077\nTreatment\nTienshan\n\n\nTI_2_3\nTienshan_Treatment\n44910\n0.9603761\nTreatment\nTienshan"
  },
  {
    "objectID": "nb/bulk.html#normalized-counts---exploratory-data-analysis",
    "href": "nb/bulk.html#normalized-counts---exploratory-data-analysis",
    "title": "RNA-seq differential gene expression",
    "section": "Normalized counts - Exploratory Data analysis",
    "text": "Normalized counts - Exploratory Data analysis\nFor data analysis purposes normalized log2 counts can be extracted from the DGEList object using the function CPM (counts per million).\nWe will generate the same plots as for the raw counts in order to compare the data before and after normalization.\nDo the plots for normalized counts look different compared with the plots computed before data filtering and normalization?\n\npseudoNormCounts &lt;- cpm(DGEList, log = TRUE, prior.count = 1)\nhead(pseudoNormCounts)\nhist(pseudoNormCounts[ ,\"S10_1_1\"], main = \"\", xlab = \"counts\")\nboxplot(pseudoNormCounts, col = \"gray\", las = 3, cex.names = 1)\n\nresPCA &lt;- pca(t(pseudoNormCounts), ncomp = 6)\nplotIndiv(resPCA, group = metadata$Genotype, pch=metadata$Condition,\n                  legend = T, legend.title = 'Genotype', legend.title.pch = 'Condition',\n                  title = 'PCA plot normalized counts', style = 'ggplot2', size.xlabel = 10, size.ylabel = 10)\n\n\nA matrix: 6 √ó 12 of type dbl\n\n\n\nS10_1_1\nS10_1_2\nS10_1_3\nS10_2_1\nS10_2_2\nS10_2_3\nTI_1_1\nTI_1_2\nTI_1_3\nTI_2_1\nTI_2_2\nTI_2_3\n\n\n\n\ng175\n11.568005\n11.864813\n11.782957\n11.863090\n12.083127\n11.749272\n12.323049\n12.334198\n12.178544\n12.112851\n12.175386\n11.908906\n\n\ng176\n8.564108\n7.760868\n7.974199\n7.290213\n8.292080\n8.405708\n9.349782\n8.956131\n9.490388\n7.125494\n8.054467\n9.111569\n\n\ng180\n15.836359\n16.387906\n16.035457\n16.109276\n16.038322\n16.329943\n14.435626\n15.008665\n14.340400\n15.704307\n14.482504\n15.860317\n\n\ng181\n13.287211\n13.446752\n13.138771\n12.869139\n13.000828\n12.965820\n13.775545\n14.101988\n13.989757\n13.664955\n13.327806\n13.217591\n\n\ng182\n8.716557\n8.056048\n8.360376\n7.439590\n7.551908\n6.505541\n8.245462\n7.611500\n7.689402\n7.125494\n7.041192\n6.815835\n\n\ng184\n9.350249\n8.573811\n9.628852\n9.955925\n11.089735\n10.542877\n9.653135\n9.546090\n8.779819\n11.073313\n10.609695\n11.024686"
  },
  {
    "objectID": "nb/bulk.html#degs-for-white-clover-s10-plants-treatment-vs-control",
    "href": "nb/bulk.html#degs-for-white-clover-s10-plants-treatment-vs-control",
    "title": "RNA-seq differential gene expression",
    "section": "DEGs for White clover S10 plants Treatment vs Control",
    "text": "DEGs for White clover S10 plants Treatment vs Control\nFind DEGs for White clover S10 plants in Treatment condition compared with the Control condition We will test for differentially expressed genes using the quasi-likelihood F-tests method. This is easily done just by running the ‚ÄúglmQFTest‚Äù function on the fit model and selecting one of the contrasts we created above (in this case the ‚ÄúS10‚Äù contrast).\nNext, we will use the topTags function to extract the information about all the genes.\n\nglmqlf_S10 &lt;- glmQLFTest(fit, contrast=contrasts[,\"S10\"])\nDEG_S10 &lt;- topTags(glmqlf_S10, n = nrow(DGEList$counts))\nDEG_S10\n\n\n    $table\n        \n\nA data.frame: 163 √ó 5\n\n\n\nlogFC\nlogCPM\nF\nPValue\nFDR\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ng39\n3.5861702\n14.124630\n336.66158\n5.227331e-10\n8.520550e-08\n\n\ng232\n4.0494125\n11.950441\n157.50997\n3.685988e-08\n2.591779e-06\n\n\ng6\n2.3225347\n12.999541\n150.27854\n4.770146e-08\n2.591779e-06\n\n\ng350\n2.0530029\n13.324566\n97.56453\n4.890245e-07\n1.992775e-05\n\n\ng99\n-1.5387874\n11.681004\n85.17478\n9.976659e-07\n3.195090e-05\n\n\ng142\n-1.4235276\n13.830692\n82.52308\n1.176107e-06\n3.195090e-05\n\n\ng240\n1.3603712\n14.708794\n79.98114\n1.383201e-06\n3.220882e-05\n\n\ng269\n-1.4191681\n11.834217\n75.66563\n1.841279e-06\n3.751606e-05\n\n\ng26\n2.1254241\n11.366827\n68.55898\n3.047273e-06\n5.518949e-05\n\n\ng129\n-5.3324794\n8.679594\n60.45459\n5.738115e-06\n9.353127e-05\n\n\ng272\n3.1405978\n13.860652\n59.08187\n6.432977e-06\n9.532503e-05\n\n\ng157\n5.3813801\n10.414972\n57.03712\n7.659515e-06\n1.040417e-04\n\n\ng42\n-1.9856547\n9.962762\n53.97164\n1.005146e-05\n1.260298e-04\n\n\ng165\n2.2666761\n13.690016\n51.66777\n1.243606e-05\n1.447913e-04\n\n\ng101\n3.1488142\n13.181625\n48.21727\n1.736838e-05\n1.887363e-04\n\n\ng15\n2.7410696\n10.684840\n47.29143\n1.906062e-05\n1.941800e-04\n\n\ng210\n-2.2430064\n9.993002\n46.52627\n2.060621e-05\n1.975772e-04\n\n\ng299\n-2.3509276\n10.984491\n45.75893\n2.230566e-05\n2.019901e-04\n\n\ng103\n2.6810410\n10.579777\n44.26963\n2.609599e-05\n2.238762e-04\n\n\ng144\n-0.7963477\n16.186987\n43.17707\n2.936057e-05\n2.392886e-04\n\n\ng77\n1.0984806\n14.118231\n41.46740\n3.548119e-05\n2.754016e-04\n\n\ng125\n-1.3099534\n10.195970\n39.85537\n4.266319e-05\n3.160955e-04\n\n\ng298\n-2.0471647\n9.837072\n33.49832\n9.395967e-05\n6.658881e-04\n\n\ng104\n2.4081173\n9.219160\n38.54240\n1.121281e-04\n7.615370e-04\n\n\ng122\n-0.6485441\n12.457152\n30.90261\n1.341148e-04\n8.744287e-04\n\n\ng164\n1.4415064\n11.156457\n30.50383\n1.419308e-04\n8.897970e-04\n\n\ng146\n1.3983889\n12.824184\n29.92911\n1.541544e-04\n9.306356e-04\n\n\ng313\n2.2492040\n13.614815\n28.41728\n1.926822e-04\n1.121686e-03\n\n\ng150\n1.9650641\n13.229706\n27.90020\n2.083770e-04\n1.171222e-03\n\n\ng13\n-0.6522187\n13.101579\n26.45593\n2.608176e-04\n1.417109e-03\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\ng96\n-1.873792302\n8.939397\n0.4844512655\n0.4999546\n0.6041584\n\n\ng10\n0.233134670\n14.382992\n0.4834790913\n0.5003766\n0.6041584\n\n\ng253\n0.052426914\n13.741219\n0.3075042687\n0.5896191\n0.7066759\n\n\ng289\n-0.212573283\n9.390864\n0.2887857862\n0.6010328\n0.7150974\n\n\ng312\n0.093543041\n10.849110\n0.2666731965\n0.6151559\n0.7265972\n\n\ng301\n-0.102000599\n10.135184\n0.2572520652\n0.6214023\n0.7274503\n\n\ng221\n-0.277095720\n8.469909\n0.2522121463\n0.6248039\n0.7274503\n\n\ng162\n-0.145155616\n8.517263\n0.2278112475\n0.6463283\n0.7413085\n\n\ng50\n-0.170907352\n8.749274\n0.2158314533\n0.6507284\n0.7413085\n\n\ng203\n0.062836598\n14.227601\n0.2124612164\n0.6532634\n0.7413085\n\n\ng88\n0.045949497\n14.235850\n0.2103049178\n0.6548983\n0.7413085\n\n\ng355\n-0.287897714\n8.890754\n0.1803234432\n0.6787703\n0.7630314\n\n\ng204\n-0.055975779\n11.947887\n0.1408988543\n0.7140799\n0.7972262\n\n\ng306\n0.054269738\n11.294732\n0.0923937800\n0.7664733\n0.8498990\n\n\ng193\n0.049946343\n11.682386\n0.0642557849\n0.8042743\n0.8857886\n\n\ng205\n0.037877227\n10.986961\n0.0473457745\n0.8314821\n0.9029713\n\n\ng194\n-0.142990391\n9.403497\n0.0447552162\n0.8360811\n0.9029713\n\n\ng362\n0.025629967\n11.336529\n0.0415198735\n0.8420254\n0.9029713\n\n\ng315\n0.027958374\n11.878331\n0.0409766489\n0.8430470\n0.9029713\n\n\ng180\n0.059680256\n15.711409\n0.0386140448\n0.8475743\n0.9029713\n\n\ng282\n-0.026492114\n11.756078\n0.0247991469\n0.8775434\n0.9288284\n\n\ng176\n-0.061055115\n8.587203\n0.0144510429\n0.9063467\n0.9531258\n\n\ng126\n0.061707217\n8.311212\n0.0024786868\n0.9648334\n1.0000000\n\n\ng128\n0.063825269\n7.671043\n0.0019414812\n0.9655950\n1.0000000\n\n\ng227\n-0.025740630\n7.939955\n0.0011908008\n0.9730516\n1.0000000\n\n\ng121\n0.002660852\n12.896620\n0.0005233398\n0.9821327\n1.0000000\n\n\ng284\n0.000000000\n8.538720\n0.0000000000\n1.0000000\n1.0000000\n\n\ng116\n0.000000000\n7.180297\n0.0000000000\n1.0000000\n1.0000000\n\n\ng117\n0.000000000\n7.033307\n0.0000000000\n1.0000000\n1.0000000\n\n\ng118\n0.000000000\n7.515646\n0.0000000000\n1.0000000\n1.0000000\n\n\n\n\n\n    $adjust.method\n        'BH'\n    $comparison\n        '-1*S10_Control 1*S10_Treatment'\n    $test\n        'glm'\n\n\n\nWe have now created a table with certain parameters calculated for each of the genes analysed.\nlogFC represents the base 2 logarithm of the fold change and it shows us how much the expression of the gene has changed between the two conditions. A logFC of 1 means a doubling in the read per gene count between the control and treatment samples. The genes with a logFC higher than 0 are upregulated while the genes with a logFC lower than 0 are downregulated between the control and treatment samples.  logCPM represents the average log2-counts-per-million, the abundance of the gene.\nF - F-statistic.\nPValue is the raw p-value.\nFDR (The false discovery rate) represents the adjusted p-value and is calculated using Benjamini and Hochberg‚Äôs algorithm. It controls the rate of false positive values under multiple testing. Usually, a threshold of under 5% is set for the FDR.\nThe important information for us in this table is stored in the ‚ÄúlogFC‚Äù and the ‚ÄúFDR‚Äù columns. The top DE genes have small FDR values and large fold changes\nMany of the genes in the samples are uninteresting for us, as they have a high FDR and/or low logFC values so we cannot consider them as differentially expressed.\nWe will apply a filtering step in order to keep only the statistically significant genes. We will filter out the genes with an FDR higher than 0.05 and an absolute logFC lower than 1.\n\nDEG_S10_filtered &lt;- DEG_S10$table[DEG_S10$table$FDR &lt; 0.05 & abs(DEG_S10$table$logFC) &gt; 1,] #Filtering\nDEG_S10_filtered &lt;- rownames_to_column(DEG_S10_filtered) %&gt;% rename(gene_ID = rowname) #Adding the gene_ID column\nhead(DEG_S10_filtered)\nnrow(DEG_S10_filtered) # finding the number of genes that passed the filter \n\n\nA data.frame: 6 √ó 6\n\n\n\ngene_ID\nlogFC\nlogCPM\nF\nPValue\nFDR\n\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\ng39\n3.586170\n14.12463\n336.66158\n5.227331e-10\n8.520550e-08\n\n\n2\ng232\n4.049413\n11.95044\n157.50997\n3.685988e-08\n2.591779e-06\n\n\n3\ng6\n2.322535\n12.99954\n150.27854\n4.770146e-08\n2.591779e-06\n\n\n4\ng350\n2.053003\n13.32457\n97.56453\n4.890245e-07\n1.992775e-05\n\n\n5\ng99\n-1.538787\n11.68100\n85.17478\n9.976659e-07\n3.195090e-05\n\n\n6\ng142\n-1.423528\n13.83069\n82.52308\n1.176107e-06\n3.195090e-05\n\n\n\n\n\n52\n\n\nWe can also visualize the selected genes by plotting a Smear plot or a Volcano plot. The Genes that passed the filter are coloured in red, and the top 10 genes with the lowest FDR value are labelled with their gene ID.\nWe can see that the majority of the genes analysed are either not statistically significant or have a very small logFC.\n\nplotSmear(glmqlf_S10,\n          de.tags = rownames(DEG_S10$table)[which(DEG_S10$table$FDR &lt; 0.05 & abs(DEG_S10$table$logFC) &gt; 1)])\ntext(x=DEG_S10_filtered$logCPM[1:10],\n     y=DEG_S10_filtered$logFC[1:10],\n     labels=DEG_S10_filtered$gene_ID[1:10], cex=0.7, pos=1)\nabline(h = c(-1, 1), col = \"blue\")\n\n\n\n\n\n\n\n\nWe can also create a heatmap with the log2 read counts of the selected differentially expressed genes so that we can visualise the differences in normalized counts between the Control and the Treatment samples.\nThe genes are ordered by the FDR value.\n\nannot_col &lt;- data.frame(row.names = colnames(pseudoNormCounts)[1:6], Condition = c(rep(\"Control\", 3),rep( \"Treatment\", 3)))                   \npheatmap(as.matrix(pseudoNormCounts[DEG_S10_filtered$gene_ID,c(1:6)]), cluster_rows = F, cluster_col = F, annotation_col = annot_col)"
  },
  {
    "objectID": "nb/bulk.html#degs-for-white-clover-tienshan-treatment-vs-control",
    "href": "nb/bulk.html#degs-for-white-clover-tienshan-treatment-vs-control",
    "title": "RNA-seq differential gene expression",
    "section": "DEGs for White clover Tienshan Treatment vs Control",
    "text": "DEGs for White clover Tienshan Treatment vs Control\nWe can do this using the same functions as above and changing the contrast.\nThis time we will directly filter the differentially expressed genes using the same parameters as for the S10 samples.\n\nglmqlf_Ti &lt;- glmQLFTest(fit, contrast=contrasts[,\"Tienshan\"])\nDEG_Ti &lt;- topTags(glmqlf_Ti, n = nrow(DGEList$counts))\nDEG_Ti_filtered &lt;- DEG_Ti$table[DEG_Ti$table$FDR &lt; 0.05 & abs(DEG_Ti$table$logFC) &gt; 1,]\nDEG_Ti_filtered &lt;- rownames_to_column(DEG_Ti_filtered) %&gt;% rename(gene_ID = rowname)\nprint(head(DEG_Ti_filtered))\nprint(\"Nr of differentially expressed genes:\")\nprint(nrow(DEG_Ti_filtered))\n\n  gene_ID     logFC   logCPM         F       PValue          FDR\n1    g234 -3.348667 13.00417 278.01679 1.547626e-09 2.522630e-07\n2    g269 -1.885843 11.83422 127.39949 1.172628e-07 9.556922e-06\n3     g26  2.423725 11.36683  74.33983 2.016212e-06 8.910761e-05\n4    g101  4.303290 13.18162  73.17140 2.186690e-06 8.910761e-05\n5    g272  3.391225 13.86065  66.80131 3.475790e-06 9.840357e-05\n6     g99 -1.430395 11.68100  66.25814 3.622217e-06 9.840357e-05\n[1] \"Nr of differentially expressed genes:\"\n[1] 42\n\n\nWe can now plot a Venn diagram with the DEGs for the two genotypes in order to observe the number of common and specific differentially expressed genes between the two genotypes as response to the cold exposure. You can see that a high percentage of the identified genes are common for the two genotypes, while each genotype has also specific genes.\n\nvd &lt;- venn.diagram(\n  x = list(DEG_S10_filtered$gene_ID, DEG_Ti_filtered$gene_ID),\n  category.names = c(\"S10\" , \"Tienshan\"),\n  lwd = 4,\n  fill = c(\"cornflowerblue\", \"yellowgreen\"),\n  filename = NULL,\n  cat.cex = 1,\n  cat.fontface = \"bold\",\n  output=TRUE\n)\ngrid.draw(vd)"
  },
  {
    "objectID": "nb/bulk.html#degs-for-s10tienshan-treatment-vs-control-wo-genotype-effects",
    "href": "nb/bulk.html#degs-for-s10tienshan-treatment-vs-control-wo-genotype-effects",
    "title": "RNA-seq differential gene expression",
    "section": "DEGs for S10+Tienshan Treatment vs Control w/o genotype effects",
    "text": "DEGs for S10+Tienshan Treatment vs Control w/o genotype effects\nUntil now we tested for DEGs specific for each of the two genotypes under cold treatment. We can also run a test where we ignore the genotype and just test for the differences in the cold response.  Consider the counts for both genotypes as a single dataset using the previously created contrast ‚ÄúS10_Tienshan‚Äù.  * Do the results look different compared with the previous tests?\n\nglmqlf_S10_Ti &lt;- glmQLFTest(fit, contrast=contrasts[,\"S10_Tienshan\"])\nDEG_S10_Ti &lt;- topTags(glmqlf_S10_Ti, n = nrow(DGEList$counts))\nDEG_S10_Ti_filtered &lt;- DEG_S10_Ti$table[DEG_S10_Ti$table$FDR &lt; 0.05 & abs(DEG_S10_Ti$table$logFC) &gt; 1,]\nDEG_S10_Ti_filtered &lt;- rownames_to_column(DEG_S10_Ti_filtered)  %&gt;% rename(gene_ID = rowname)\nprint(head(DEG_S10_Ti_filtered))\nprint(\"Nr of differentially expressed genes:\")\nprint(nrow(DEG_S10_Ti_filtered))\n\n  gene_ID     logFC   logCPM        F       PValue          FDR\n1     g39  2.057128 14.12463 246.6519 3.039491e-09 4.954370e-07\n2    g232  3.261008 11.95044 203.4580 8.934889e-09 5.288546e-07\n3    g269 -1.652505 11.83422 200.3564 9.733520e-09 5.288546e-07\n4      g6  1.714849 12.99954 166.2297 2.740066e-08 1.116577e-06\n5     g99 -1.484591 11.68100 150.3246 4.762148e-08 1.552460e-06\n6     g26  2.274575 11.36683 142.8625 6.290957e-08 1.623160e-06\n[1] \"Nr of differentially expressed genes:\"\n[1] 52\n\n\nPlot the results from the 3 tests in a Venn diagram to visualize the number of common and unique genes\n\nvd &lt;- venn.diagram(\n  x = list(DEG_S10_filtered$gene_ID, DEG_Ti_filtered$gene_ID,\n           DEG_S10_Ti_filtered$gene_ID),\n  category.names = c(\"S10\" , \"Tienshan\", \"S10_Tienshan\"),\n  lwd = 3,\n  fill = c(\"cornflowerblue\", \"yellowgreen\", \"thistle3\"),\n  filename = NULL,\n  cat.cex = 1,\n  cat.fontface = \"bold\",\n  output=TRUE\n)\ngrid.draw(vd)"
  },
  {
    "objectID": "nb/bulk.html#explore-dge-results",
    "href": "nb/bulk.html#explore-dge-results",
    "title": "RNA-seq differential gene expression",
    "section": "Explore DGE results",
    "text": "Explore DGE results\n\nSelect the genes which appear only in the analysis using both genotypes for further examination.\nWe can use the ‚Äúanti_join‚Äù function from the dplyr package to keep only the unique genes that appear only when using both genotypes.\n\nS10_Ti_unique &lt;- anti_join(DEG_S10_Ti_filtered, DEG_S10_filtered, by=\"gene_ID\") %&gt;%\n                       anti_join(DEG_Ti_filtered, by=\"gene_ID\")\nS10_Ti_unique\n\n\nA data.frame: 2 √ó 6\n\n\ngene_ID\nlogFC\nlogCPM\nF\nPValue\nFDR\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ng247\n-1.412652\n8.424523\n10.877350\n0.006535994\n0.01500517\n\n\ng360\n1.180849\n7.900076\n9.804067\n0.013809376\n0.02813660\n\n\n\n\n\n\n\nLinking the genes selected as differentially expressed back to the raw read counts\nHow do the counts look for these genes, does it make sense that they are differentially expressed only when using the two genotypes?\n\nRead_counts &lt;- rownames_to_column(Read_counts) %&gt;% rename(gene_ID = rowname)\nS10_Ti_unique_counts &lt;- inner_join(S10_Ti_unique[,c(1,2,6)], Read_counts, by=\"gene_ID\")\nS10_Ti_unique_counts\n\n\nA data.frame: 2 √ó 15\n\n\ngene_ID\nlogFC\nFDR\nS10_1_1\nS10_1_2\nS10_1_3\nS10_2_1\nS10_2_2\nS10_2_3\nTI_1_1\nTI_1_2\nTI_1_3\nTI_2_1\nTI_2_2\nTI_2_3\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\ng247\n-1.412652\n0.01500517\n4\n9\n3\n1\n2\n1\n42\n27\n32\n8\n22\n22\n\n\ng360\n1.180849\n0.02813660\n1\n0\n1\n3\n2\n3\n16\n10\n16\n22\n19\n22\n\n\n\n\n\n\n\nAdding functional annotation to DEGs\nUntil now we looked only at gene IDs, but we can also add functional annotations to the DEGs. The functional annotations were generated using protein sequences and the EggNOG software.\nIdentifying the molecular function of the differentially expressed genes can help us do a literature survey in order to check if any of the genes discovered have been previously identified as being involved in the cold response.\n\nFunctional_annotations &lt;- read.delim(\"../Data/Clover_Data/Functional_Annotations.txt\")\nS10_Ti_unique_FA &lt;- inner_join(S10_Ti_unique[,c(1,2,6)], Functional_annotations, by=\"gene_ID\")\nS10_Ti_unique_FA\n\n\nA data.frame: 2 √ó 4\n\n\ngene_ID\nlogFC\nFDR\nHuman.Readable.Description\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n\n\n\n\ng247\n-1.412652\n0.01500517\nNitrogen regulatory protein P-II homolog\n\n\ng360\n1.180849\n0.02813660\nUnknown protein\n\n\n\n\n\n\n  Tasks and Questions  \n\n\nBased on the results obtained in the analysis so far, would you change the cut-off for the FDR and logFC to be more strict or more permissive? Look back at the raw counts for different FDR and logFC values and set the thresholds as you find appropriate.\n\nYou can also plot histograms with the FDR and logFC values.\n\n hist(DEG_S10$table$FDR , main = \"\", xlab = \"FDR\",  breaks= 200, xlim = range(c(0, 0.1)))\n\n\n hist(DEG_S10$table$logFC , main = \"\", xlab = \"logFC\",  breaks= 50, xlim = range(c(-6, 6)))\n\n\nSeparate the upregulated and downregulated genes for each genotype and append functional annotations to them.\nIdentify the genes that are commonly upregulated in S10 and Tienshan samples and the uniquely upregulated genes for each genotype.\nWhy do you think some of the proteins appear in duplicates? \n\nTo answer these questions, it may be convenient to save summary tables from R and open them in excel. See the code below for examples of how to do this. Files can be downloaded by right-clicking on the file name.\nIf you are familiar with R functions, you are welcome to use those for counting.\n\ndir.create(\"DEG_Output_tables\", showWarnings = FALSE)\n\n\n#Create the table with the DEGs, Raw counts(just for the Ti samples in this case, change to columns (2:7) for the S10 samples) and Functional annotations\nDEG_Ti_counts_FA &lt;- inner_join(DEG_Ti_filtered[,c(1, 2, 6)], Read_counts[, c(1, 8:13)], by=\"gene_ID\") %&gt;%\n                 inner_join(Functional_annotations, by=\"gene_ID\")\n#Write the table to file\nwrite.table(DEG_Ti_counts_FA, file = \"DEG_Output_tables/Ti_Treatment_Control_DGE.txt\", quote = FALSE, row.names = FALSE, sep = \"\\t\")\n#Display the first 10 rows of the table\nhead(DEG_Ti_counts_FA, n=10)\n\nExample for filtering and counting the Up/Down genes. You can easily filter using the ‚Äúfilter()‚Äù function just by specifying the dataframe and a logical argument.\n\nDEG_Ti_up &lt;- filter(DEG_Ti_counts_FA, logFC &gt; 0)\nprint(\"Nr of upregulated genes:\")\nprint(nrow(DEG_Ti_up))\nDEG_Ti_down &lt;- filter(DEG_Ti_counts_FA, logFC &lt; 0)\nprint(\"Nr of downregulated genes:\")\nprint(nrow(DEG_Ti_down))\n\nYou can use the ‚Äúinner_join‚Äù and the ‚Äúanti_join‚Äù functions from the dplyr package to select the common and unique genes for each genotype:\nexample_file_joined &lt;- inner_join(file1, file2, by=\"gene_ID\")"
  },
  {
    "objectID": "access/genomedk.html",
    "href": "access/genomedk.html",
    "title": "Introduction to NGS data analysis",
    "section": "",
    "text": "sss"
  },
  {
    "objectID": "access/index.html",
    "href": "access/index.html",
    "title": "HPC access",
    "section": "",
    "text": "The Sandbox is collaborating with the two major academic high performance computing platforms in Denmark. Computerome is located at the Technical University of Denmark (and co-owned by the University of Copenhagen) while UCloud is owned by the University of Southern Denmark. These HPC platforms each have their own strengths which we leverage in the Sandbox in different ways."
  },
  {
    "objectID": "access/index.html#ucloud",
    "href": "access/index.html#ucloud",
    "title": "HPC access",
    "section": "UCloud",
    "text": "UCloud\nUCloud is a relatively new HPC platform that can be accessed by students at Danish universities (via a WAYF university login). It has a user friendly graphical user interface that supports straightforward project, user, and resource management. UCloud provides access to many tools via selectable Apps matched with a range of flexible compute resources, and the Sandbox is deploying training modules in this form such that any UCloud user can easily access Sandbox materials independently. The Sandbox is also hosting workshops and training events on UCloud in conjunction with in-person training.\n\n\n\n\n\n\nAccess Sandbox Apps on UCloud\n\n\n\nFind detailed instructions on accessing Sandbox apps here via UCloud. Check out UCloud‚Äôs extensive user docs here."
  },
  {
    "objectID": "access/index.html#computerome",
    "href": "access/index.html#computerome",
    "title": "HPC access",
    "section": "Computerome",
    "text": "Computerome\nComputerome is the home of many sensitive health datasets via collaborations between DTU, KU, Rigshospitalet, and other major health sector players in the Capital Region of Denmark. Computerome has recently launched their secure cloud platform, DELPHI, and in collaboration with the Sandbox has built a Course Platform on the same backbone such that courses and training can be conducted in the same environment as real research would be performed in the secure cloud. The Sandbox is supporting courses in the Course Platform, but it is also available for independent use by educators at Danish universities. Please see their website for more information on independent use and pricing, and contact us if you‚Äôd like to collaborate on hosting a course on Computerome. We can help with tool installation, environment testing, and user support (ranging from using the environment to course content if we have Sandbox staff with matching expertise).\nParticipants in courses co-hosted by the Sandbox can check here for access instructions."
  },
  {
    "objectID": "access/index.html#genomedk",
    "href": "access/index.html#genomedk",
    "title": "HPC access",
    "section": "GenomeDK",
    "text": "GenomeDK\nIn development."
  },
  {
    "objectID": "access/index.html#any-other-computing-cluster",
    "href": "access/index.html#any-other-computing-cluster",
    "title": "HPC access",
    "section": "Any other computing cluster",
    "text": "Any other computing cluster\nIn development."
  },
  {
    "objectID": "access/index.html#your-local-pc",
    "href": "access/index.html#your-local-pc",
    "title": "HPC access",
    "section": "Your local PC",
    "text": "Your local PC\nIn development."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "Computing and didactical support from the Danish Health Data Science Sandbox\n\nThis course introduces you to NGS data (short-reads and long-reads) alignment, variant analysis, bulk-RNA analysis and single-cell RNA analysis.\n\n\nThe material for this course is organized in four separated jupyter notebooks in both bash, python and R where you will benefit of an interactive coding setup on jupyterlab.\n\n\nThe first exercise lesson is executed with the web interface usegalaxy.org. Click on 1.Galaxy Exercise in the menu Exercises to get started)\n\n\n\nThe following exercise lessons will work on a computing environment with jupyterlab. Use the menu Access and the drop-down menu selecting the computing environment you need (danish clusters uCloud and GenomeDK, your PC, or another cluster).\n\n\n\n\nif you need to have a look at the exercises as a reference, then the menu Exercises contains all the compiled exercises on jupyterlab in a document format, from which you can also copy-paste the code.\n¬†\n\n¬†\n\n\n\n\n\n\nCourse overview\n\n\n\n\nAbstract: After the course, you will be able to apply bioinformatics methods for analyzing genomes and transcriptomes using NGS data. This includes knowledge of the existing types of genome data, how they can be displayed and analyzed, the current methods for genome assembly and analysis, their accuracy and how they can be used.\nPrerequisites: This is an introductory course that needs a basic understanding of the biology behind sequencing, and just basic programming experience would help.\nSyllabus:\n\nDescribe key challenges in the analysis of NGS data\nExplain the theoretical foundation for methods that use NGS for assembly and analysis of genomes\nDiscuss the bioinformatic methods for genome analysis and hypothesize what drives the outcome of the methods\nReview original literature within the subjects and relate the discussed topics to analysis scenarios\nApply bioinformatics tools within the selected application areas and reflect on the results, formulating your own conclusion in the proposed tasks\n\nTime: 20 hours (for reading through the code, executing it, answering questions). The material fits 4-5 days of lessons.\nSupporting Materials:\n\njupyter notebooks for interactive coding\nlecture slides from the instructor (Slides button in the menu)\n\nCourse authors\n\nMikkel H Schierup\nStig U Andersen\nSamuele Soraggi\nPeter S Porsborg\nAdri√°n G Repoll√©s\n\nLicense: Course Content is licensed under Creative Commons Attribution 4.0 International License\nCitation: If you use any of this material for your research, please cite this course with the DOI below, and acknowledge the Health Data Science Sandbox project of the Novo Nordisk Foundation (grant number NNF20OC0063268). It is of great help to support the project. \nContact: Samuele Soraggi (samuele at birc.au.dk) for technical issues in using the material."
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "The material for this course is organized in four separated jupyter notebooks in both bash, python and R where you will benefit of an interactive coding setup on jupyterlab.\n\n\nThe first exercise lesson is executed with the web interface usegalaxy.org. Click on 1.Galaxy Exercise in the menu Exercises to get started)\n\n\n\nThe following exercise lessons will work on a computing environment with jupyterlab. Use the menu Access and the drop-down menu selecting the computing environment you need (danish clusters uCloud and GenomeDK, your PC, or another cluster)."
  },
  {
    "objectID": "index.html#compiled-exercises",
    "href": "index.html#compiled-exercises",
    "title": "Introduction to Next Generation Sequencing data",
    "section": "",
    "text": "if you need to have a look at the exercises as a reference, then the menu Exercises contains all the compiled exercises on jupyterlab in a document format, from which you can also copy-paste the code.\n¬†\n\n¬†\n\n\n\n\n\n\nCourse overview\n\n\n\n\nAbstract: After the course, you will be able to apply bioinformatics methods for analyzing genomes and transcriptomes using NGS data. This includes knowledge of the existing types of genome data, how they can be displayed and analyzed, the current methods for genome assembly and analysis, their accuracy and how they can be used.\nPrerequisites: This is an introductory course that needs a basic understanding of the biology behind sequencing, and just basic programming experience would help.\nSyllabus:\n\nDescribe key challenges in the analysis of NGS data\nExplain the theoretical foundation for methods that use NGS for assembly and analysis of genomes\nDiscuss the bioinformatic methods for genome analysis and hypothesize what drives the outcome of the methods\nReview original literature within the subjects and relate the discussed topics to analysis scenarios\nApply bioinformatics tools within the selected application areas and reflect on the results, formulating your own conclusion in the proposed tasks\n\nTime: 20 hours (for reading through the code, executing it, answering questions). The material fits 4-5 days of lessons.\nSupporting Materials:\n\njupyter notebooks for interactive coding\nlecture slides from the instructor (Slides button in the menu)\n\nCourse authors\n\nMikkel H Schierup\nStig U Andersen\nSamuele Soraggi\nPeter S Porsborg\nAdri√°n G Repoll√©s\n\nLicense: Course Content is licensed under Creative Commons Attribution 4.0 International License\nCitation: If you use any of this material for your research, please cite this course with the DOI below, and acknowledge the Health Data Science Sandbox project of the Novo Nordisk Foundation (grant number NNF20OC0063268). It is of great help to support the project. \nContact: Samuele Soraggi (samuele at birc.au.dk) for technical issues in using the material."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor‚Äôs slides from 2022.\n\n\n\nTopic\nSlide\nNotebook\n\n\n\n\nSequencing technologies\nlink\n‚Äì\n\n\nMapping to reference\nlink\nNotebook\n\n\nData visualization\nlink\n‚Äì\n\n\nSNPs and structural variants\nlink\nNotebook\n\n\nRNA sequencing\nlink\nNotebook\n\n\nDe-novo assembly\nlink\n‚Äì\n\n\nMicrobiomes and metagenomics\nlink\n‚Äì\n\n\nSingle cell RNA sequencing\nlink\nNotebook\n\n\n\n\n\n\nHere you find a table with the instructor‚Äôs slides and a link to the compiled notebooks, that you can also run on your own following the instructions in this webpage. Data alignment can also be performed on the Galaxy interactive webpage (see the galaxy exercise in this webpage)."
  },
  {
    "objectID": "slides.html#course-material-2022",
    "href": "slides.html#course-material-2022",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor‚Äôs slides from 2022.\n\n\n\nTopic\nSlide\nNotebook\n\n\n\n\nSequencing technologies\nlink\n‚Äì\n\n\nMapping to reference\nlink\nNotebook\n\n\nData visualization\nlink\n‚Äì\n\n\nSNPs and structural variants\nlink\nNotebook\n\n\nRNA sequencing\nlink\nNotebook\n\n\nDe-novo assembly\nlink\n‚Äì\n\n\nMicrobiomes and metagenomics\nlink\n‚Äì\n\n\nSingle cell RNA sequencing\nlink\nNotebook"
  },
  {
    "objectID": "slides.html#course-material-2024",
    "href": "slides.html#course-material-2024",
    "title": "Course slides",
    "section": "",
    "text": "Here you find a table with the instructor‚Äôs slides and a link to the compiled notebooks, that you can also run on your own following the instructions in this webpage. Data alignment can also be performed on the Galaxy interactive webpage (see the galaxy exercise in this webpage)."
  },
  {
    "objectID": "access/UCloud.html",
    "href": "access/UCloud.html",
    "title": "UCloud",
    "section": "",
    "text": "Accessing the NGS summer school on UCloud\n1. User accounts on UCloud are enabled by university login credentials using WAYF (Where Are You From). Access the WAYF login portal with the button below here, and then find your affiliated university or institution using the search bar.\n¬†\n\n UCloud Access - click here \n\n¬†\n\n\n\n\n\n\nNGS summer school\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, click AFTER logging in on the button below. This will add you to a project on uCloud, where we have data and extra computing credit for the course. You should see a message on your browser where you have to accept the invitation to the project. The link expires 30 days after the course.\n¬†\n\n Invite link for the course \n\n¬†\n\n\n2. Once you are an approved user of UCloud, you are met with a dashboard interface as below. Here you can see a summary of the workspace you are using, like the hours of computing, the storage available, and other informations. The workspace you are working on is shown in the top-right corner (red circle). On the left side of the screen you have a toolbar menu.\n\n¬†\n\n\n\n\n\n\nNGS summer school\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, choose the workspace NGS summer school.\n\n\n\n3. The left-side menu can be used to access the stored data, applications, running programs and settings. Use the Applications symbol (red circle) and click on the Health Science store (green circle).\n\n5. Your screen will show some apps falling in the Health Science subcategory. Click on the Genomics Sandbox application to open its settings.\n\n6. Choose any Job Name (Nr 1 in the figure below), how many hours you want to use for the job (Nr 2, choose at least 2 hours, you can increase this later), and how many CPUs (Nr 3, choose at least 4 CPUs for the first three exercises, but use at least 8 CPUs to run the single cell analysis). Select the Introduction to NGS Data Analysis as course (Nr 4). Then click on Submit (Nr 5).\n\n7. You will be waiting in a queue looking like this\n\n8. As soon as there are resources, you will have them available, and in a short time the course will be ready to run. The screen you get is in the image below. Here you can increase the number of hours you want the session to run (red circle), close the session (green circle) and open the interface for coding (blue circle)\n\n\n\n\n\n\n\nTip\n\n\n\nOnce you open the coding interface, it does not matter if you close the browser tab with the countdown timer. You can always access it again from the toolbar menu of uCloud. Simply click on jobs and choose your session from the list of running softwares:\n\n\n\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\n\nRecovering the material from your previous session\nIt would be annoying to start from scratch at each session, with all the analysis to be executed again. You can of course find all the notebooks and results in your personal user folder in the workspace in which you are working.\nTo retrieve your work add the folders Data and Notebooks in the submission page of the Genomics App. Those are inside your user folder (called member Files: NameSurname#Number) under Jobs/Genomics Sandbox/SessionName. For example, look at how the Data folder is added from a previous session:\n\nYou need to do the same thing for the folder Notebooks. In the end you should have two folders added in your setup page just as below:"
  },
  {
    "objectID": "about/about.html",
    "href": "about/about.html",
    "title": "About the Sandbox",
    "section": "",
    "text": "An infrastructure project for health data science training and research in Denmark\nThe National Health Data Science Sandbox project kicked off in 2021 with 5 years of funding via the Data Science Research Infrastructure initiative from the Novo Nordisk Foundation. Health data science experts at five Danish universities are contributing to the Sandbox with coordination from the Center for Health Data Science under lead PI Professor Anders Krogh. Data scientists hosted in the research groups of each PI are building infrastructure and training modules on Computerome and UCloud, the primary academic high performance computing (HPC) platforms in Denmark. If you have any questions or would like to get in touch with one of our data scientists, please contact us here.\n\n\n\n\n\nOur computational ‚Äòsandbox‚Äô allows data scientists to explore datasets, tools and analysis pipelines in the same high performance computing environments where real research projects are conducted. Rather than a single, hefty environment, we‚Äôre deploying modularized topical environments tailored for independent use on each HPC platform. We aim to support three key user groups based at Danish universities:\n\ntrainees: use our training modules to learn analysis techniques with some guidance and guardrails - for your data type of interest AND for general good practices for HPC environments\n\nresearchers: prototype your tools and algorithms with an array of good quality datasets that are GDPR compliant and free to access\neducators: develop your next course with computational assignments in the HPC environment your students will use for their research\n\nActivity developing independent training modules and hosting workshops has centered on UCloud, while collaborative construction of a flexible Course Platform has been completed on Computerome for use by the Sandbox and independent educators. Publicly sourced datasets are being used in training modules on UCloud, while generation of synthetic data is an ongoing project at Computerome. Sandbox resources are under active construction, so check out our other pages for the current status on HPC Access, Datasets, and Modules. We run workshops using completed training modules on a regular basis and provide active support for Sandbox-hosted courses through a slack workspace. See our Contact page for more information.\n\n\nPartner with the Sandbox\nThe Sandbox welcomes proposals for new courses, modules, and prototyping projects from researchers and educators. We‚Äôd like to partner with lecturers engaged with us in developing needed materials collaboratively - we would love to have input from subject experts or help promote exciting new tools and analysis methods via modules! Please contact us with your ideas at nhds_sandbox@sund.ku.dk.\n\nWe thank the Novo Nordisk Foundation for funding support. If you use the Sandbox for research or reference it in text or presentations, please acknowledge the Health Data Science Sandbox project and its funder the Novo Nordisk Foundation (grant number NNF20OC0063268)."
  },
  {
    "objectID": "nb/vcf.html",
    "href": "nb/vcf.html",
    "title": "Variant Calling and VCF processing",
    "section": "",
    "text": "This tutorial will cover the steps for performing Variant calling and working on the resulting VCF file format. We will be using the Hifi and RNA-seq mapping data obtained from Galaxy. At the end of this tutorial you will be able to:\nThe present tutorial, like the rest of the course material, is available at our open-source github repository.\nTo use this notebook, use the NGS (python) kernel that contains the packages. Choose it by selecting Kernel -&gt; Change Kernel in the menu on top of the window.\nImport the necessary Python libraries:\nimport pandas\nimport allel\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSome of the commands used in the course are functions we implement to simplify reading the code of this course. Mostly, those are commands requiring lines of code that would not add anything to your learning curve (management of plots, trivial calculations, few management of the notebook layout). However, you are free to look at the code into the file Scripts/pythonScripts.py and to reuse our code in your own work (citing our course).\n%run ../Scripts/pythonScripts.py\nCreate a folder for the data necessary to VCF data analysis\n%%bash\nmkdir -p Data_for_VCF_analysis"
  },
  {
    "objectID": "nb/vcf.html#call-subgenome-snps-using-the-hifi-alignments-and-the-reference-genome",
    "href": "nb/vcf.html#call-subgenome-snps-using-the-hifi-alignments-and-the-reference-genome",
    "title": "Variant Calling and VCF processing",
    "section": "Call subgenome SNPs using the Hifi alignments and the reference genome",
    "text": "Call subgenome SNPs using the Hifi alignments and the reference genome\nWe will use the bcftools software to call SNPs from alignment files. bcftools is a toolkit for variant calling and manipulating VCF files. If you are interested, you can find all the functionalities here http://samtools.github.io/bcftools/bcftools.html#call.\nWe mainly need two commands for this step, first bcftools mpileup which takes as input the alignment and the genome reference files, followed by bcftools call to produce VCF files.\nThe cell below will generate 3 VCF files stored in the folder results/VCF_Files using the Hifi alignment files uploaded from Galaxy.\n\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_1.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_1.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_2.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_2.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f ../Data/Clover_Data/DNA_Contig1_2.fasta Data_for_VCF_analysis/HIFI_contig_1_2.bam | bcftools call -mv -Ov -o results/VCF_Files/HIFI_Contig_1_2.vcf\n\nNote: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n[mpileup] 1 samples in 1 input files\n[mpileup] maximum number of reads per input file set to -d 250\nNote: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n[mpileup] 1 samples in 1 input files\n[mpileup] maximum number of reads per input file set to -d 250\nNote: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n[mpileup] 1 samples in 1 input files\n[mpileup] maximum number of reads per input file set to -d 250\n\n\n\n  TASK  \n\n\nInspect the VCF files using IGV, comparing them to the specific alignment BAM files. (You can download the VCF files to your computer from the results/VCF_Files folder)\nAre there any problematic positions that may not represent true SNPs?\nHow can you use the HiFi reads aligned to Contigs1+2 identify potential problems?\n\nHint: Try scrolling to the ends of the contigs."
  },
  {
    "objectID": "nb/vcf.html#call-snps-using-the-two-rna-seq-genotypes-s10-and-ti",
    "href": "nb/vcf.html#call-snps-using-the-two-rna-seq-genotypes-s10-and-ti",
    "title": "Variant Calling and VCF processing",
    "section": "Call SNPs using the two RNA-seq genotypes, S10 and Ti",
    "text": "Call SNPs using the two RNA-seq genotypes, S10 and Ti\nWe will repeat the same step as above this time using the RNA-seq alignment files for the two white clover genotypes (S10 and Ti). These commands will produce another two VCF files, stored in the same folder.\n\n!bcftools mpileup --threads 4 -Ou --skip-indels -f reference_data/DNA_Contig1_2.fasta Data_for_VCF_analysis/RNA_S10_merged.bam | bcftools call -mv -Ov -o results/VCF_Files/RNA_S10_merged.vcf\n!bcftools mpileup --threads 4 -Ou --skip-indels -f reference_data/DNA_Contig1_2.fasta Data_for_VCF_analysis/RNA_TI_merged.bam | bcftools call -mv -Ov -o results/VCF_Files/RNA_TI_merged.vcf\n\n[mpileup] 1 samples in 1 input files\nNote: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n[mpileup] maximum number of reads per input file set to -d 250\nNote: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n[mpileup] 1 samples in 1 input files\n[mpileup] maximum number of reads per input file set to -d 250\n\n\n\n  TASK  \n\n\nInspect one of the VCFs and the corresponding alignment files in IGV.\nIs it relevant to filter for false positives in this case, and what parameters would you look further into?"
  }
]